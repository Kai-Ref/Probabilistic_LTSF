method: bayes  # You can also use 'random' here
metric:
  name: val/loss
  goal: minimize
parameters:
  MODEL.NAME: 
    values: ['iTransformer']
  DATA_NAME:
    values: ['ETTh1']
  OUTPUT_LEN:
    values: [720]
  RESCALE:
    values: [True, False]
  NORM_EACH_CHANNEL:
    values: [True, False]
  # INPUT_LEN:
  #   values: []
  NUM_NODES:
    values: [160, 321, 641]
  
  # MODEL params
  MODEL.PARAM.factor:
    values: [2, 3, 4, 5, 7, 10]
  MODEL.PARAM.d_model:
    values: [2, 4, 8]
  MODEL.PARAM.d_model:
    values: [32, 64, 128, 256, 512]
  MODEL.PARAM.moving_avg:
    values: [13, 19, 25, 30, 40, 51]
  MODEL.PARAM.n_heads:
    values: [4, 8, 12]
  MODEL.PARAM.e_layers:
    values: [2, 3, 4, 5]
  MODEL.PARAM.d_layers:
    values: [2, 3, 4, 5]
  MODEL.PARAM.d_ff:
    values: [32, 64, 128, 256, 512]
  MODEL.PARAM.p_hidden_dims:
    values: [32, 64, 128, 256, 512]
  MODEL.PARAM.p_hidden_layers:
    values: [1, 2, 3, 4]
  MODEL.PARAM.distil:
    values: [False, True]
  MODEL.PARAM.sigma:
    min: 0.01
    max: 0.4
    distribution: uniform 
  MODEL.PARAM.dropout:
    min: 0.01
    max: 0.4
    distribution: uniform
  MODEL.PARAM.use_norm:
    values: [False, True]
  MODEL.PARAM.output_attention:
    values: [False, True]
  MODEL.PARAM.use_norm:
    values: ['timeF', 'fixed', 'learned']
  MODEL.PARAM.activation:
    values: ['gelu', 'relu']
  MODEL.PARAM.num_time_features:
    values: [2, 3, 4, 5, 7, 10]
  MODEL.PARAM.head_type:
    values: ['probabilistic']
  MODEL.PARAM.distribution_type:
    values: ['gaussian', 'laplace', 'student_t', 'flow'] # flow 
    # values: ['m_gaussian', 'm_lr_gaussian']

  # Basic Params
  NUM_EPOCHS:
    values: [100]
  USE_WANDB:
    values: [True]

  # SCALER 
  SCALER.TYPE:
    values: [ZScoreScaler, MinMaxScaler, None]

  # OPTIMIZER
  TRAIN.OPTIM.TYPE:
    values: [Adam]
  TRAIN.OPTIM.PARAM.lr:
    min: 2.5e-4
    max: 2.5e-2
    distribution: uniform  
  TRAIN.OPTIM.PARAM.weight_decay:
    min: 1.0e-5
    max: 1.0e-3
    distribution: uniform 
  
  # SCHEDULER
  TRAIN.LR_SCHEDULER.TYPE:
    values: [MultiStepLR] 
  TRAIN.LR_SCHEDULER.PARAM.gamma:
    min: 0.3
    max: 0.7
    distribution: uniform 
  TRAIN.DATA.BATCH_SIZE:
    values: [16, 32, 64, 128]
  TRAIN.RESUME_TRAINING:
    values: [False]   
  # TRAIN.EARLY_STOPPING_PATIENCE: 
  # values: [5] 
early_terminate:
  type: hyperband
  min_iter: 2
  eta: 3