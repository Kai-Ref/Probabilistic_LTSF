None
2025-05-05 22:19:19,763 - easytorch-sweep - INFO - Launching EasyTorch HPO with wandb sweeps.
DESCRIPTION: An Example Config
GPU_NUM: 1
RUNNER: <class 'basicts.runners.runner_zoo.simple_prob_tsf_runner.SimpleProbTimeSeriesForecastingRunner'>
USE_WANDB: False
DATASET:
  NAME: ETTh1
  TYPE: <class 'basicts.data.simple_tsf_dataset.TimeSeriesForecastingDataset'>
  PARAM:
    dataset_name: ETTh1
    train_val_test_ratio: [0.6, 0.2, 0.2]
    input_len: 336
    output_len: 96
SCALER:
  TYPE: <class 'basicts.scaler.min_max_scaler.MinMaxScaler'>
  PARAM:
    dataset_name: ETTh1
    train_ratio: 0.6
    norm_each_channel: True
    rescale: False
MODEL:
  NAME: PatchTST
  ARCH: <class 'baselines.PatchTST.arch.patchtst_arch.PatchTST'>
  PARAM:
    enc_in: 7
    seq_len: 336
    pred_len: 96
    e_layers: 3
    n_heads: 4
    d_model: 16
    d_ff: 128
    dropout: 0.3
    fc_dropout: 0.3
    head_dropout: 0.0
    patch_len: 16
    stride: 8
    individual: 1
    padding_patch: end
    revin: 0
    affine: 0
    subtract_last: 1
    decomposition: 1
    kernel_size: 25
    head_type: probabilistic
    distribution_type: gaussian
    quantiles: []
  FORWARD_FEATURES: [0]
  TARGET_FEATURES: [0]
METRICS:
  FUNCS:
    NLL: nll_loss
    CRPS: crps
  TARGET: NLL
  NULL_VAL: nan
TRAIN:
  RESUME_TRAINING: False
  EARLY_STOPPING_PATIENCE: 5
  NUM_EPOCHS: 100
  CKPT_SAVE_DIR: checkpoints/gaussian_PatchTST/ETTh1_100_336_96
  LOSS: nll_loss
  OPTIM:
    TYPE: Adam
    PARAM:
      lr: 0.0002
      weight_decay: 0.0001
  LR_SCHEDULER:
    TYPE: MultiStepLR
    PARAM:
      milestones: [1, 25]
      gamma: 0.5
  CLIP_GRAD_PARAM:
    max_norm: 5.0
  DATA:
    BATCH_SIZE: 64
    SHUFFLE: True
VAL:
  INTERVAL: 1
  DATA:
    BATCH_SIZE: 64
TEST:
  INTERVAL: 1
  DATA:
    BATCH_SIZE: 64
EVAL:
  USE_GPU: True

wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: nbw0qqsb with config:
wandb: 	MODEL.PARAM.d_model: 128
wandb: 	MODEL.PARAM.decomposition: 0
wandb: 	MODEL.PARAM.distribution_type: laplace
wandb: 	MODEL.PARAM.dropout: 0.1164705562152736
wandb: 	MODEL.PARAM.e_layers: 2
wandb: 	MODEL.PARAM.fc_dropout: 0.22872650920122417
wandb: 	MODEL.PARAM.head_type: probabilistic
wandb: 	MODEL.PARAM.individual: 1
wandb: 	MODEL.PARAM.kernel_size: 32
wandb: 	MODEL.PARAM.n_heads: 8
wandb: 	MODEL.PARAM.patch_len: 32
wandb: 	MODEL.PARAM.stride: 32
wandb: 	MODEL.PARAM.subtract_last: 0
wandb: 	NORM_EACH_CHANNEL: True
wandb: 	NUM_EPOCHS: 100
wandb: 	OUTPUT_LEN: 96
wandb: 	RESCALE: True
wandb: 	SCALER.TYPE: MinMaxScaler
wandb: 	TRAIN.DATA.BATCH_SIZE: 64
wandb: 	TRAIN.LR_SCHEDULER.PARAM.gamma: 0.5789978790653056
wandb: 	TRAIN.LR_SCHEDULER.TYPE: MultiStepLR
wandb: 	TRAIN.OPTIM.PARAM.lr: 0.005356378689308299
wandb: 	TRAIN.OPTIM.PARAM.weight_decay: 0.0008691030028184726
wandb: 	TRAIN.OPTIM.TYPE: Adam
wandb: 	TRAIN.RESUME_TRAINING: False
wandb: 	USE_WANDB: True
wandb: Currently logged in as: kai-reffert (kai-reffert-university-mannheim) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: WARNING Ignoring project 'Prob_LTSF' when running a sweep.
wandb: WARNING Ignoring entity 'kai-reffert-university-mannheim' when running a sweep.
wandb: Tracking run with wandb version 0.19.9
wandb: Run data is saved locally in /home/kreffert/Probabilistic_LTSF/BasicTS/wandb/run-20250505_221921-nbw0qqsb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run PatchTST_May_05_22_19
wandb: ‚≠êÔ∏è View project at https://wandb.ai/kai-reffert-university-mannheim/Prob_LTSF
wandb: üßπ View sweep at https://wandb.ai/kai-reffert-university-mannheim/Prob_LTSF/sweeps/fwvzje2j
wandb: üöÄ View run at https://wandb.ai/kai-reffert-university-mannheim/Prob_LTSF/runs/nbw0qqsb
2025-05-05 22:19:22,260 - easytorch-sweep-agent - INFO - Starting sweep agent trial with configuration:
Update d_model to 128
Update decomposition to 0
Update distribution_type to laplace
Update dropout to 0.1164705562152736
Update e_layers to 2
Update fc_dropout to 0.22872650920122417
Update head_type to probabilistic
Update individual to 1
Update kernel_size to 32
Update n_heads to 8
Update patch_len to 32
Update stride to 32
Update subtract_last to 0
Update NORM_EACH_CHANNEL to True
Update NUM_EPOCHS to 100
Update OUTPUT_LEN to 96
Update RESCALE to True
Update TYPE to <class 'basicts.scaler.min_max_scaler.MinMaxScaler'>
Update BATCH_SIZE to 64
Update gamma to 0.5789978790653056
Update TYPE to MultiStepLR
Update lr to 0.005356378689308299
Update weight_decay to 0.0008691030028184726
Update TYPE to Adam
Update RESUME_TRAINING to False
Update USE_WANDB to True
{'DESCRIPTION': 'An Example Config', 'GPU_NUM': 1, 'RUNNER': <class 'basicts.runners.runner_zoo.simple_prob_tsf_runner.SimpleProbTimeSeriesForecastingRunner'>, 'USE_WANDB': True, 'DATASET': {'NAME': 'ETTh1', 'TYPE': <class 'basicts.data.simple_tsf_dataset.TimeSeriesForecastingDataset'>, 'PARAM': {'dataset_name': 'ETTh1', 'train_val_test_ratio': [0.6, 0.2, 0.2], 'input_len': 336, 'output_len': 96}}, 'SCALER': {'TYPE': <class 'basicts.scaler.min_max_scaler.MinMaxScaler'>, 'PARAM': {'dataset_name': 'ETTh1', 'train_ratio': 0.6, 'norm_each_channel': True, 'rescale': False}}, 'MODEL': {'NAME': 'PatchTST', 'ARCH': <class 'baselines.PatchTST.arch.patchtst_arch.PatchTST'>, 'PARAM': {'enc_in': 7, 'seq_len': 336, 'pred_len': 96, 'e_layers': 2, 'n_heads': 8, 'd_model': 128, 'd_ff': 128, 'dropout': 0.1164705562152736, 'fc_dropout': 0.22872650920122417, 'head_dropout': 0.0, 'patch_len': 32, 'stride': 32, 'individual': 1, 'padding_patch': 'end', 'revin': 0, 'affine': 0, 'subtract_last': 0, 'decomposition': 0, 'kernel_size': 32, 'head_type': 'probabilistic', 'distribution_type': 'laplace', 'quantiles': []}, 'FORWARD_FEATURES': [0], 'TARGET_FEATURES': [0]}, 'METRICS': {'FUNCS': {'NLL': <function nll_loss at 0x7f0765438360>, 'CRPS': <function crps at 0x7f0766413420>}, 'TARGET': 'NLL', 'NULL_VAL': nan}, 'TRAIN': {'RESUME_TRAINING': False, 'EARLY_STOPPING_PATIENCE': 5, 'NUM_EPOCHS': 100, 'CKPT_SAVE_DIR': 'checkpoints/gaussian_PatchTST/ETTh1_100_336_96', 'LOSS': <function nll_loss at 0x7f0765438360>, 'OPTIM': {'TYPE': 'Adam', 'PARAM': {'lr': 0.005356378689308299, 'weight_decay': 0.0008691030028184726}}, 'LR_SCHEDULER': {'TYPE': 'MultiStepLR', 'PARAM': {'milestones': [1, 25], 'gamma': 0.5789978790653056}}, 'CLIP_GRAD_PARAM': {'max_norm': 5.0}, 'DATA': {'BATCH_SIZE': 64, 'SHUFFLE': True}}, 'VAL': {'INTERVAL': 1, 'DATA': {'BATCH_SIZE': 64}}, 'TEST': {'INTERVAL': 1, 'DATA': {'BATCH_SIZE': 64}}, 'EVAL': {'USE_GPU': True}, 'MD5': 'b1a7fc8ebd65fd32cc59e1587d8e4831', 'NORM_EACH_CHANNEL': True, 'NUM_EPOCHS': 100, 'OUTPUT_LEN': 96, 'RESCALE': True}
2025-05-05 22:19:22,264 - easytorch-sweep-agent - INFO - Updated configuration with sweep parameters.
2025-05-05 22:19:22,265 - easytorch-launcher - INFO - Initializing runner '<class 'basicts.runners.runner_zoo.simple_prob_tsf_runner.SimpleProbTimeSeriesForecastingRunner'>'
2025-05-05 22:19:22,265 - easytorch-env - INFO - Disable TF32 mode
2025-05-05 22:19:22,266 - easytorch - INFO - Set ckpt save dir: 'checkpoints/gaussian_PatchTST/ETTh1_100_336_96/b1a7fc8ebd65fd32cc59e1587d8e4831'
2025-05-05 22:19:22,266 - easytorch - INFO - Building model.
PatchTST
2025-05-05 22:19:22,756 - easytorch-training - INFO - Initializing training.
2025-05-05 22:19:22,757 - easytorch-training - INFO - Set clip grad, param: {'max_norm': 5.0}
2025-05-05 22:19:22,758 - easytorch-training - INFO - Building training data loader.
2025-05-05 22:19:22,763 - easytorch-training - INFO - Train dataset length: 8209
2025-05-05 22:19:26,944 - easytorch-training - INFO - Set optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    decoupled_weight_decay: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.005356378689308299
    maximize: False
    weight_decay: 0.0008691030028184726
)
2025-05-05 22:19:26,947 - easytorch-training - INFO - Set lr_scheduler: <torch.optim.lr_scheduler.MultiStepLR object at 0x7f0701bb74d0>
2025-05-05 22:19:26,951 - easytorch-training - INFO - Initializing validation.
2025-05-05 22:19:26,952 - easytorch-training - INFO - Building val data loader.
2025-05-05 22:19:26,955 - easytorch-training - INFO - Validation dataset length: 2449
2025-05-05 22:19:26,959 - easytorch-training - INFO - Test dataset length: 2449
2025-05-05 22:19:26,962 - easytorch-training - INFO - Number of parameters: 2098496
2025-05-05 22:19:26,962 - easytorch-training - INFO - Epoch 1 / 100
  0%|          | 0/129 [00:00<?, ?it/s]  1%|          | 1/129 [00:01<02:25,  1.14s/it]  2%|‚ñè         | 3/129 [00:01<00:42,  2.99it/s]  5%|‚ñç         | 6/129 [00:01<00:19,  6.41it/s]  7%|‚ñã         | 9/129 [00:01<00:12,  9.87it/s]  9%|‚ñâ         | 12/129 [00:01<00:09, 12.88it/s] 12%|‚ñà‚ñè        | 15/129 [00:01<00:07, 15.68it/s] 14%|‚ñà‚ñç        | 18/129 [00:01<00:06, 18.10it/s] 16%|‚ñà‚ñã        | 21/129 [00:01<00:05, 19.83it/s] 19%|‚ñà‚ñä        | 24/129 [00:02<00:04, 21.36it/s] 21%|‚ñà‚ñà        | 27/129 [00:02<00:04, 22.49it/s] 23%|‚ñà‚ñà‚ñé       | 30/129 [00:02<00:04, 23.20it/s] 26%|‚ñà‚ñà‚ñå       | 33/129 [00:02<00:04, 23.52it/s] 28%|‚ñà‚ñà‚ñä       | 36/129 [00:02<00:03, 23.96it/s] 30%|‚ñà‚ñà‚ñà       | 39/129 [00:02<00:03, 24.33it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 42/129 [00:02<00:03, 24.60it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 45/129 [00:02<00:03, 24.86it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 48/129 [00:03<00:03, 25.28it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 51/129 [00:03<00:03, 24.77it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 54/129 [00:03<00:03, 24.77it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 57/129 [00:03<00:02, 24.23it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 60/129 [00:03<00:02, 24.38it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 63/129 [00:03<00:02, 24.74it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 66/129 [00:03<00:02, 24.85it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 69/129 [00:03<00:02, 24.51it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 72/129 [00:04<00:02, 24.42it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 75/129 [00:04<00:02, 23.12it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 78/129 [00:04<00:02, 23.24it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 81/129 [00:04<00:02, 23.29it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 84/129 [00:04<00:01, 23.76it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 87/129 [00:04<00:01, 23.99it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 90/129 [00:04<00:01, 23.98it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 93/129 [00:04<00:01, 24.02it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 96/129 [00:05<00:01, 24.18it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 99/129 [00:05<00:01, 24.23it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 102/129 [00:05<00:01, 23.92it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 105/129 [00:05<00:00, 24.01it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 108/129 [00:05<00:00, 24.33it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 111/129 [00:05<00:00, 24.47it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 114/129 [00:05<00:00, 24.33it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 117/129 [00:05<00:00, 24.52it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 120/129 [00:06<00:00, 24.73it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 123/129 [00:06<00:00, 24.32it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 126/129 [00:06<00:00, 24.46it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 129/129 [00:06<00:00, 24.35it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 129/129 [00:06<00:00, 20.15it/s]
2025-05-05 22:19:33,377 - easytorch-training - INFO - Result <train>: [train/time: 6.41 (s), train/lr: 5.36e-03, train/loss: 0.8115, train/NLL: 0.8115, train/CRPS: 0.3001]
2025-05-05 22:19:33,380 - easytorch-training - INFO - Start validation.
  0%|          | 0/39 [00:00<?, ?it/s] 13%|‚ñà‚ñé        | 5/39 [00:00<00:00, 42.98it/s] 28%|‚ñà‚ñà‚ñä       | 11/39 [00:00<00:00, 49.11it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 17/39 [00:00<00:00, 50.33it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 23/39 [00:00<00:00, 51.95it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 29/39 [00:00<00:00, 52.97it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 35/39 [00:00<00:00, 51.34it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 39/39 [00:00<00:00, 51.29it/s]
2025-05-05 22:19:34,144 - easytorch-training - INFO - Result <val>: [val/time: 0.76 (s), val/loss: 9.7743, val/NLL: 9.7743, val/CRPS: 6.8632]
2025-05-05 22:19:34,318 - easytorch-training - INFO - Checkpoint checkpoints/gaussian_PatchTST/ETTh1_100_336_96/b1a7fc8ebd65fd32cc59e1587d8e4831/PatchTST_best_val_NLL.pt saved
  0%|          | 0/39 [00:00<?, ?it/s] 18%|‚ñà‚ñä        | 7/39 [00:00<00:00, 61.48it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 15/39 [00:00<00:00, 69.66it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 23/39 [00:00<00:00, 70.72it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 31/39 [00:00<00:00, 70.48it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 39/39 [00:00<00:00, 71.14it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 39/39 [00:00<00:00, 69.92it/s]
2025-05-05 22:19:35,000 - easytorch-training - INFO - Result <test>: [test/time: 0.68 (s), test/loss: 17.5774, test/NLL: 17.6413, test/CRPS: 8.4211]
2025-05-05 22:19:35,129 - easytorch-training - INFO - Checkpoint checkpoints/gaussian_PatchTST/ETTh1_100_336_96/b1a7fc8ebd65fd32cc59e1587d8e4831/PatchTST_001.pt saved
2025-05-05 22:19:35,132 - easytorch-training - INFO - The estimated training finish time is 2025-05-05 22:33:03
2025-05-05 22:19:35,132 - easytorch-training - INFO - Epoch 2 / 100
  0%|          | 0/129 [00:00<?, ?it/s]  2%|‚ñè         | 3/129 [00:00<00:05, 21.34it/s]  5%|‚ñç         | 6/129 [00:00<00:05, 22.92it/s]  7%|‚ñã         | 9/129 [00:00<00:05, 23.75it/s]  9%|‚ñâ         | 12/129 [00:00<00:04, 24.05it/s] 12%|‚ñà‚ñè        | 15/129 [00:00<00:04, 24.44it/s] 14%|‚ñà‚ñç        | 18/129 [00:00<00:04, 24.56it/s] 16%|‚ñà‚ñã        | 21/129 [00:00<00:04, 24.46it/s] 19%|‚ñà‚ñä        | 24/129 [00:00<00:04, 24.57it/s] 21%|‚ñà‚ñà        | 27/129 [00:01<00:04, 24.17it/s] 23%|‚ñà‚ñà‚ñé       | 30/129 [00:01<00:04, 24.19it/s] 26%|‚ñà‚ñà‚ñå       | 33/129 [00:01<00:03, 24.35it/s] 28%|‚ñà‚ñà‚ñä       | 36/129 [00:01<00:03, 24.60it/s] 30%|‚ñà‚ñà‚ñà       | 39/129 [00:01<00:03, 24.61it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 42/129 [00:01<00:03, 24.55it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 45/129 [00:01<00:03, 24.22it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 48/129 [00:01<00:03, 24.08it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 51/129 [00:02<00:03, 24.14it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 54/129 [00:02<00:03, 24.28it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 57/129 [00:02<00:02, 24.42it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 60/129 [00:02<00:02, 24.41it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 63/129 [00:02<00:02, 24.61it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 66/129 [00:02<00:02, 24.66it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 69/129 [00:02<00:02, 24.67it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 72/129 [00:02<00:02, 24.68it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 75/129 [00:03<00:02, 24.76it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 78/129 [00:03<00:02, 24.83it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 81/129 [00:03<00:01, 24.77it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 84/129 [00:03<00:01, 24.89it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 87/129 [00:03<00:01, 24.75it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 90/129 [00:03<00:01, 24.84it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 93/129 [00:03<00:01, 24.69it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 96/129 [00:03<00:01, 24.89it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 99/129 [00:04<00:01, 24.87it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 102/129 [00:04<00:01, 24.78it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 105/129 [00:04<00:00, 24.95it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 108/129 [00:04<00:00, 25.07it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 111/129 [00:04<00:00, 25.04it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 114/129 [00:04<00:00, 24.89it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 117/129 [00:04<00:00, 24.88it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 120/129 [00:04<00:00, 25.06it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 123/129 [00:05<00:00, 24.91it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 126/129 [00:05<00:00, 24.91it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 129/129 [00:05<00:00, 25.47it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 129/129 [00:05<00:00, 24.62it/s]
2025-05-05 22:19:40,378 - easytorch-training - INFO - Result <train>: [train/time: 5.24 (s), train/lr: 3.10e-03, train/loss: -0.3317, train/NLL: -0.3317, train/CRPS: 0.1999]
2025-05-05 22:19:40,380 - easytorch-training - INFO - Start validation.
  0%|          | 0/39 [00:00<?, ?it/s] 15%|‚ñà‚ñå        | 6/39 [00:00<00:00, 51.26it/s] 31%|‚ñà‚ñà‚ñà       | 12/39 [00:00<00:00, 52.37it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 18/39 [00:00<00:00, 52.69it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 24/39 [00:00<00:00, 52.27it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 30/39 [00:00<00:00, 52.49it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 36/39 [00:00<00:00, 52.53it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 39/39 [00:00<00:00, 52.81it/s]
2025-05-05 22:19:41,122 - easytorch-training - INFO - Result <val>: [val/time: 0.74 (s), val/loss: -0.6251, val/NLL: -0.6251, val/CRPS: 0.0746]
2025-05-05 22:19:41,254 - easytorch-training - INFO - Checkpoint checkpoints/gaussian_PatchTST/ETTh1_100_336_96/b1a7fc8ebd65fd32cc59e1587d8e4831/PatchTST_best_val_NLL.pt saved
  0%|          | 0/39 [00:00<?, ?it/s] 18%|‚ñà‚ñä        | 7/39 [00:00<00:00, 66.08it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 14/39 [00:00<00:00, 66.42it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 22/39 [00:00<00:00, 68.57it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 30/39 [00:00<00:00, 71.17it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 38/39 [00:00<00:00, 72.87it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 39/39 [00:00<00:00, 71.37it/s]
2025-05-05 22:19:41,903 - easytorch-training - INFO - Result <test>: [test/time: 0.65 (s), test/loss: -0.8721, test/NLL: -0.8711, test/CRPS: 0.0577]
2025-05-05 22:19:42,043 - easytorch-training - INFO - Checkpoint checkpoints/gaussian_PatchTST/ETTh1_100_336_96/b1a7fc8ebd65fd32cc59e1587d8e4831/PatchTST_002.pt saved
2025-05-05 22:19:42,045 - easytorch-training - INFO - The estimated training finish time is 2025-05-05 22:32:01
2025-05-05 22:19:42,045 - easytorch-training - INFO - Epoch 3 / 100
  0%|          | 0/129 [00:00<?, ?it/s]  2%|‚ñè         | 2/129 [00:00<00:06, 19.29it/s]wandb: WARNING Tried to log to step 129 that is less than the current step 130. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 258 that is less than the current step 259. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
  4%|‚ñç         | 5/129 [00:00<00:05, 21.18it/s]  6%|‚ñå         | 8/129 [00:00<00:05, 22.39it/s]  9%|‚ñä         | 11/129 [00:00<00:05, 22.58it/s] 11%|‚ñà         | 14/129 [00:00<00:05, 22.90it/s] 13%|‚ñà‚ñé        | 17/129 [00:00<00:04, 23.32it/s] 16%|‚ñà‚ñå        | 20/129 [00:00<00:04, 23.51it/s] 18%|‚ñà‚ñä        | 23/129 [00:01<00:04, 23.58it/s] 20%|‚ñà‚ñà        | 26/129 [00:01<00:04, 23.78it/s] 22%|‚ñà‚ñà‚ñè       | 29/129 [00:01<00:04, 23.79it/s] 25%|‚ñà‚ñà‚ñç       | 32/129 [00:01<00:04, 23.76it/s] 27%|‚ñà‚ñà‚ñã       | 35/129 [00:01<00:03, 23.97it/s] 29%|‚ñà‚ñà‚ñâ       | 38/129 [00:01<00:03, 24.00it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 41/129 [00:01<00:03, 23.93it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 44/129 [00:01<00:03, 23.94it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 47/129 [00:02<00:03, 23.88it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 50/129 [00:02<00:03, 23.93it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 53/129 [00:02<00:03, 23.89it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 56/129 [00:02<00:03, 23.94it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 59/129 [00:02<00:02, 23.79it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 62/129 [00:02<00:02, 23.68it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 65/129 [00:02<00:02, 23.55it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 68/129 [00:02<00:02, 23.45it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 71/129 [00:03<00:02, 23.16it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 74/129 [00:03<00:02, 23.33it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 77/129 [00:03<00:02, 23.31it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 80/129 [00:03<00:02, 23.47it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 83/129 [00:03<00:01, 23.36it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 86/129 [00:03<00:01, 23.53it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 89/129 [00:03<00:01, 23.55it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 92/129 [00:03<00:01, 23.24it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 95/129 [00:04<00:01, 23.22it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 98/129 [00:04<00:01, 23.52it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 101/129 [00:04<00:01, 23.39it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 104/129 [00:04<00:01, 23.56it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 107/129 [00:04<00:00, 23.37it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 110/129 [00:04<00:00, 23.18it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 113/129 [00:04<00:00, 23.36it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 116/129 [00:04<00:00, 23.53it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 119/129 [00:05<00:00, 23.66it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 122/129 [00:05<00:00, 23.75it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 125/129 [00:05<00:00, 23.92it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 128/129 [00:05<00:00, 24.01it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 129/129 [00:05<00:00, 23.55it/s]
2025-05-05 22:19:47,528 - easytorch-training - INFO - Result <train>: [train/time: 5.48 (s), train/lr: 3.10e-03, train/loss: -0.7269, train/NLL: -0.7269, train/CRPS: 0.2055]
2025-05-05 22:19:47,530 - easytorch-training - INFO - Start validation.
  0%|          | 0/39 [00:00<?, ?it/s] 13%|‚ñà‚ñé        | 5/39 [00:00<00:00, 49.45it/s] 28%|‚ñà‚ñà‚ñä       | 11/39 [00:00<00:00, 51.89it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 17/39 [00:00<00:00, 52.33it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 23/39 [00:00<00:00, 53.12it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 29/39 [00:00<00:00, 52.86it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 35/39 [00:00<00:00, 52.75it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 39/39 [00:00<00:00, 52.82it/s]
2025-05-05 22:19:48,273 - easytorch-training - INFO - Result <val>: [val/time: 0.74 (s), val/loss: -0.4252, val/NLL: -0.4252, val/CRPS: 0.5968]
  0%|          | 0/39 [00:00<?, ?it/s] 21%|‚ñà‚ñà        | 8/39 [00:00<00:00, 72.46it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 16/39 [00:00<00:00, 72.91it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 24/39 [00:00<00:00, 73.53it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 32/39 [00:00<00:00, 73.55it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 39/39 [00:00<00:00, 73.51it/s]
2025-05-05 22:19:48,904 - easytorch-training - INFO - Result <test>: [test/time: 0.63 (s), test/loss: -0.7491, test/NLL: -0.7459, test/CRPS: 0.2402]
2025-05-05 22:19:49,039 - easytorch-training - INFO - Checkpoint checkpoints/gaussian_PatchTST/ETTh1_100_336_96/b1a7fc8ebd65fd32cc59e1587d8e4831/PatchTST_003.pt saved
2025-05-05 22:19:49,041 - easytorch-training - INFO - The estimated training finish time is 2025-05-05 22:31:42
2025-05-05 22:19:49,041 - easytorch-training - INFO - Epoch 4 / 100
  0%|          | 0/129 [00:00<?, ?it/s]  2%|‚ñè         | 3/129 [00:00<00:05, 21.54it/s]  5%|‚ñç         | 6/129 [00:00<00:05, 23.47it/s]  7%|‚ñã         | 9/129 [00:00<00:04, 24.07it/s]  9%|‚ñâ         | 12/129 [00:00<00:04, 24.33it/s] 12%|‚ñà‚ñè        | 15/129 [00:00<00:04, 24.63it/s] 14%|‚ñà‚ñç        | 18/129 [00:00<00:04, 24.65it/s] 16%|‚ñà‚ñã        | 21/129 [00:00<00:04, 24.65it/s] 19%|‚ñà‚ñä        | 24/129 [00:00<00:04, 24.70it/s] 21%|‚ñà‚ñà        | 27/129 [00:01<00:04, 24.69it/s] 23%|‚ñà‚ñà‚ñé       | 30/129 [00:01<00:03, 24.79it/s] 26%|‚ñà‚ñà‚ñå       | 33/129 [00:01<00:03, 24.89it/s] 28%|‚ñà‚ñà‚ñä       | 36/129 [00:01<00:03, 24.94it/s] 30%|‚ñà‚ñà‚ñà       | 39/129 [00:01<00:03, 24.97it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 42/129 [00:01<00:03, 24.93it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 45/129 [00:01<00:03, 25.08it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 48/129 [00:01<00:03, 25.23it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 51/129 [00:02<00:03, 25.08it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 54/129 [00:02<00:02, 25.16it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 57/129 [00:02<00:02, 25.26it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 60/129 [00:02<00:02, 25.13it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 63/129 [00:02<00:02, 25.11it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 66/129 [00:02<00:02, 24.68it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 69/129 [00:02<00:02, 24.84it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 72/129 [00:02<00:02, 24.71it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 75/129 [00:03<00:02, 24.84it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 78/129 [00:03<00:02, 24.96it/s]wandb: WARNING Tried to log to step 387 that is less than the current step 388. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 81/129 [00:03<00:01, 24.52it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 84/129 [00:03<00:01, 24.57it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 87/129 [00:03<00:01, 24.63it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 90/129 [00:03<00:01, 24.82it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 93/129 [00:03<00:01, 24.72it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 96/129 [00:03<00:01, 24.58it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 99/129 [00:04<00:01, 24.67it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 102/129 [00:04<00:01, 24.65it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 105/129 [00:04<00:00, 24.69it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 108/129 [00:04<00:00, 24.66it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 111/129 [00:04<00:00, 24.25it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 114/129 [00:04<00:00, 24.27it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 117/129 [00:04<00:00, 24.26it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 120/129 [00:04<00:00, 24.30it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 123/129 [00:04<00:00, 23.97it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 126/129 [00:05<00:00, 24.06it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 129/129 [00:05<00:00, 24.70it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 129/129 [00:05<00:00, 24.65it/s]
2025-05-05 22:19:54,280 - easytorch-training - INFO - Result <train>: [train/time: 5.24 (s), train/lr: 3.10e-03, train/loss: -0.7514, train/NLL: -0.7514, train/CRPS: 0.1638]
2025-05-05 22:19:54,282 - easytorch-training - INFO - Start validation.
  0%|          | 0/39 [00:00<?, ?it/s] 15%|‚ñà‚ñå        | 6/39 [00:00<00:00, 51.14it/s] 31%|‚ñà‚ñà‚ñà       | 12/39 [00:00<00:00, 51.31it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 18/39 [00:00<00:00, 52.09it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 24/39 [00:00<00:00, 51.70it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 30/39 [00:00<00:00, 51.73it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 36/39 [00:00<00:00, 52.76it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 39/39 [00:00<00:00, 52.63it/s]
2025-05-05 22:19:55,027 - easytorch-training - INFO - Result <val>: [val/time: 0.74 (s), val/loss: -0.6662, val/NLL: -0.6662, val/CRPS: 0.0739]
2025-05-05 22:19:55,158 - easytorch-training - INFO - Checkpoint checkpoints/gaussian_PatchTST/ETTh1_100_336_96/b1a7fc8ebd65fd32cc59e1587d8e4831/PatchTST_best_val_NLL.pt saved
  0%|          | 0/39 [00:00<?, ?it/s] 18%|‚ñà‚ñä        | 7/39 [00:00<00:00, 66.91it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 15/39 [00:00<00:00, 71.44it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 23/39 [00:00<00:00, 72.80it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 31/39 [00:00<00:00, 74.03it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 39/39 [00:00<00:00, 75.56it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 39/39 [00:00<00:00, 73.68it/s]
2025-05-05 22:19:55,796 - easytorch-training - INFO - Result <test>: [test/time: 0.64 (s), test/loss: -0.8872, test/NLL: -0.8859, test/CRPS: 0.0579]
2025-05-05 22:19:55,930 - easytorch-training - INFO - Checkpoint checkpoints/gaussian_PatchTST/ETTh1_100_336_96/b1a7fc8ebd65fd32cc59e1587d8e4831/PatchTST_004.pt saved
2025-05-05 22:19:55,933 - easytorch-training - INFO - The estimated training finish time is 2025-05-05 22:31:31
2025-05-05 22:19:55,933 - easytorch-training - INFO - Epoch 5 / 100
  0%|          | 0/129 [00:00<?, ?it/s]  2%|‚ñè         | 3/129 [00:00<00:05, 21.50it/s]  5%|‚ñç         | 6/129 [00:00<00:05, 23.31it/s]  7%|‚ñã         | 9/129 [00:00<00:05, 23.86it/s]  9%|‚ñâ         | 12/129 [00:00<00:04, 24.08it/s] 12%|‚ñà‚ñè        | 15/129 [00:00<00:04, 24.28it/s] 14%|‚ñà‚ñç        | 18/129 [00:00<00:04, 24.38it/s] 16%|‚ñà‚ñã        | 21/129 [00:00<00:04, 24.37it/s] 19%|‚ñà‚ñä        | 24/129 [00:01<00:04, 23.96it/s] 21%|‚ñà‚ñà        | 27/129 [00:01<00:04, 23.95it/s] 23%|‚ñà‚ñà‚ñé       | 30/129 [00:01<00:04, 24.31it/s] 26%|‚ñà‚ñà‚ñå       | 33/129 [00:01<00:03, 24.45it/s] 28%|‚ñà‚ñà‚ñä       | 36/129 [00:01<00:03, 24.48it/s] 30%|‚ñà‚ñà‚ñà       | 39/129 [00:01<00:03, 24.55it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 42/129 [00:01<00:03, 24.59it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 45/129 [00:01<00:03, 24.69it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 48/129 [00:01<00:03, 24.77it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 51/129 [00:02<00:03, 24.49it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 54/129 [00:02<00:03, 24.57it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 57/129 [00:02<00:02, 24.70it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 60/129 [00:02<00:02, 24.72it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 63/129 [00:02<00:02, 24.72it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 66/129 [00:02<00:02, 24.61it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 69/129 [00:02<00:02, 24.72it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 72/129 [00:02<00:02, 24.63it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 75/129 [00:03<00:02, 24.64it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 78/129 [00:03<00:02, 24.69it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 81/129 [00:03<00:01, 24.59it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 84/129 [00:03<00:01, 24.69it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 87/129 [00:03<00:01, 24.71it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 90/129 [00:03<00:01, 24.72it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 93/129 [00:03<00:01, 24.65it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 96/129 [00:03<00:01, 24.72it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 99/129 [00:04<00:01, 24.80it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 102/129 [00:04<00:01, 24.60it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 105/129 [00:04<00:00, 24.72it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 108/129 [00:04<00:00, 24.78it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 111/129 [00:04<00:00, 24.78it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 114/129 [00:04<00:00, 24.73it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 117/129 [00:04<00:00, 24.87it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 120/129 [00:04<00:00, 24.64it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 123/129 [00:05<00:00, 24.46it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 126/129 [00:05<00:00, 24.08it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 129/129 [00:05<00:00, 24.84it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 129/129 [00:05<00:00, 24.52it/s]
2025-05-05 22:20:01,198 - easytorch-training - INFO - Result <train>: [train/time: 5.26 (s), train/lr: 3.10e-03, train/loss: -0.8211, train/NLL: -0.8211, train/CRPS: 0.1118]
2025-05-05 22:20:01,200 - easytorch-training - INFO - Start validation.
  0%|          | 0/39 [00:00<?, ?it/s] 15%|‚ñà‚ñå        | 6/39 [00:00<00:00, 53.29it/s] 31%|‚ñà‚ñà‚ñà       | 12/39 [00:00<00:00, 54.08it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 18/39 [00:00<00:00, 54.41it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 24/39 [00:00<00:00, 54.94it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 30/39 [00:00<00:00, 54.80it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 36/39 [00:00<00:00, 55.01it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 39/39 [00:00<00:00, 55.08it/s]
2025-05-05 22:20:01,912 - easytorch-training - INFO - Result <val>: [val/time: 0.71 (s), val/loss: -0.7599, val/NLL: -0.7599, val/CRPS: 0.0665]
2025-05-05 22:20:02,047 - easytorch-training - INFO - Checkpoint checkpoints/gaussian_PatchTST/ETTh1_100_336_96/b1a7fc8ebd65fd32cc59e1587d8e4831/PatchTST_best_val_NLL.pt saved
  0%|          | 0/39 [00:00<?, ?it/s] 18%|‚ñà‚ñä        | 7/39 [00:00<00:00, 65.35it/s]wandb: WARNING Tried to log to step 516 that is less than the current step 517. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
 36%|‚ñà‚ñà‚ñà‚ñå      | 14/39 [00:00<00:00, 66.88it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 22/39 [00:00<00:00, 68.90it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 30/39 [00:00<00:00, 71.47it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 38/39 [00:00<00:00, 70.89it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 39/39 [00:00<00:00, 70.46it/s]
2025-05-05 22:20:02,684 - easytorch-training - INFO - Result <test>: [test/time: 0.63 (s), test/loss: -0.9917, test/NLL: -0.9901, test/CRPS: 0.0513]
2025-05-05 22:20:02,802 - easytorch-training - INFO - Checkpoint checkpoints/gaussian_PatchTST/ETTh1_100_336_96/b1a7fc8ebd65fd32cc59e1587d8e4831/PatchTST_005.pt saved
2025-05-05 22:20:02,805 - easytorch-training - INFO - The estimated training finish time is 2025-05-05 22:31:23
2025-05-05 22:20:02,805 - easytorch-training - INFO - Epoch 6 / 100
  0%|          | 0/129 [00:00<?, ?it/s]  2%|‚ñè         | 2/129 [00:00<00:06, 19.90it/s]  4%|‚ñç         | 5/129 [00:00<00:05, 22.71it/s]  6%|‚ñå         | 8/129 [00:00<00:05, 23.61it/s]  9%|‚ñä         | 11/129 [00:00<00:04, 24.02it/s] 11%|‚ñà         | 14/129 [00:00<00:04, 24.27it/s] 13%|‚ñà‚ñé        | 17/129 [00:00<00:04, 24.55it/s] 16%|‚ñà‚ñå        | 20/129 [00:00<00:04, 24.59it/s] 18%|‚ñà‚ñä        | 23/129 [00:00<00:04, 24.51it/s] 20%|‚ñà‚ñà        | 26/129 [00:01<00:04, 24.26it/s] 22%|‚ñà‚ñà‚ñè       | 29/129 [00:01<00:04, 24.11it/s] 25%|‚ñà‚ñà‚ñç       | 32/129 [00:01<00:04, 23.85it/s] 27%|‚ñà‚ñà‚ñã       | 35/129 [00:01<00:03, 23.86it/s] 29%|‚ñà‚ñà‚ñâ       | 38/129 [00:01<00:03, 23.86it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 41/129 [00:01<00:03, 23.80it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 44/129 [00:01<00:03, 24.34it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 47/129 [00:01<00:03, 24.17it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 50/129 [00:02<00:03, 24.03it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 53/129 [00:02<00:03, 23.89it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 56/129 [00:02<00:03, 23.82it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 59/129 [00:02<00:02, 23.73it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 62/129 [00:02<00:02, 23.57it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 65/129 [00:02<00:02, 23.65it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 68/129 [00:02<00:02, 23.68it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 71/129 [00:02<00:02, 23.65it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 74/129 [00:03<00:02, 23.62it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 77/129 [00:03<00:02, 23.73it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 80/129 [00:03<00:02, 23.77it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 83/129 [00:03<00:01, 23.64it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 86/129 [00:03<00:01, 23.74it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 89/129 [00:03<00:01, 23.95it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 92/129 [00:03<00:01, 23.90it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 95/129 [00:03<00:01, 23.92it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 98/129 [00:04<00:01, 23.67it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 101/129 [00:04<00:01, 23.47it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 104/129 [00:04<00:01, 23.36it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 107/129 [00:04<00:00, 23.08it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 110/129 [00:04<00:00, 23.03it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 113/129 [00:04<00:00, 22.88it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 116/129 [00:04<00:00, 22.79it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 119/129 [00:05<00:00, 23.01it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 122/129 [00:05<00:00, 22.84it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 125/129 [00:05<00:00, 23.09it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 128/129 [00:05<00:00, 23.22it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 129/129 [00:05<00:00, 23.67it/s]
2025-05-05 22:20:08,260 - easytorch-training - INFO - Result <train>: [train/time: 5.45 (s), train/lr: 3.10e-03, train/loss: -0.9371, train/NLL: -0.9371, train/CRPS: 0.0827]
2025-05-05 22:20:08,262 - easytorch-training - INFO - Start validation.
  0%|          | 0/39 [00:00<?, ?it/s] 15%|‚ñà‚ñå        | 6/39 [00:00<00:00, 50.91it/s] 31%|‚ñà‚ñà‚ñà       | 12/39 [00:00<00:00, 52.20it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 18/39 [00:00<00:00, 52.79it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 24/39 [00:00<00:00, 51.76it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 30/39 [00:00<00:00, 51.35it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 36/39 [00:00<00:00, 52.35it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 39/39 [00:00<00:00, 52.56it/s]
2025-05-05 22:20:09,008 - easytorch-training - INFO - Result <val>: [val/time: 0.74 (s), val/loss: -0.7068, val/NLL: -0.7068, val/CRPS: 0.0695]
  0%|          | 0/39 [00:00<?, ?it/s] 21%|‚ñà‚ñà        | 8/39 [00:00<00:00, 73.19it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 16/39 [00:00<00:00, 72.43it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 24/39 [00:00<00:00, 73.06it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 32/39 [00:00<00:00, 73.17it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 39/39 [00:00<00:00, 73.41it/s]
2025-05-05 22:20:09,638 - easytorch-training - INFO - Result <test>: [test/time: 0.63 (s), test/loss: -0.9179, test/NLL: -0.9147, test/CRPS: 0.0553]
2025-05-05 22:20:09,849 - easytorch-training - INFO - Checkpoint checkpoints/gaussian_PatchTST/ETTh1_100_336_96/b1a7fc8ebd65fd32cc59e1587d8e4831/PatchTST_006.pt saved
2025-05-05 22:20:09,852 - easytorch-training - INFO - The estimated training finish time is 2025-05-05 22:31:21
2025-05-05 22:20:09,852 - easytorch-training - INFO - Epoch 7 / 100
  0%|          | 0/129 [00:00<?, ?it/s]  2%|‚ñè         | 2/129 [00:00<00:06, 18.55it/s]  4%|‚ñç         | 5/129 [00:00<00:05, 21.61it/s]  6%|‚ñå         | 8/129 [00:00<00:05, 22.54it/s]  9%|‚ñä         | 11/129 [00:00<00:05, 23.04it/s] 11%|‚ñà         | 14/129 [00:00<00:04, 23.31it/s] 13%|‚ñà‚ñé        | 17/129 [00:00<00:04, 23.50it/s] 16%|‚ñà‚ñå        | 20/129 [00:00<00:04, 23.59it/s] 18%|‚ñà‚ñä        | 23/129 [00:00<00:04, 23.48it/s] 20%|‚ñà‚ñà        | 26/129 [00:01<00:04, 23.34it/s] 22%|‚ñà‚ñà‚ñè       | 29/129 [00:01<00:04, 23.63it/s] 25%|‚ñà‚ñà‚ñç       | 32/129 [00:01<00:04, 23.56it/s] 27%|‚ñà‚ñà‚ñã       | 35/129 [00:01<00:04, 23.13it/s] 29%|‚ñà‚ñà‚ñâ       | 38/129 [00:01<00:03, 23.43it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 41/129 [00:01<00:03, 23.44it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 44/129 [00:01<00:03, 23.38it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 47/129 [00:02<00:03, 23.57it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 50/129 [00:02<00:03, 23.57it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 53/129 [00:02<00:03, 23.39it/s]wandb: WARNING Tried to log to step 645 that is less than the current step 646. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 774 that is less than the current step 775. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 56/129 [00:02<00:03, 23.24it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 59/129 [00:02<00:03, 22.92it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 62/129 [00:02<00:02, 22.75it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 65/129 [00:02<00:02, 23.12it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 68/129 [00:02<00:02, 23.22it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 71/129 [00:03<00:02, 23.30it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 74/129 [00:03<00:02, 23.25it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 77/129 [00:03<00:02, 23.45it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 80/129 [00:03<00:02, 23.65it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 83/129 [00:03<00:01, 23.51it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 86/129 [00:03<00:01, 23.52it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 89/129 [00:03<00:01, 23.66it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 92/129 [00:03<00:01, 23.60it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 95/129 [00:04<00:01, 23.59it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 98/129 [00:04<00:01, 23.63it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 101/129 [00:04<00:01, 23.60it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 104/129 [00:04<00:01, 23.65it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 107/129 [00:04<00:00, 23.76it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 110/129 [00:04<00:00, 23.78it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 113/129 [00:04<00:00, 23.64it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 116/129 [00:04<00:00, 23.69it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 119/129 [00:05<00:00, 24.27it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 122/129 [00:05<00:00, 23.92it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 125/129 [00:05<00:00, 23.75it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 128/129 [00:05<00:00, 23.83it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 129/129 [00:05<00:00, 23.48it/s]
2025-05-05 22:20:15,352 - easytorch-training - INFO - Result <train>: [train/time: 5.50 (s), train/lr: 3.10e-03, train/loss: -0.9727, train/NLL: -0.9727, train/CRPS: 0.0694]
2025-05-05 22:20:15,355 - easytorch-training - INFO - Start validation.
  0%|          | 0/39 [00:00<?, ?it/s] 15%|‚ñà‚ñå        | 6/39 [00:00<00:00, 52.42it/s] 31%|‚ñà‚ñà‚ñà       | 12/39 [00:00<00:00, 53.46it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 18/39 [00:00<00:00, 53.10it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 24/39 [00:00<00:00, 52.59it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 30/39 [00:00<00:00, 52.53it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 36/39 [00:00<00:00, 53.26it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 39/39 [00:00<00:00, 53.36it/s]
2025-05-05 22:20:16,090 - easytorch-training - INFO - Result <val>: [val/time: 0.73 (s), val/loss: -0.7227, val/NLL: -0.7227, val/CRPS: 0.0895]
  0%|          | 0/39 [00:00<?, ?it/s] 21%|‚ñà‚ñà        | 8/39 [00:00<00:00, 70.80it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 16/39 [00:00<00:00, 71.15it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 24/39 [00:00<00:00, 71.62it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 32/39 [00:00<00:00, 72.39it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 39/39 [00:00<00:00, 72.55it/s]
2025-05-05 22:20:16,732 - easytorch-training - INFO - Result <test>: [test/time: 0.64 (s), test/loss: -0.9994, test/NLL: -0.9966, test/CRPS: 0.0520]
2025-05-05 22:20:16,868 - easytorch-training - INFO - Checkpoint checkpoints/gaussian_PatchTST/ETTh1_100_336_96/b1a7fc8ebd65fd32cc59e1587d8e4831/PatchTST_007.pt saved
2025-05-05 22:20:16,870 - easytorch-training - INFO - The estimated training finish time is 2025-05-05 22:31:19
2025-05-05 22:20:16,870 - easytorch-training - INFO - Epoch 8 / 100
  0%|          | 0/129 [00:00<?, ?it/s]  2%|‚ñè         | 2/129 [00:00<00:06, 18.77it/s]  4%|‚ñç         | 5/129 [00:00<00:05, 21.66it/s]  6%|‚ñå         | 8/129 [00:00<00:05, 22.95it/s]  9%|‚ñä         | 11/129 [00:00<00:05, 23.50it/s] 11%|‚ñà         | 14/129 [00:00<00:04, 23.85it/s] 13%|‚ñà‚ñé        | 17/129 [00:00<00:04, 23.76it/s] 16%|‚ñà‚ñå        | 20/129 [00:00<00:04, 24.00it/s] 18%|‚ñà‚ñä        | 23/129 [00:00<00:04, 24.15it/s] 20%|‚ñà‚ñà        | 26/129 [00:01<00:04, 24.48it/s] 22%|‚ñà‚ñà‚ñè       | 29/129 [00:01<00:04, 24.78it/s] 25%|‚ñà‚ñà‚ñç       | 32/129 [00:01<00:03, 24.61it/s] 27%|‚ñà‚ñà‚ñã       | 35/129 [00:01<00:03, 24.75it/s] 29%|‚ñà‚ñà‚ñâ       | 38/129 [00:01<00:03, 24.90it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 41/129 [00:01<00:03, 24.81it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 44/129 [00:01<00:03, 24.97it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 47/129 [00:01<00:03, 25.09it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 50/129 [00:02<00:03, 25.06it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 53/129 [00:02<00:03, 24.89it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 56/129 [00:02<00:02, 25.05it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 59/129 [00:02<00:02, 25.06it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 62/129 [00:02<00:02, 24.91it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 65/129 [00:02<00:02, 24.97it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 68/129 [00:02<00:02, 25.00it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 71/129 [00:02<00:02, 24.92it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 74/129 [00:03<00:02, 24.91it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 77/129 [00:03<00:02, 25.77it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 80/129 [00:03<00:01, 26.40it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 83/129 [00:03<00:01, 25.87it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 86/129 [00:03<00:01, 25.64it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 89/129 [00:03<00:01, 25.54it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 92/129 [00:03<00:01, 25.20it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 95/129 [00:03<00:01, 25.28it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 98/129 [00:03<00:01, 25.34it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 101/129 [00:04<00:01, 25.12it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 104/129 [00:04<00:00, 25.26it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 107/129 [00:04<00:00, 25.41it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 110/129 [00:04<00:00, 25.36it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 113/129 [00:04<00:00, 25.09it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 116/129 [00:04<00:00, 24.74it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 119/129 [00:04<00:00, 24.95it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 122/129 [00:04<00:00, 24.90it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 125/129 [00:05<00:00, 25.00it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 128/129 [00:05<00:00, 25.15it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 129/129 [00:05<00:00, 24.90it/s]
2025-05-05 22:20:22,058 - easytorch-training - INFO - Result <train>: [train/time: 5.19 (s), train/lr: 3.10e-03, train/loss: -1.0061, train/NLL: -1.0061, train/CRPS: 0.0593]
2025-05-05 22:20:22,060 - easytorch-training - INFO - Start validation.
  0%|          | 0/39 [00:00<?, ?it/s] 15%|‚ñà‚ñå        | 6/39 [00:00<00:00, 53.12it/s]wandb: WARNING Tried to log to step 903 that is less than the current step 904. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
 31%|‚ñà‚ñà‚ñà       | 12/39 [00:00<00:00, 53.93it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 18/39 [00:00<00:00, 54.81it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 24/39 [00:00<00:00, 55.18it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 30/39 [00:00<00:00, 52.81it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 36/39 [00:00<00:00, 51.01it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 39/39 [00:00<00:00, 52.76it/s]
2025-05-05 22:20:22,806 - easytorch-training - INFO - Result <val>: [val/time: 0.74 (s), val/loss: -0.6968, val/NLL: -0.6968, val/CRPS: 0.0684]
  0%|          | 0/39 [00:00<?, ?it/s] 21%|‚ñà‚ñà        | 8/39 [00:00<00:00, 71.57it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 16/39 [00:00<00:00, 72.68it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 24/39 [00:00<00:00, 73.19it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 32/39 [00:00<00:00, 73.68it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 39/39 [00:00<00:00, 73.89it/s]
2025-05-05 22:20:23,443 - easytorch-training - INFO - Result <test>: [test/time: 0.63 (s), test/loss: -0.8780, test/NLL: -0.8793, test/CRPS: 0.0555]
2025-05-05 22:20:23,574 - easytorch-training - INFO - Checkpoint checkpoints/gaussian_PatchTST/ETTh1_100_336_96/b1a7fc8ebd65fd32cc59e1587d8e4831/PatchTST_008.pt saved
2025-05-05 22:20:23,577 - easytorch-training - INFO - The estimated training finish time is 2025-05-05 22:31:14
2025-05-05 22:20:23,577 - easytorch-training - INFO - Epoch 9 / 100
  0%|          | 0/129 [00:00<?, ?it/s]  2%|‚ñè         | 3/129 [00:00<00:05, 21.56it/s]  5%|‚ñç         | 6/129 [00:00<00:05, 23.29it/s]  7%|‚ñã         | 9/129 [00:00<00:05, 23.74it/s]  9%|‚ñâ         | 12/129 [00:00<00:04, 23.97it/s] 12%|‚ñà‚ñè        | 15/129 [00:00<00:04, 24.05it/s] 14%|‚ñà‚ñç        | 18/129 [00:00<00:04, 24.39it/s] 16%|‚ñà‚ñã        | 21/129 [00:00<00:04, 24.31it/s] 19%|‚ñà‚ñä        | 24/129 [00:00<00:04, 24.40it/s] 21%|‚ñà‚ñà        | 27/129 [00:01<00:04, 24.70it/s] 23%|‚ñà‚ñà‚ñé       | 30/129 [00:01<00:04, 24.60it/s] 26%|‚ñà‚ñà‚ñå       | 33/129 [00:01<00:03, 24.51it/s] 28%|‚ñà‚ñà‚ñä       | 36/129 [00:01<00:03, 24.70it/s] 30%|‚ñà‚ñà‚ñà       | 39/129 [00:01<00:03, 24.75it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 42/129 [00:01<00:03, 24.57it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 45/129 [00:01<00:03, 24.66it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 48/129 [00:01<00:03, 24.62it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 51/129 [00:02<00:03, 24.42it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 54/129 [00:02<00:03, 24.51it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 57/129 [00:02<00:02, 24.63it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 60/129 [00:02<00:02, 24.73it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 63/129 [00:02<00:02, 24.68it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 66/129 [00:02<00:02, 24.83it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 69/129 [00:02<00:02, 24.93it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 72/129 [00:02<00:02, 24.83it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 75/129 [00:03<00:02, 25.01it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 78/129 [00:03<00:02, 24.93it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 81/129 [00:03<00:01, 24.92it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 84/129 [00:03<00:01, 24.72it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 87/129 [00:03<00:01, 24.87it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 90/129 [00:03<00:01, 24.84it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 93/129 [00:03<00:01, 24.63it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 96/129 [00:03<00:01, 24.68it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 99/129 [00:04<00:01, 24.71it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 102/129 [00:04<00:01, 24.49it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 105/129 [00:04<00:00, 24.27it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 108/129 [00:04<00:00, 24.26it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 111/129 [00:04<00:00, 24.26it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 114/129 [00:04<00:00, 24.41it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 117/129 [00:04<00:00, 24.49it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 120/129 [00:04<00:00, 24.58it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 123/129 [00:05<00:00, 24.35it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 126/129 [00:05<00:00, 24.37it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 129/129 [00:05<00:00, 25.15it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 129/129 [00:05<00:00, 24.56it/s]
2025-05-05 22:20:28,834 - easytorch-training - INFO - Result <train>: [train/time: 5.26 (s), train/lr: 3.10e-03, train/loss: -1.0205, train/NLL: -1.0205, train/CRPS: 0.0541]
2025-05-05 22:20:28,836 - easytorch-training - INFO - Start validation.
  0%|          | 0/39 [00:00<?, ?it/s] 15%|‚ñà‚ñå        | 6/39 [00:00<00:00, 52.13it/s] 31%|‚ñà‚ñà‚ñà       | 12/39 [00:00<00:00, 52.10it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 18/39 [00:00<00:00, 52.52it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 24/39 [00:00<00:00, 52.50it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 30/39 [00:00<00:00, 52.69it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 36/39 [00:00<00:00, 53.05it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 39/39 [00:00<00:00, 53.14it/s]
2025-05-05 22:20:29,574 - easytorch-training - INFO - Result <val>: [val/time: 0.74 (s), val/loss: -0.7570, val/NLL: -0.7570, val/CRPS: 0.0662]
  0%|          | 0/39 [00:00<?, ?it/s] 21%|‚ñà‚ñà        | 8/39 [00:00<00:00, 70.64it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 16/39 [00:00<00:00, 72.87it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 24/39 [00:00<00:00, 73.69it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 32/39 [00:00<00:00, 74.08it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 39/39 [00:00<00:00, 74.13it/s]
2025-05-05 22:20:30,195 - easytorch-training - INFO - Result <test>: [test/time: 0.62 (s), test/loss: -0.9425, test/NLL: -0.9424, test/CRPS: 0.0579]
2025-05-05 22:20:30,402 - easytorch-training - INFO - Checkpoint checkpoints/gaussian_PatchTST/ETTh1_100_336_96/b1a7fc8ebd65fd32cc59e1587d8e4831/PatchTST_009.pt saved
2025-05-05 22:20:30,404 - easytorch-training - INFO - The estimated training finish time is 2025-05-05 22:31:11
2025-05-05 22:20:30,404 - easytorch-training - INFO - Epoch 10 / 100
  0%|          | 0/129 [00:00<?, ?it/s]  2%|‚ñè         | 3/129 [00:00<00:05, 21.54it/s]  5%|‚ñç         | 6/129 [00:00<00:05, 23.35it/s]  7%|‚ñã         | 9/129 [00:00<00:04, 24.02it/s]  9%|‚ñâ         | 12/129 [00:00<00:04, 24.30it/s] 12%|‚ñà‚ñè        | 15/129 [00:00<00:04, 24.55it/s] 14%|‚ñà‚ñç        | 18/129 [00:00<00:04, 24.68it/s] 16%|‚ñà‚ñã        | 21/129 [00:00<00:04, 24.63it/s] 19%|‚ñà‚ñä        | 24/129 [00:00<00:04, 24.75it/s] 21%|‚ñà‚ñà        | 27/129 [00:01<00:04, 24.71it/s] 23%|‚ñà‚ñà‚ñé       | 30/129 [00:01<00:04, 24.68it/s] 26%|‚ñà‚ñà‚ñå       | 33/129 [00:01<00:03, 24.09it/s] 28%|‚ñà‚ñà‚ñä       | 36/129 [00:01<00:03, 24.27it/s] 30%|‚ñà‚ñà‚ñà       | 39/129 [00:01<00:03, 24.52it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 42/129 [00:01<00:03, 24.49it/s]wandb: WARNING Tried to log to step 1032 that is less than the current step 1033. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 1161 that is less than the current step 1162. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
 35%|‚ñà‚ñà‚ñà‚ñç      | 45/129 [00:01<00:03, 24.35it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 48/129 [00:01<00:03, 24.03it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 51/129 [00:02<00:03, 24.00it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 54/129 [00:02<00:03, 24.13it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 57/129 [00:02<00:02, 24.35it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 60/129 [00:02<00:02, 24.49it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 63/129 [00:02<00:02, 23.94it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 66/129 [00:02<00:02, 23.92it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 69/129 [00:02<00:02, 24.22it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 72/129 [00:02<00:02, 24.21it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 75/129 [00:03<00:02, 24.44it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 78/129 [00:03<00:02, 24.53it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 81/129 [00:03<00:01, 24.53it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 84/129 [00:03<00:01, 24.59it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 87/129 [00:03<00:01, 24.69it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 90/129 [00:03<00:01, 24.72it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 93/129 [00:03<00:01, 24.55it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 96/129 [00:03<00:01, 24.36it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 99/129 [00:04<00:01, 24.46it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 102/129 [00:04<00:01, 24.41it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 105/129 [00:04<00:00, 24.53it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 108/129 [00:04<00:00, 24.53it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 111/129 [00:04<00:00, 24.33it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 114/129 [00:04<00:00, 24.54it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 117/129 [00:04<00:00, 24.58it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 120/129 [00:04<00:00, 24.82it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 123/129 [00:05<00:00, 25.09it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 126/129 [00:05<00:00, 24.81it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 129/129 [00:05<00:00, 25.30it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 129/129 [00:05<00:00, 24.46it/s]
2025-05-05 22:20:35,683 - easytorch-training - INFO - Result <train>: [train/time: 5.28 (s), train/lr: 3.10e-03, train/loss: -1.0670, train/NLL: -1.0670, train/CRPS: 0.0491]
2025-05-05 22:20:35,686 - easytorch-training - INFO - Start validation.
  0%|          | 0/39 [00:00<?, ?it/s] 15%|‚ñà‚ñå        | 6/39 [00:00<00:00, 52.41it/s] 31%|‚ñà‚ñà‚ñà       | 12/39 [00:00<00:00, 52.98it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 18/39 [00:00<00:00, 53.08it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 24/39 [00:00<00:00, 53.19it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 30/39 [00:00<00:00, 53.00it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 36/39 [00:00<00:00, 53.01it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 39/39 [00:00<00:00, 53.29it/s]
2025-05-05 22:20:36,422 - easytorch-training - INFO - Result <val>: [val/time: 0.73 (s), val/loss: -0.7981, val/NLL: -0.7981, val/CRPS: 0.0644]
2025-05-05 22:20:36,557 - easytorch-training - INFO - Checkpoint checkpoints/gaussian_PatchTST/ETTh1_100_336_96/b1a7fc8ebd65fd32cc59e1587d8e4831/PatchTST_best_val_NLL.pt saved
  0%|          | 0/39 [00:00<?, ?it/s] 18%|‚ñà‚ñä        | 7/39 [00:00<00:00, 64.36it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 15/39 [00:00<00:00, 68.93it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 23/39 [00:00<00:00, 69.70it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 30/39 [00:00<00:00, 69.61it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 38/39 [00:00<00:00, 70.33it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 39/39 [00:00<00:00, 70.04it/s]
2025-05-05 22:20:37,219 - easytorch-training - INFO - Result <test>: [test/time: 0.66 (s), test/loss: -1.0784, test/NLL: -1.0753, test/CRPS: 0.0481]
2025-05-05 22:20:37,347 - easytorch-training - INFO - Checkpoint checkpoints/gaussian_PatchTST/ETTh1_100_336_96/b1a7fc8ebd65fd32cc59e1587d8e4831/PatchTST_010.pt saved
2025-05-05 22:20:37,356 - easytorch-training - INFO - The estimated training finish time is 2025-05-05 22:31:10
2025-05-05 22:20:37,356 - easytorch-training - INFO - Epoch 11 / 100
  0%|          | 0/129 [00:00<?, ?it/s]  2%|‚ñè         | 3/129 [00:00<00:05, 21.69it/s]  5%|‚ñç         | 6/129 [00:00<00:05, 23.56it/s]  7%|‚ñã         | 9/129 [00:00<00:04, 24.06it/s]  9%|‚ñâ         | 12/129 [00:00<00:04, 24.25it/s] 12%|‚ñà‚ñè        | 15/129 [00:00<00:04, 24.49it/s] 14%|‚ñà‚ñç        | 18/129 [00:00<00:04, 24.72it/s] 16%|‚ñà‚ñã        | 21/129 [00:00<00:04, 24.19it/s] 19%|‚ñà‚ñä        | 24/129 [00:00<00:04, 24.05it/s] 21%|‚ñà‚ñà        | 27/129 [00:01<00:04, 24.44it/s] 23%|‚ñà‚ñà‚ñé       | 30/129 [00:01<00:04, 24.51it/s] 26%|‚ñà‚ñà‚ñå       | 33/129 [00:01<00:03, 24.42it/s] 28%|‚ñà‚ñà‚ñä       | 36/129 [00:01<00:03, 24.53it/s] 30%|‚ñà‚ñà‚ñà       | 39/129 [00:01<00:03, 24.71it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 42/129 [00:01<00:03, 24.70it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 45/129 [00:01<00:03, 24.66it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 48/129 [00:01<00:03, 24.68it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 51/129 [00:02<00:03, 24.63it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 54/129 [00:02<00:03, 24.64it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 57/129 [00:02<00:02, 24.66it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 60/129 [00:02<00:02, 24.84it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 63/129 [00:02<00:02, 24.59it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 66/129 [00:02<00:02, 24.45it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 69/129 [00:02<00:02, 24.52it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 72/129 [00:02<00:02, 24.46it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 75/129 [00:03<00:02, 24.63it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 78/129 [00:03<00:02, 24.63it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 81/129 [00:03<00:01, 24.48it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 84/129 [00:03<00:01, 24.39it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 87/129 [00:03<00:01, 24.26it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 90/129 [00:03<00:01, 24.32it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 93/129 [00:03<00:01, 24.30it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 96/129 [00:03<00:01, 24.42it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 99/129 [00:04<00:01, 24.38it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 102/129 [00:04<00:01, 24.42it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 105/129 [00:04<00:00, 24.41it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 108/129 [00:04<00:00, 24.46it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 111/129 [00:04<00:00, 24.30it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 114/129 [00:04<00:00, 23.44it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 117/129 [00:04<00:00, 23.55it/s]wandb: WARNING Tried to log to step 1290 that is less than the current step 1291. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 120/129 [00:04<00:00, 23.66it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 123/129 [00:05<00:00, 23.64it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 126/129 [00:05<00:00, 23.98it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 129/129 [00:05<00:00, 24.67it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 129/129 [00:05<00:00, 24.35it/s]
2025-05-05 22:20:42,660 - easytorch-training - INFO - Result <train>: [train/time: 5.30 (s), train/lr: 3.10e-03, train/loss: -1.0672, train/NLL: -1.0672, train/CRPS: 0.0475]
2025-05-05 22:20:42,662 - easytorch-training - INFO - Start validation.
  0%|          | 0/39 [00:00<?, ?it/s] 15%|‚ñà‚ñå        | 6/39 [00:00<00:00, 52.73it/s] 31%|‚ñà‚ñà‚ñà       | 12/39 [00:00<00:00, 53.03it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 18/39 [00:00<00:00, 53.02it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 24/39 [00:00<00:00, 53.03it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 30/39 [00:00<00:00, 53.69it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 36/39 [00:00<00:00, 52.39it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 39/39 [00:00<00:00, 53.10it/s]
2025-05-05 22:20:43,400 - easytorch-training - INFO - Result <val>: [val/time: 0.74 (s), val/loss: -0.7943, val/NLL: -0.7943, val/CRPS: 0.0649]
  0%|          | 0/39 [00:00<?, ?it/s] 18%|‚ñà‚ñä        | 7/39 [00:00<00:00, 68.48it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 15/39 [00:00<00:00, 72.25it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 23/39 [00:00<00:00, 73.40it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 31/39 [00:00<00:00, 74.57it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 39/39 [00:00<00:00, 75.69it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 39/39 [00:00<00:00, 74.12it/s]
2025-05-05 22:20:44,025 - easytorch-training - INFO - Result <test>: [test/time: 0.62 (s), test/loss: -1.0559, test/NLL: -1.0550, test/CRPS: 0.0490]
2025-05-05 22:20:44,162 - easytorch-training - INFO - Checkpoint checkpoints/gaussian_PatchTST/ETTh1_100_336_96/b1a7fc8ebd65fd32cc59e1587d8e4831/PatchTST_011.pt saved
2025-05-05 22:20:44,165 - easytorch-training - INFO - The estimated training finish time is 2025-05-05 22:31:08
2025-05-05 22:20:44,165 - easytorch-training - INFO - Epoch 12 / 100
  0%|          | 0/129 [00:00<?, ?it/s]  2%|‚ñè         | 2/129 [00:00<00:06, 18.39it/s]  4%|‚ñç         | 5/129 [00:00<00:05, 21.36it/s]  6%|‚ñå         | 8/129 [00:00<00:05, 22.47it/s]  9%|‚ñä         | 11/129 [00:00<00:05, 22.65it/s] 11%|‚ñà         | 14/129 [00:00<00:04, 23.15it/s] 13%|‚ñà‚ñé        | 17/129 [00:00<00:04, 23.36it/s] 16%|‚ñà‚ñå        | 20/129 [00:00<00:04, 23.61it/s] 18%|‚ñà‚ñä        | 23/129 [00:01<00:04, 23.43it/s] 20%|‚ñà‚ñà        | 26/129 [00:01<00:04, 23.60it/s] 22%|‚ñà‚ñà‚ñè       | 29/129 [00:01<00:04, 23.70it/s] 25%|‚ñà‚ñà‚ñç       | 32/129 [00:01<00:04, 23.63it/s] 27%|‚ñà‚ñà‚ñã       | 35/129 [00:01<00:03, 23.60it/s] 29%|‚ñà‚ñà‚ñâ       | 38/129 [00:01<00:03, 23.71it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 41/129 [00:01<00:03, 23.54it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 44/129 [00:01<00:03, 23.93it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 47/129 [00:02<00:03, 24.23it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 50/129 [00:02<00:03, 24.38it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 53/129 [00:02<00:03, 24.38it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 56/129 [00:02<00:02, 24.56it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 59/129 [00:02<00:02, 24.59it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 62/129 [00:02<00:02, 24.62it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 65/129 [00:02<00:02, 24.69it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 68/129 [00:02<00:02, 24.71it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 71/129 [00:02<00:02, 24.59it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 74/129 [00:03<00:02, 24.66it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 77/129 [00:03<00:02, 24.78it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 80/129 [00:03<00:01, 24.70it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 83/129 [00:03<00:01, 24.66it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 86/129 [00:03<00:01, 24.75it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 89/129 [00:03<00:01, 24.68it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 92/129 [00:03<00:01, 24.69it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 95/129 [00:03<00:01, 24.66it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 98/129 [00:04<00:01, 24.77it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 101/129 [00:04<00:01, 24.73it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 104/129 [00:04<00:01, 24.35it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 107/129 [00:04<00:00, 24.29it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 110/129 [00:04<00:00, 24.49it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 113/129 [00:04<00:00, 24.61it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 116/129 [00:04<00:00, 24.83it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 119/129 [00:04<00:00, 24.90it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 122/129 [00:05<00:00, 24.91it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 125/129 [00:05<00:00, 24.88it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 128/129 [00:05<00:00, 24.94it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 129/129 [00:05<00:00, 24.27it/s]
2025-05-05 22:20:49,486 - easytorch-training - INFO - Result <train>: [train/time: 5.32 (s), train/lr: 3.10e-03, train/loss: -1.0850, train/NLL: -1.0850, train/CRPS: 0.0465]
2025-05-05 22:20:49,488 - easytorch-training - INFO - Start validation.
  0%|          | 0/39 [00:00<?, ?it/s] 15%|‚ñà‚ñå        | 6/39 [00:00<00:00, 53.21it/s] 31%|‚ñà‚ñà‚ñà       | 12/39 [00:00<00:00, 53.77it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 18/39 [00:00<00:00, 53.39it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 24/39 [00:00<00:00, 53.48it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 30/39 [00:00<00:00, 53.62it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 36/39 [00:00<00:00, 53.75it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 39/39 [00:00<00:00, 54.00it/s]
2025-05-05 22:20:50,214 - easytorch-training - INFO - Result <val>: [val/time: 0.72 (s), val/loss: -0.7231, val/NLL: -0.7231, val/CRPS: 0.0685]
  0%|          | 0/39 [00:00<?, ?it/s] 21%|‚ñà‚ñà        | 8/39 [00:00<00:00, 71.99it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 16/39 [00:00<00:00, 73.09it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 24/39 [00:00<00:00, 73.45it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 32/39 [00:00<00:00, 74.06it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 39/39 [00:00<00:00, 75.17it/s]
2025-05-05 22:20:50,840 - easytorch-training - INFO - Result <test>: [test/time: 0.62 (s), test/loss: -0.9727, test/NLL: -0.9687, test/CRPS: 0.0533]
2025-05-05 22:20:50,973 - easytorch-training - INFO - Checkpoint checkpoints/gaussian_PatchTST/ETTh1_100_336_96/b1a7fc8ebd65fd32cc59e1587d8e4831/PatchTST_012.pt saved
2025-05-05 22:20:50,975 - easytorch-training - INFO - The estimated training finish time is 2025-05-05 22:31:07
2025-05-05 22:20:50,976 - easytorch-training - INFO - Epoch 13 / 100
  0%|          | 0/129 [00:00<?, ?it/s]  2%|‚ñè         | 2/129 [00:00<00:06, 18.83it/s]  4%|‚ñç         | 5/129 [00:00<00:05, 21.08it/s]  6%|‚ñå         | 8/129 [00:00<00:05, 22.58it/s]  9%|‚ñä         | 11/129 [00:00<00:05, 23.40it/s] 11%|‚ñà         | 14/129 [00:00<00:04, 24.02it/s] 13%|‚ñà‚ñé        | 17/129 [00:00<00:04, 24.46it/s] 16%|‚ñà‚ñå        | 20/129 [00:00<00:04, 24.53it/s] 18%|‚ñà‚ñä        | 23/129 [00:00<00:04, 24.50it/s] 20%|‚ñà‚ñà        | 26/129 [00:01<00:04, 24.69it/s] 22%|‚ñà‚ñà‚ñè       | 29/129 [00:01<00:04, 24.67it/s]wandb: WARNING Tried to log to step 1419 that is less than the current step 1420. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 1548 that is less than the current step 1549. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
 25%|‚ñà‚ñà‚ñç       | 32/129 [00:01<00:04, 23.70it/s] 27%|‚ñà‚ñà‚ñã       | 35/129 [00:01<00:03, 24.04it/s] 29%|‚ñà‚ñà‚ñâ       | 38/129 [00:01<00:03, 24.11it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 41/129 [00:01<00:03, 24.19it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 44/129 [00:01<00:03, 24.36it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 47/129 [00:01<00:03, 24.55it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 50/129 [00:02<00:03, 24.72it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 53/129 [00:02<00:03, 24.70it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 56/129 [00:02<00:02, 24.81it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 59/129 [00:02<00:02, 24.96it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 62/129 [00:02<00:02, 24.88it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 65/129 [00:02<00:02, 24.40it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 68/129 [00:02<00:02, 24.47it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 71/129 [00:02<00:02, 24.50it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 74/129 [00:03<00:02, 24.70it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 77/129 [00:03<00:02, 24.77it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 80/129 [00:03<00:01, 24.78it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 83/129 [00:03<00:01, 24.68it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 86/129 [00:03<00:01, 24.81it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 89/129 [00:03<00:01, 24.85it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 92/129 [00:03<00:01, 24.83it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 95/129 [00:03<00:01, 24.87it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 98/129 [00:04<00:01, 24.91it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 101/129 [00:04<00:01, 24.83it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 104/129 [00:04<00:01, 24.88it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 107/129 [00:04<00:00, 24.85it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 110/129 [00:04<00:00, 24.92it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 113/129 [00:04<00:00, 24.69it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 116/129 [00:04<00:00, 24.77it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 119/129 [00:04<00:00, 25.38it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 122/129 [00:04<00:00, 25.45it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 125/129 [00:05<00:00, 25.18it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 128/129 [00:05<00:00, 25.20it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 129/129 [00:05<00:00, 24.60it/s]
2025-05-05 22:20:56,223 - easytorch-training - INFO - Result <train>: [train/time: 5.25 (s), train/lr: 3.10e-03, train/loss: -1.0939, train/NLL: -1.0939, train/CRPS: 0.0462]
2025-05-05 22:20:56,226 - easytorch-training - INFO - Start validation.
  0%|          | 0/39 [00:00<?, ?it/s] 15%|‚ñà‚ñå        | 6/39 [00:00<00:00, 51.56it/s] 31%|‚ñà‚ñà‚ñà       | 12/39 [00:00<00:00, 52.33it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 18/39 [00:00<00:00, 52.94it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 24/39 [00:00<00:00, 52.81it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 30/39 [00:00<00:00, 52.79it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 36/39 [00:00<00:00, 52.65it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 39/39 [00:00<00:00, 52.87it/s]
2025-05-05 22:20:56,967 - easytorch-training - INFO - Result <val>: [val/time: 0.74 (s), val/loss: -0.8225, val/NLL: -0.8225, val/CRPS: 0.0643]
2025-05-05 22:20:57,101 - easytorch-training - INFO - Checkpoint checkpoints/gaussian_PatchTST/ETTh1_100_336_96/b1a7fc8ebd65fd32cc59e1587d8e4831/PatchTST_best_val_NLL.pt saved
  0%|          | 0/39 [00:00<?, ?it/s] 18%|‚ñà‚ñä        | 7/39 [00:00<00:00, 64.87it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 15/39 [00:00<00:00, 69.90it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 23/39 [00:00<00:00, 72.04it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 31/39 [00:00<00:00, 72.58it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 39/39 [00:00<00:00, 74.82it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 39/39 [00:00<00:00, 72.67it/s]
2025-05-05 22:20:57,737 - easytorch-training - INFO - Result <test>: [test/time: 0.63 (s), test/loss: -1.1451, test/NLL: -1.1432, test/CRPS: 0.0456]
2025-05-05 22:20:57,867 - easytorch-training - INFO - Checkpoint checkpoints/gaussian_PatchTST/ETTh1_100_336_96/b1a7fc8ebd65fd32cc59e1587d8e4831/PatchTST_013.pt saved
2025-05-05 22:20:57,870 - easytorch-training - INFO - The estimated training finish time is 2025-05-05 22:31:06
2025-05-05 22:20:57,870 - easytorch-training - INFO - Epoch 14 / 100
  0%|          | 0/129 [00:00<?, ?it/s]  2%|‚ñè         | 3/129 [00:00<00:05, 22.18it/s]  5%|‚ñç         | 6/129 [00:00<00:05, 23.64it/s]  7%|‚ñã         | 9/129 [00:00<00:04, 24.38it/s]  9%|‚ñâ         | 12/129 [00:00<00:04, 24.47it/s] 12%|‚ñà‚ñè        | 15/129 [00:00<00:04, 24.50it/s] 14%|‚ñà‚ñç        | 18/129 [00:00<00:04, 24.58it/s] 16%|‚ñà‚ñã        | 21/129 [00:00<00:04, 24.34it/s] 19%|‚ñà‚ñä        | 24/129 [00:00<00:04, 24.33it/s] 21%|‚ñà‚ñà        | 27/129 [00:01<00:04, 24.63it/s] 23%|‚ñà‚ñà‚ñé       | 30/129 [00:01<00:04, 24.71it/s] 26%|‚ñà‚ñà‚ñå       | 33/129 [00:01<00:03, 24.69it/s] 28%|‚ñà‚ñà‚ñä       | 36/129 [00:01<00:03, 24.78it/s] 30%|‚ñà‚ñà‚ñà       | 39/129 [00:01<00:03, 24.62it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 42/129 [00:01<00:03, 24.69it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 45/129 [00:01<00:03, 24.74it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 48/129 [00:01<00:03, 24.94it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 51/129 [00:02<00:03, 24.73it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 54/129 [00:02<00:03, 24.73it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 57/129 [00:02<00:02, 24.85it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 60/129 [00:02<00:02, 24.95it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 63/129 [00:02<00:02, 24.67it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 66/129 [00:02<00:02, 24.90it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 69/129 [00:02<00:02, 25.01it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 72/129 [00:02<00:02, 24.76it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 75/129 [00:03<00:02, 24.95it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 78/129 [00:03<00:01, 25.58it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 81/129 [00:03<00:01, 25.43it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 84/129 [00:03<00:01, 25.34it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 87/129 [00:03<00:01, 25.15it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 90/129 [00:03<00:01, 24.97it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 93/129 [00:03<00:01, 24.78it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 96/129 [00:03<00:01, 24.78it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 99/129 [00:03<00:01, 24.84it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 102/129 [00:04<00:01, 24.71it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 105/129 [00:04<00:00, 24.93it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 108/129 [00:04<00:00, 25.11it/s]wandb: WARNING Tried to log to step 1677 that is less than the current step 1678. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 111/129 [00:04<00:00, 24.45it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 114/129 [00:04<00:00, 24.06it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 117/129 [00:04<00:00, 24.17it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 120/129 [00:04<00:00, 24.17it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 123/129 [00:04<00:00, 24.11it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 126/129 [00:05<00:00, 24.40it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 129/129 [00:05<00:00, 25.22it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 129/129 [00:05<00:00, 24.72it/s]
2025-05-05 22:21:03,094 - easytorch-training - INFO - Result <train>: [train/time: 5.22 (s), train/lr: 3.10e-03, train/loss: -1.0880, train/NLL: -1.0880, train/CRPS: 0.0464]
2025-05-05 22:21:03,096 - easytorch-training - INFO - Start validation.
  0%|          | 0/39 [00:00<?, ?it/s] 15%|‚ñà‚ñå        | 6/39 [00:00<00:00, 53.21it/s] 31%|‚ñà‚ñà‚ñà       | 12/39 [00:00<00:00, 53.84it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 18/39 [00:00<00:00, 53.68it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 24/39 [00:00<00:00, 53.42it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 30/39 [00:00<00:00, 53.02it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 36/39 [00:00<00:00, 52.85it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 39/39 [00:00<00:00, 53.40it/s]
2025-05-05 22:21:03,830 - easytorch-training - INFO - Result <val>: [val/time: 0.73 (s), val/loss: -0.7890, val/NLL: -0.7890, val/CRPS: 0.0652]
  0%|          | 0/39 [00:00<?, ?it/s] 21%|‚ñà‚ñà        | 8/39 [00:00<00:00, 71.72it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 16/39 [00:00<00:00, 73.19it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 24/39 [00:00<00:00, 73.94it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 32/39 [00:00<00:00, 74.59it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 39/39 [00:00<00:00, 74.38it/s]
2025-05-05 22:21:04,445 - easytorch-training - INFO - Result <test>: [test/time: 0.61 (s), test/loss: -1.1166, test/NLL: -1.1165, test/CRPS: 0.0465]
2025-05-05 22:21:04,585 - easytorch-training - INFO - Checkpoint checkpoints/gaussian_PatchTST/ETTh1_100_336_96/b1a7fc8ebd65fd32cc59e1587d8e4831/PatchTST_014.pt saved
2025-05-05 22:21:04,587 - easytorch-training - INFO - The estimated training finish time is 2025-05-05 22:31:04
2025-05-05 22:21:04,588 - easytorch-training - INFO - Epoch 15 / 100
  0%|          | 0/129 [00:00<?, ?it/s]  2%|‚ñè         | 3/129 [00:00<00:05, 21.73it/s]  5%|‚ñç         | 6/129 [00:00<00:05, 23.16it/s]  7%|‚ñã         | 9/129 [00:00<00:05, 23.84it/s]  9%|‚ñâ         | 12/129 [00:00<00:04, 23.92it/s] 12%|‚ñà‚ñè        | 15/129 [00:00<00:04, 24.47it/s] 14%|‚ñà‚ñç        | 18/129 [00:00<00:04, 24.52it/s] 16%|‚ñà‚ñã        | 21/129 [00:00<00:04, 24.55it/s] 19%|‚ñà‚ñä        | 24/129 [00:00<00:04, 24.70it/s] 21%|‚ñà‚ñà        | 27/129 [00:01<00:04, 24.75it/s] 23%|‚ñà‚ñà‚ñé       | 30/129 [00:01<00:03, 24.79it/s] 26%|‚ñà‚ñà‚ñå       | 33/129 [00:01<00:03, 24.83it/s] 28%|‚ñà‚ñà‚ñä       | 36/129 [00:01<00:03, 25.10it/s] 30%|‚ñà‚ñà‚ñà       | 39/129 [00:01<00:03, 25.18it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 42/129 [00:01<00:03, 24.91it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 45/129 [00:01<00:03, 25.06it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 48/129 [00:01<00:03, 25.16it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 51/129 [00:02<00:03, 25.02it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 54/129 [00:02<00:03, 24.88it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 57/129 [00:02<00:02, 24.76it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 60/129 [00:02<00:02, 24.21it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 63/129 [00:02<00:02, 24.05it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 66/129 [00:02<00:02, 24.06it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 69/129 [00:02<00:02, 24.43it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 72/129 [00:02<00:02, 24.39it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 75/129 [00:03<00:02, 24.53it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 78/129 [00:03<00:02, 24.76it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 81/129 [00:03<00:01, 24.80it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 84/129 [00:03<00:01, 25.04it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 87/129 [00:03<00:01, 25.25it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 90/129 [00:03<00:01, 25.20it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 93/129 [00:03<00:01, 25.06it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 96/129 [00:03<00:01, 25.10it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 99/129 [00:04<00:01, 25.23it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 102/129 [00:04<00:01, 25.16it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 105/129 [00:04<00:00, 25.13it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 108/129 [00:04<00:00, 25.13it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 111/129 [00:04<00:00, 24.47it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 114/129 [00:04<00:00, 24.40it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 117/129 [00:04<00:00, 24.58it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 120/129 [00:04<00:00, 24.72it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 123/129 [00:04<00:00, 24.74it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 126/129 [00:05<00:00, 24.93it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 129/129 [00:05<00:00, 25.71it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 129/129 [00:05<00:00, 24.77it/s]
2025-05-05 22:21:09,800 - easytorch-training - INFO - Result <train>: [train/time: 5.21 (s), train/lr: 3.10e-03, train/loss: -1.1036, train/NLL: -1.1036, train/CRPS: 0.0458]
2025-05-05 22:21:09,802 - easytorch-training - INFO - Start validation.
  0%|          | 0/39 [00:00<?, ?it/s] 15%|‚ñà‚ñå        | 6/39 [00:00<00:00, 53.64it/s] 31%|‚ñà‚ñà‚ñà       | 12/39 [00:00<00:00, 53.68it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 18/39 [00:00<00:00, 53.42it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 24/39 [00:00<00:00, 53.59it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 30/39 [00:00<00:00, 53.87it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 36/39 [00:00<00:00, 53.68it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 39/39 [00:00<00:00, 53.88it/s]
2025-05-05 22:21:10,530 - easytorch-training - INFO - Result <val>: [val/time: 0.73 (s), val/loss: -0.8098, val/NLL: -0.8098, val/CRPS: 0.0637]
  0%|          | 0/39 [00:00<?, ?it/s] 21%|‚ñà‚ñà        | 8/39 [00:00<00:00, 72.09it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 16/39 [00:00<00:00, 72.27it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 24/39 [00:00<00:00, 72.90it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 32/39 [00:00<00:00, 72.18it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 39/39 [00:00<00:00, 73.01it/s]
2025-05-05 22:21:11,157 - easytorch-training - INFO - Result <test>: [test/time: 0.62 (s), test/loss: -1.0707, test/NLL: -1.0704, test/CRPS: 0.0482]
2025-05-05 22:21:11,393 - easytorch-training - INFO - Checkpoint checkpoints/gaussian_PatchTST/ETTh1_100_336_96/b1a7fc8ebd65fd32cc59e1587d8e4831/PatchTST_015.pt saved
2025-05-05 22:21:11,396 - easytorch-training - INFO - The estimated training finish time is 2025-05-05 22:31:03
2025-05-05 22:21:11,396 - easytorch-training - INFO - Epoch 16 / 100
  0%|          | 0/129 [00:00<?, ?it/s]  2%|‚ñè         | 3/129 [00:00<00:05, 21.38it/s]  5%|‚ñç         | 6/129 [00:00<00:05, 23.03it/s]  7%|‚ñã         | 9/129 [00:00<00:05, 23.59it/s]  9%|‚ñâ         | 12/129 [00:00<00:04, 23.74it/s] 12%|‚ñà‚ñè        | 15/129 [00:00<00:04, 23.89it/s] 14%|‚ñà‚ñç        | 18/129 [00:00<00:04, 24.12it/s]wandb: WARNING Tried to log to step 1806 that is less than the current step 1807. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 1935 that is less than the current step 1936. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
 16%|‚ñà‚ñã        | 21/129 [00:00<00:04, 23.87it/s] 19%|‚ñà‚ñä        | 24/129 [00:01<00:04, 24.09it/s] 21%|‚ñà‚ñà        | 27/129 [00:01<00:04, 23.93it/s] 23%|‚ñà‚ñà‚ñé       | 30/129 [00:01<00:04, 24.16it/s] 26%|‚ñà‚ñà‚ñå       | 33/129 [00:01<00:04, 23.87it/s] 28%|‚ñà‚ñà‚ñä       | 36/129 [00:01<00:03, 24.05it/s] 30%|‚ñà‚ñà‚ñà       | 39/129 [00:01<00:03, 24.04it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 42/129 [00:01<00:03, 24.24it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 45/129 [00:01<00:03, 24.28it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 48/129 [00:02<00:03, 24.33it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 51/129 [00:02<00:03, 24.05it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 54/129 [00:02<00:03, 23.53it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 57/129 [00:02<00:03, 23.48it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 60/129 [00:02<00:02, 23.60it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 63/129 [00:02<00:02, 23.64it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 66/129 [00:02<00:02, 23.42it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 69/129 [00:02<00:02, 23.60it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 72/129 [00:03<00:02, 23.82it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 75/129 [00:03<00:02, 23.55it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 78/129 [00:03<00:02, 23.81it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 81/129 [00:03<00:02, 23.58it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 84/129 [00:03<00:01, 23.58it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 87/129 [00:03<00:01, 23.84it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 90/129 [00:03<00:01, 24.17it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 93/129 [00:03<00:01, 24.26it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 96/129 [00:04<00:01, 24.46it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 99/129 [00:04<00:01, 24.70it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 102/129 [00:04<00:01, 24.73it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 105/129 [00:04<00:00, 24.91it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 108/129 [00:04<00:00, 24.91it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 111/129 [00:04<00:00, 24.89it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 114/129 [00:04<00:00, 24.96it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 117/129 [00:04<00:00, 25.19it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 120/129 [00:04<00:00, 25.22it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 123/129 [00:05<00:00, 24.91it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 126/129 [00:05<00:00, 24.80it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 129/129 [00:05<00:00, 25.30it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 129/129 [00:05<00:00, 24.18it/s]
2025-05-05 22:21:16,735 - easytorch-training - INFO - Result <train>: [train/time: 5.34 (s), train/lr: 3.10e-03, train/loss: -1.1308, train/NLL: -1.1308, train/CRPS: 0.0449]
2025-05-05 22:21:16,738 - easytorch-training - INFO - Start validation.
  0%|          | 0/39 [00:00<?, ?it/s] 15%|‚ñà‚ñå        | 6/39 [00:00<00:00, 52.66it/s] 31%|‚ñà‚ñà‚ñà       | 12/39 [00:00<00:00, 52.93it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 18/39 [00:00<00:00, 52.70it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 24/39 [00:00<00:00, 53.01it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 30/39 [00:00<00:00, 52.84it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 36/39 [00:00<00:00, 52.87it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 39/39 [00:00<00:00, 53.25it/s]
2025-05-05 22:21:17,474 - easytorch-training - INFO - Result <val>: [val/time: 0.73 (s), val/loss: -0.7461, val/NLL: -0.7461, val/CRPS: 0.0669]
  0%|          | 0/39 [00:00<?, ?it/s] 21%|‚ñà‚ñà        | 8/39 [00:00<00:00, 72.23it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 16/39 [00:00<00:00, 73.27it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 24/39 [00:00<00:00, 73.47it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 32/39 [00:00<00:00, 73.76it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 39/39 [00:00<00:00, 74.19it/s]
2025-05-05 22:21:18,104 - easytorch-training - INFO - Result <test>: [test/time: 0.63 (s), test/loss: -0.9580, test/NLL: -0.9533, test/CRPS: 0.0539]
2025-05-05 22:21:18,242 - easytorch-training - INFO - Checkpoint checkpoints/gaussian_PatchTST/ETTh1_100_336_96/b1a7fc8ebd65fd32cc59e1587d8e4831/PatchTST_016.pt saved
2025-05-05 22:21:18,245 - easytorch-training - INFO - The estimated training finish time is 2025-05-05 22:31:02
2025-05-05 22:21:18,245 - easytorch-training - INFO - Epoch 17 / 100
  0%|          | 0/129 [00:00<?, ?it/s]  2%|‚ñè         | 3/129 [00:00<00:05, 21.81it/s]  5%|‚ñç         | 6/129 [00:00<00:05, 23.49it/s]  7%|‚ñã         | 9/129 [00:00<00:04, 24.10it/s]  9%|‚ñâ         | 12/129 [00:00<00:04, 24.32it/s] 12%|‚ñà‚ñè        | 15/129 [00:00<00:04, 24.60it/s] 14%|‚ñà‚ñç        | 18/129 [00:00<00:04, 24.70it/s] 16%|‚ñà‚ñã        | 21/129 [00:00<00:04, 24.72it/s] 19%|‚ñà‚ñä        | 24/129 [00:00<00:04, 24.78it/s] 21%|‚ñà‚ñà        | 27/129 [00:01<00:04, 24.83it/s] 23%|‚ñà‚ñà‚ñé       | 30/129 [00:01<00:04, 24.65it/s] 26%|‚ñà‚ñà‚ñå       | 33/129 [00:01<00:03, 24.48it/s] 28%|‚ñà‚ñà‚ñä       | 36/129 [00:01<00:03, 24.59it/s] 30%|‚ñà‚ñà‚ñà       | 39/129 [00:01<00:03, 24.74it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 42/129 [00:01<00:03, 24.64it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 45/129 [00:01<00:03, 24.68it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 48/129 [00:01<00:03, 24.65it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 51/129 [00:02<00:03, 24.60it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 54/129 [00:02<00:03, 24.57it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 57/129 [00:02<00:02, 24.63it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 60/129 [00:02<00:02, 24.70it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 63/129 [00:02<00:02, 24.47it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 66/129 [00:02<00:02, 24.68it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 69/129 [00:02<00:02, 24.91it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 72/129 [00:02<00:02, 24.73it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 75/129 [00:03<00:02, 24.64it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 78/129 [00:03<00:02, 25.08it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 81/129 [00:03<00:01, 25.29it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 84/129 [00:03<00:01, 25.11it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 87/129 [00:03<00:01, 25.22it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 90/129 [00:03<00:01, 25.12it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 93/129 [00:03<00:01, 24.86it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 96/129 [00:03<00:01, 24.65it/s]wandb: WARNING Tried to log to step 2064 that is less than the current step 2065. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 99/129 [00:04<00:01, 24.44it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 102/129 [00:04<00:01, 24.56it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 105/129 [00:04<00:00, 24.36it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 108/129 [00:04<00:00, 24.38it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 111/129 [00:04<00:00, 24.45it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 114/129 [00:04<00:00, 24.48it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 117/129 [00:04<00:00, 23.94it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 120/129 [00:04<00:00, 23.26it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 123/129 [00:05<00:00, 23.45it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 126/129 [00:05<00:00, 23.70it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 129/129 [00:05<00:00, 24.46it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 129/129 [00:05<00:00, 24.51it/s]
2025-05-05 22:21:23,513 - easytorch-training - INFO - Result <train>: [train/time: 5.27 (s), train/lr: 3.10e-03, train/loss: -1.1097, train/NLL: -1.1097, train/CRPS: 0.0456]
2025-05-05 22:21:23,515 - easytorch-training - INFO - Start validation.
  0%|          | 0/39 [00:00<?, ?it/s] 13%|‚ñà‚ñé        | 5/39 [00:00<00:00, 49.34it/s] 28%|‚ñà‚ñà‚ñä       | 11/39 [00:00<00:00, 51.16it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 17/39 [00:00<00:00, 50.67it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 23/39 [00:00<00:00, 50.78it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 29/39 [00:00<00:00, 51.22it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 35/39 [00:00<00:00, 51.47it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 39/39 [00:00<00:00, 51.53it/s]
2025-05-05 22:21:24,276 - easytorch-training - INFO - Result <val>: [val/time: 0.76 (s), val/loss: -0.8071, val/NLL: -0.8071, val/CRPS: 0.0635]
  0%|          | 0/39 [00:00<?, ?it/s] 18%|‚ñà‚ñä        | 7/39 [00:00<00:00, 69.35it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 15/39 [00:00<00:00, 71.09it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 23/39 [00:00<00:00, 71.66it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 31/39 [00:00<00:00, 71.45it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 39/39 [00:00<00:00, 72.22it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 39/39 [00:00<00:00, 71.49it/s]
2025-05-05 22:21:24,924 - easytorch-training - INFO - Result <test>: [test/time: 0.65 (s), test/loss: -1.1051, test/NLL: -1.1038, test/CRPS: 0.0472]
2025-05-05 22:21:25,055 - easytorch-training - INFO - Checkpoint checkpoints/gaussian_PatchTST/ETTh1_100_336_96/b1a7fc8ebd65fd32cc59e1587d8e4831/PatchTST_017.pt saved
2025-05-05 22:21:25,057 - easytorch-training - INFO - The estimated training finish time is 2025-05-05 22:31:01
2025-05-05 22:21:25,057 - easytorch-training - INFO - Epoch 18 / 100
  0%|          | 0/129 [00:00<?, ?it/s]  2%|‚ñè         | 2/129 [00:00<00:06, 19.17it/s]  4%|‚ñç         | 5/129 [00:00<00:05, 21.84it/s]  6%|‚ñå         | 8/129 [00:00<00:05, 23.03it/s]  9%|‚ñä         | 11/129 [00:00<00:05, 23.40it/s] 11%|‚ñà         | 14/129 [00:00<00:04, 23.78it/s] 13%|‚ñà‚ñé        | 17/129 [00:00<00:04, 23.75it/s] 16%|‚ñà‚ñå        | 20/129 [00:00<00:04, 23.93it/s] 18%|‚ñà‚ñä        | 23/129 [00:00<00:04, 23.99it/s] 20%|‚ñà‚ñà        | 26/129 [00:01<00:04, 24.02it/s] 22%|‚ñà‚ñà‚ñè       | 29/129 [00:01<00:04, 24.05it/s] 25%|‚ñà‚ñà‚ñç       | 32/129 [00:01<00:04, 24.03it/s] 27%|‚ñà‚ñà‚ñã       | 35/129 [00:01<00:03, 24.13it/s] 29%|‚ñà‚ñà‚ñâ       | 38/129 [00:01<00:03, 24.15it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 41/129 [00:01<00:03, 24.11it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 44/129 [00:01<00:03, 24.20it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 47/129 [00:01<00:03, 24.06it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 50/129 [00:02<00:03, 24.08it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 53/129 [00:02<00:03, 23.83it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 56/129 [00:02<00:03, 23.89it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 59/129 [00:02<00:02, 24.18it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 62/129 [00:02<00:02, 24.05it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 65/129 [00:02<00:02, 24.03it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 68/129 [00:02<00:02, 24.09it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 71/129 [00:02<00:02, 24.02it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 74/129 [00:03<00:02, 24.22it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 77/129 [00:03<00:02, 24.33it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 80/129 [00:03<00:02, 24.31it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 83/129 [00:03<00:01, 24.28it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 86/129 [00:03<00:01, 24.46it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 89/129 [00:03<00:01, 24.53it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 92/129 [00:03<00:01, 24.32it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 95/129 [00:03<00:01, 24.23it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 98/129 [00:04<00:01, 24.21it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 101/129 [00:04<00:01, 24.25it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 104/129 [00:04<00:01, 24.33it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 107/129 [00:04<00:00, 24.34it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 110/129 [00:04<00:00, 24.29it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 113/129 [00:04<00:00, 23.67it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 116/129 [00:04<00:00, 23.65it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 119/129 [00:04<00:00, 23.96it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 122/129 [00:05<00:00, 23.78it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 125/129 [00:05<00:00, 23.95it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 128/129 [00:05<00:00, 24.06it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 129/129 [00:05<00:00, 24.01it/s]
2025-05-05 22:21:30,435 - easytorch-training - INFO - Result <train>: [train/time: 5.38 (s), train/lr: 3.10e-03, train/loss: -1.1171, train/NLL: -1.1171, train/CRPS: 0.0453]
2025-05-05 22:21:30,438 - easytorch-training - INFO - Start validation.
  0%|          | 0/39 [00:00<?, ?it/s] 13%|‚ñà‚ñé        | 5/39 [00:00<00:00, 48.63it/s] 28%|‚ñà‚ñà‚ñä       | 11/39 [00:00<00:00, 49.52it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 17/39 [00:00<00:00, 50.91it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 23/39 [00:00<00:00, 50.75it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 29/39 [00:00<00:00, 50.36it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 35/39 [00:00<00:00, 50.20it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 39/39 [00:00<00:00, 50.38it/s]
2025-05-05 22:21:31,215 - easytorch-training - INFO - Result <val>: [val/time: 0.78 (s), val/loss: -0.6866, val/NLL: -0.6866, val/CRPS: 0.0682]
  0%|          | 0/39 [00:00<?, ?it/s] 18%|‚ñà‚ñä        | 7/39 [00:00<00:00, 65.89it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 14/39 [00:00<00:00, 66.19it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 22/39 [00:00<00:00, 69.22it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 30/39 [00:00<00:00, 71.37it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 38/39 [00:00<00:00, 72.31it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 39/39 [00:00<00:00, 71.16it/s]
2025-05-05 22:21:31,869 - easytorch-training - INFO - Result <test>: [test/time: 0.65 (s), test/loss: -0.9300, test/NLL: -0.9267, test/CRPS: 0.0541]
2025-05-05 22:21:31,999 - easytorch-training - INFO - Checkpoint checkpoints/gaussian_PatchTST/ETTh1_100_336_96/b1a7fc8ebd65fd32cc59e1587d8e4831/PatchTST_018.pt saved
2025-05-05 22:21:32,001 - easytorch-training - INFO - The estimated training finish time is 2025-05-05 22:31:01
2025-05-05 22:21:32,001 - easytorch-training - INFO - Early stopping.
2025-05-05 22:21:32,001 - easytorch-training - INFO - The training finished at 2025-05-05 22:21:32
2025-05-05 22:21:32,002 - easytorch-training - INFO - Evaluating the best model on the test set.
2025-05-05 22:21:32,003 - easytorch-training - INFO - Load model from : checkpoints/gaussian_PatchTST/ETTh1_100_336_96/b1a7fc8ebd65fd32cc59e1587d8e4831/PatchTST_best_val_NLL.pt
2025-05-05 22:21:32,003 - easytorch-training - INFO - Loading Checkpoint from 'checkpoints/gaussian_PatchTST/ETTh1_100_336_96/b1a7fc8ebd65fd32cc59e1587d8e4831/PatchTST_best_val_NLL.pt'
2025-05-05 22:21:32,133 - easytorch-training - ERROR - Traceback (most recent call last):
  File "/home/kreffert/Probabilistic_LTSF/BasicTS/basicts/launcher.py", line 183, in training_func
    best_metrics = runner.train(cfg=cfg)
                   ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kreffert/Probabilistic_LTSF/BasicTS/basicts/runners/base_epoch_runner.py", line 457, in train
    self.on_training_end(cfg=cfg, train_epoch=epoch_index + 1)
  File "/home/kreffert/Probabilistic_LTSF/BasicTS/basicts/runners/base_epoch_runner.py", line 694, in on_training_end
    self.load_model(ckpt_path=best_model_path, strict=True)
  File "/home/kreffert/Probabilistic_LTSF/BasicTS/basicts/runners/base_epoch_runner.py", line 728, in load_model
    self.model.load_state_dict(checkpoint_dict['model_state_dict'], strict=strict)
  File "/home/kreffert/miniconda3/envs/BasicTS/lib/python3.11/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
    raise RuntimeError(
RuntimeError: Error(s) in loading state_dict for PatchTST:
	Unexpected key(s) in state_dict: "model.head.prob_heads.0.head.df_layer.weight", "model.head.prob_heads.0.head.df_layer.bias", "model.head.prob_heads.1.head.df_layer.weight", "model.head.prob_heads.1.head.df_layer.bias", "model.head.prob_heads.2.head.df_layer.weight", "model.head.prob_heads.2.head.df_layer.bias", "model.head.prob_heads.3.head.df_layer.weight", "model.head.prob_heads.3.head.df_layer.bias", "model.head.prob_heads.4.head.df_layer.weight", "model.head.prob_heads.4.head.df_layer.bias", "model.head.prob_heads.5.head.df_layer.weight", "model.head.prob_heads.5.head.df_layer.bias", "model.head.prob_heads.6.head.df_layer.weight", "model.head.prob_heads.6.head.df_layer.bias". 
	size mismatch for model.backbone.W_pos: copying a param with shape torch.Size([19, 16]) from checkpoint, the shape in current model is torch.Size([11, 128]).
	size mismatch for model.backbone.W_P.weight: copying a param with shape torch.Size([16, 64]) from checkpoint, the shape in current model is torch.Size([128, 32]).
	size mismatch for model.backbone.W_P.bias: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for model.backbone.encoder.layers.0.self_attn.W_Q.weight: copying a param with shape torch.Size([16, 16]) from checkpoint, the shape in current model is torch.Size([128, 128]).
	size mismatch for model.backbone.encoder.layers.0.self_attn.W_Q.bias: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for model.backbone.encoder.layers.0.self_attn.W_K.weight: copying a param with shape torch.Size([16, 16]) from checkpoint, the shape in current model is torch.Size([128, 128]).
	size mismatch for model.backbone.encoder.layers.0.self_attn.W_K.bias: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for model.backbone.encoder.layers.0.self_attn.W_V.weight: copying a param with shape torch.Size([16, 16]) from checkpoint, the shape in current model is torch.Size([128, 128]).
	size mismatch for model.backbone.encoder.layers.0.self_attn.W_V.bias: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for model.backbone.encoder.layers.0.self_attn.to_out.0.weight: copying a param with shape torch.Size([16, 16]) from checkpoint, the shape in current model is torch.Size([128, 128]).
	size mismatch for model.backbone.encoder.layers.0.self_attn.to_out.0.bias: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for model.backbone.encoder.layers.0.norm_attn.1.weight: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for model.backbone.encoder.layers.0.norm_attn.1.bias: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for model.backbone.encoder.layers.0.norm_attn.1.running_mean: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for model.backbone.encoder.layers.0.norm_attn.1.running_var: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for model.backbone.encoder.layers.0.ff.0.weight: copying a param with shape torch.Size([128, 16]) from checkpoint, the shape in current model is torch.Size([128, 128]).
	size mismatch for model.backbone.encoder.layers.0.ff.3.weight: copying a param with shape torch.Size([16, 128]) from checkpoint, the shape in current model is torch.Size([128, 128]).
	size mismatch for model.backbone.encoder.layers.0.ff.3.bias: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for model.backbone.encoder.layers.0.norm_ffn.1.weight: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for model.backbone.encoder.layers.0.norm_ffn.1.bias: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for model.backbone.encoder.layers.0.norm_ffn.1.running_mean: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for model.backbone.encoder.layers.0.norm_ffn.1.running_var: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for model.backbone.encoder.layers.1.self_attn.W_Q.weight: copying a param with shape torch.Size([16, 16]) from checkpoint, the shape in current model is torch.Size([128, 128]).
	size mismatch for model.backbone.encoder.layers.1.self_attn.W_Q.bias: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for model.backbone.encoder.layers.1.self_attn.W_K.weight: copying a param with shape torch.Size([16, 16]) from checkpoint, the shape in current model is torch.Size([128, 128]).
	size mismatch for model.backbone.encoder.layers.1.self_attn.W_K.bias: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for model.backbone.encoder.layers.1.self_attn.W_V.weight: copying a param with shape torch.Size([16, 16]) from checkpoint, the shape in current model is torch.Size([128, 128]).
	size mismatch for model.backbone.encoder.layers.1.self_attn.W_V.bias: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for model.backbone.encoder.layers.1.self_attn.to_out.0.weight: copying a param with shape torch.Size([16, 16]) from checkpoint, the shape in current model is torch.Size([128, 128]).
	size mismatch for model.backbone.encoder.layers.1.self_attn.to_out.0.bias: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for model.backbone.encoder.layers.1.norm_attn.1.weight: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for model.backbone.encoder.layers.1.norm_attn.1.bias: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for model.backbone.encoder.layers.1.norm_attn.1.running_mean: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for model.backbone.encoder.layers.1.norm_attn.1.running_var: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for model.backbone.encoder.layers.1.ff.0.weight: copying a param with shape torch.Size([128, 16]) from checkpoint, the shape in current model is torch.Size([128, 128]).
	size mismatch for model.backbone.encoder.layers.1.ff.3.weight: copying a param with shape torch.Size([16, 128]) from checkpoint, the shape in current model is torch.Size([128, 128]).
	size mismatch for model.backbone.encoder.layers.1.ff.3.bias: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for model.backbone.encoder.layers.1.norm_ffn.1.weight: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for model.backbone.encoder.layers.1.norm_ffn.1.bias: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for model.backbone.encoder.layers.1.norm_ffn.1.running_mean: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for model.backbone.encoder.layers.1.norm_ffn.1.running_var: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for model.head.prob_heads.0.head.mean_layer.weight: copying a param with shape torch.Size([96, 304]) from checkpoint, the shape in current model is torch.Size([96, 1408]).
	size mismatch for model.head.prob_heads.0.head.std_layer.weight: copying a param with shape torch.Size([96, 304]) from checkpoint, the shape in current model is torch.Size([96, 1408]).
	size mismatch for model.head.prob_heads.1.head.mean_layer.weight: copying a param with shape torch.Size([96, 304]) from checkpoint, the shape in current model is torch.Size([96, 1408]).
	size mismatch for model.head.prob_heads.1.head.std_layer.weight: copying a param with shape torch.Size([96, 304]) from checkpoint, the shape in current model is torch.Size([96, 1408]).
	size mismatch for model.head.prob_heads.2.head.mean_layer.weight: copying a param with shape torch.Size([96, 304]) from checkpoint, the shape in current model is torch.Size([96, 1408]).
	size mismatch for model.head.prob_heads.2.head.std_layer.weight: copying a param with shape torch.Size([96, 304]) from checkpoint, the shape in current model is torch.Size([96, 1408]).
	size mismatch for model.head.prob_heads.3.head.mean_layer.weight: copying a param with shape torch.Size([96, 304]) from checkpoint, the shape in current model is torch.Size([96, 1408]).
	size mismatch for model.head.prob_heads.3.head.std_layer.weight: copying a param with shape torch.Size([96, 304]) from checkpoint, the shape in current model is torch.Size([96, 1408]).
	size mismatch for model.head.prob_heads.4.head.mean_layer.weight: copying a param with shape torch.Size([96, 304]) from checkpoint, the shape in current model is torch.Size([96, 1408]).
	size mismatch for model.head.prob_heads.4.head.std_layer.weight: copying a param with shape torch.Size([96, 304]) from checkpoint, the shape in current model is torch.Size([96, 1408]).
	size mismatch for model.head.prob_heads.5.head.mean_layer.weight: copying a param with shape torch.Size([96, 304]) from checkpoint, the shape in current model is torch.Size([96, 1408]).
	size mismatch for model.head.prob_heads.5.head.std_layer.weight: copying a param with shape torch.Size([96, 304]) from checkpoint, the shape in current model is torch.Size([96, 1408]).
	size mismatch for model.head.prob_heads.6.head.mean_layer.weight: copying a param with shape torch.Size([96, 304]) from checkpoint, the shape in current model is torch.Size([96, 1408]).
	size mismatch for model.head.prob_heads.6.head.std_layer.weight: copying a param with shape torch.Size([96, 304]) from checkpoint, the shape in current model is torch.Size([96, 1408]).

Traceback (most recent call last):
  File "/home/kreffert/Probabilistic_LTSF/BasicTS/basicts/launcher.py", line 363, in agent_function
    return sweep_agent_function(cfg)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kreffert/Probabilistic_LTSF/BasicTS/basicts/launcher.py", line 311, in sweep_agent_function
    training_func(merged_config, wandb_run=wandb.run)
  File "/home/kreffert/Probabilistic_LTSF/BasicTS/basicts/launcher.py", line 187, in training_func
    raise e
  File "/home/kreffert/Probabilistic_LTSF/BasicTS/basicts/launcher.py", line 183, in training_func
    best_metrics = runner.train(cfg=cfg)
                   ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kreffert/Probabilistic_LTSF/BasicTS/basicts/runners/base_epoch_runner.py", line 457, in train
    self.on_training_end(cfg=cfg, train_epoch=epoch_index + 1)
  File "/home/kreffert/Probabilistic_LTSF/BasicTS/basicts/runners/base_epoch_runner.py", line 694, in on_training_end
    self.load_model(ckpt_path=best_model_path, strict=True)
  File "/home/kreffert/Probabilistic_LTSF/BasicTS/basicts/runners/base_epoch_runner.py", line 728, in load_model
    self.model.load_state_dict(checkpoint_dict['model_state_dict'], strict=strict)
  File "/home/kreffert/miniconda3/envs/BasicTS/lib/python3.11/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
    raise RuntimeError(
RuntimeError: Error(s) in loading state_dict for PatchTST:
	Unexpected key(s) in state_dict: "model.head.prob_heads.0.head.df_layer.weight", "model.head.prob_heads.0.head.df_layer.bias", "model.head.prob_heads.1.head.df_layer.weight", "model.head.prob_heads.1.head.df_layer.bias", "model.head.prob_heads.2.head.df_layer.weight", "model.head.prob_heads.2.head.df_layer.bias", "model.head.prob_heads.3.head.df_layer.weight", "model.head.prob_heads.3.head.df_layer.bias", "model.head.prob_heads.4.head.df_layer.weight", "model.head.prob_heads.4.head.df_layer.bias", "model.head.prob_heads.5.head.df_layer.weight", "model.head.prob_heads.5.head.df_layer.bias", "model.head.prob_heads.6.head.df_layer.weight", "model.head.prob_heads.6.head.df_layer.bias". 
	size mismatch for model.backbone.W_pos: copying a param with shape torch.Size([19, 16]) from checkpoint, the shape in current model is torch.Size([11, 128]).
	size mismatch for model.backbone.W_P.weight: copying a param with shape torch.Size([16, 64]) from checkpoint, the shape in current model is torch.Size([128, 32]).
	size mismatch for model.backbone.W_P.bias: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for model.backbone.encoder.layers.0.self_attn.W_Q.weight: copying a param with shape torch.Size([16, 16]) from checkpoint, the shape in current model is torch.Size([128, 128]).
	size mismatch for model.backbone.encoder.layers.0.self_attn.W_Q.bias: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for model.backbone.encoder.layers.0.self_attn.W_K.weight: copying a param with shape torch.Size([16, 16]) from checkpoint, the shape in current model is torch.Size([128, 128]).
	size mismatch for model.backbone.encoder.layers.0.self_attn.W_K.bias: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for model.backbone.encoder.layers.0.self_attn.W_V.weight: copying a param with shape torch.Size([16, 16]) from checkpoint, the shape in current model is torch.Size([128, 128]).
	size mismatch for model.backbone.encoder.layers.0.self_attn.W_V.bias: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for model.backbone.encoder.layers.0.self_attn.to_out.0.weight: copying a param with shape torch.Size([16, 16]) from checkpoint, the shape in current model is torch.Size([128, 128]).
	size mismatch for model.backbone.encoder.layers.0.self_attn.to_out.0.bias: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for model.backbone.encoder.layers.0.norm_attn.1.weight: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for model.backbone.encoder.layers.0.norm_attn.1.bias: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for model.backbone.encoder.layers.0.norm_attn.1.running_mean: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for model.backbone.encoder.layers.0.norm_attn.1.running_var: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for model.backbone.encoder.layers.0.ff.0.weight: copying a param with shape torch.Size([128, 16]) from checkpoint, the shape in current model is torch.Size([128, 128]).
	size mismatch for model.backbone.encoder.layers.0.ff.3.weight: copying a param with shape torch.Size([16, 128]) from checkpoint, the shape in current model is torch.Size([128, 128]).
	size mismatch for model.backbone.encoder.layers.0.ff.3.bias: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for model.backbone.encoder.layers.0.norm_ffn.1.weight: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for model.backbone.encoder.layers.0.norm_ffn.1.bias: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for model.backbone.encoder.layers.0.norm_ffn.1.running_mean: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for model.backbone.encoder.layers.0.norm_ffn.1.running_var: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for model.backbone.encoder.layers.1.self_attn.W_Q.weight: copying a param with shape torch.Size([16, 16]) from checkpoint, the shape in current model is torch.Size([128, 128]).
	size mismatch for model.backbone.encoder.layers.1.self_attn.W_Q.bias: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for model.backbone.encoder.layers.1.self_attn.W_K.weight: copying a param with shape torch.Size([16, 16]) from checkpoint, the shape in current model is torch.Size([128, 128]).
	size mismatch for model.backbone.encoder.layers.1.self_attn.W_K.bias: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for model.backbone.encoder.layers.1.self_attn.W_V.weight: copying a param with shape torch.Size([16, 16]) from checkpoint, the shape in current model is torch.Size([128, 128]).
	size mismatch for model.backbone.encoder.layers.1.self_attn.W_V.bias: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for model.backbone.encoder.layers.1.self_attn.to_out.0.weight: copying a param with shape torch.Size([16, 16]) from checkpoint, the shape in current model is torch.Size([128, 128]).
	size mismatch for model.backbone.encoder.layers.1.self_attn.to_out.0.bias: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for model.backbone.encoder.layers.1.norm_attn.1.weight: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for model.backbone.encoder.layers.1.norm_attn.1.bias: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for model.backbone.encoder.layers.1.norm_attn.1.running_mean: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for model.backbone.encoder.layers.1.norm_attn.1.running_var: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for model.backbone.encoder.layers.1.ff.0.weight: copying a param with shape torch.Size([128, 16]) from checkpoint, the shape in current model is torch.Size([128, 128]).
	size mismatch for model.backbone.encoder.layers.1.ff.3.weight: copying a param with shape torch.Size([16, 128]) from checkpoint, the shape in current model is torch.Size([128, 128]).
	size mismatch for model.backbone.encoder.layers.1.ff.3.bias: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for model.backbone.encoder.layers.1.norm_ffn.1.weight: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for model.backbone.encoder.layers.1.norm_ffn.1.bias: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for model.backbone.encoder.layers.1.norm_ffn.1.running_mean: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for model.backbone.encoder.layers.1.norm_ffn.1.running_var: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for model.head.prob_heads.0.head.mean_layer.weight: copying a param with shape torch.Size([96, 304]) from checkpoint, the shape in current model is torch.Size([96, 1408]).
	size mismatch for model.head.prob_heads.0.head.std_layer.weight: copying a param with shape torch.Size([96, 304]) from checkpoint, the shape in current model is torch.Size([96, 1408]).
	size mismatch for model.head.prob_heads.1.head.mean_layer.weight: copying a param with shape torch.Size([96, 304]) from checkpoint, the shape in current model is torch.Size([96, 1408]).
	size mismatch for model.head.prob_heads.1.head.std_layer.weight: copying a param with shape torch.Size([96, 304]) from checkpoint, the shape in current model is torch.Size([96, 1408]).
	size mismatch for model.head.prob_heads.2.head.mean_layer.weight: copying a param with shape torch.Size([96, 304]) from checkpoint, the shape in current model is torch.Size([96, 1408]).
	size mismatch for model.head.prob_heads.2.head.std_layer.weight: copying a param with shape torch.Size([96, 304]) from checkpoint, the shape in current model is torch.Size([96, 1408]).
	size mismatch for model.head.prob_heads.3.head.mean_layer.weight: copying a param with shape torch.Size([96, 304]) from checkpoint, the shape in current model is torch.Size([96, 1408]).
	size mismatch for model.head.prob_heads.3.head.std_layer.weight: copying a param with shape torch.Size([96, 304]) from checkpoint, the shape in current model is torch.Size([96, 1408]).
	size mismatch for model.head.prob_heads.4.head.mean_layer.weight: copying a param with shape torch.Size([96, 304]) from checkpoint, the shape in current model is torch.Size([96, 1408]).
	size mismatch for model.head.prob_heads.4.head.std_layer.weight: copying a param with shape torch.Size([96, 304]) from checkpoint, the shape in current model is torch.Size([96, 1408]).
	size mismatch for model.head.prob_heads.5.head.mean_layer.weight: copying a param with shape torch.Size([96, 304]) from checkpoint, the shape in current model is torch.Size([96, 1408]).
	size mismatch for model.head.prob_heads.5.head.std_layer.weight: copying a param with shape torch.Size([96, 304]) from checkpoint, the shape in current model is torch.Size([96, 1408]).
	size mismatch for model.head.prob_heads.6.head.mean_layer.weight: copying a param with shape torch.Size([96, 304]) from checkpoint, the shape in current model is torch.Size([96, 1408]).
	size mismatch for model.head.prob_heads.6.head.std_layer.weight: copying a param with shape torch.Size([96, 304]) from checkpoint, the shape in current model is torch.Size([96, 1408]).
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:                    epoch ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà
wandb: epoch_summary/train/CRPS ‚ñà‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:  epoch_summary/train/NLL ‚ñà‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: epoch_summary/train/loss ‚ñà‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:   epoch_summary/train/lr ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: epoch_summary/train/time ‚ñà‚ñÅ‚ñÉ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÇ
wandb:   epoch_summary/val/CRPS ‚ñà‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:    epoch_summary/val/NLL ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:   epoch_summary/val/loss ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:   epoch_summary/val/time ‚ñá‚ñÑ‚ñÑ‚ñÑ‚ñÅ‚ñÖ‚ñÉ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÇ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñà
wandb:                test/CRPS ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                 test/NLL ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:               train/CRPS ‚ñà‚ñÜ‚ñÖ‚ñá‚ñÜ‚ñá‚ñÜ‚ñá‚ñà‚ñÑ‚ñÉ‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                train/NLL ‚ñà‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:              train/epoch ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:               train/iter ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:               train/loss ‚ñà‚ñá‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                 val/CRPS ‚ñà‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                  val/NLL ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                 val/loss ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                 val/time ‚ñá‚ñÑ‚ñÑ‚ñÑ‚ñÅ‚ñÖ‚ñÉ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÇ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñà
wandb: 
wandb: Run summary:
wandb:                    epoch 18
wandb: epoch_summary/train/CRPS 0.04532
wandb:  epoch_summary/train/NLL -1.11709
wandb: epoch_summary/train/loss -1.11709
wandb:   epoch_summary/train/lr 0.0031
wandb: epoch_summary/train/time 5.37628
wandb:   epoch_summary/val/CRPS 0.06823
wandb:    epoch_summary/val/NLL -0.68663
wandb:   epoch_summary/val/loss -0.68663
wandb:   epoch_summary/val/time 0.77659
wandb:                test/CRPS 0.05412
wandb:                 test/NLL -0.92666
wandb:               train/CRPS 0.04234
wandb:                train/NLL -1.16949
wandb:              train/epoch 18
wandb:               train/iter 2313
wandb:               train/loss -1.16949
wandb:                 val/CRPS 0.06823
wandb:                  val/NLL -0.68663
wandb:                 val/loss -0.68663
wandb:                 val/time 0.77659
wandb: 
wandb: üöÄ View run PatchTST_May_05_22_19 at: https://wandb.ai/kai-reffert-university-mannheim/Prob_LTSF/runs/nbw0qqsb
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/kai-reffert-university-mannheim/Prob_LTSF
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250505_221921-nbw0qqsb/logs
wandb: WARNING Tried to log to step 2193 that is less than the current step 2194. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: ERROR Run nbw0qqsb errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/home/kreffert/miniconda3/envs/BasicTS/lib/python3.11/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/home/kreffert/Probabilistic_LTSF/BasicTS/basicts/launcher.py", line 363, in agent_function
wandb: ERROR     return sweep_agent_function(cfg)
wandb: ERROR            ^^^^^^^^^^^^^^^^^^^^^^^^^
wandb: ERROR   File "/home/kreffert/Probabilistic_LTSF/BasicTS/basicts/launcher.py", line 311, in sweep_agent_function
wandb: ERROR     training_func(merged_config, wandb_run=wandb.run)
wandb: ERROR   File "/home/kreffert/Probabilistic_LTSF/BasicTS/basicts/launcher.py", line 187, in training_func
wandb: ERROR     raise e
wandb: ERROR   File "/home/kreffert/Probabilistic_LTSF/BasicTS/basicts/launcher.py", line 183, in training_func
wandb: ERROR     best_metrics = runner.train(cfg=cfg)
wandb: ERROR                    ^^^^^^^^^^^^^^^^^^^^^
wandb: ERROR   File "/home/kreffert/Probabilistic_LTSF/BasicTS/basicts/runners/base_epoch_runner.py", line 457, in train
wandb: ERROR     self.on_training_end(cfg=cfg, train_epoch=epoch_index + 1)
wandb: ERROR   File "/home/kreffert/Probabilistic_LTSF/BasicTS/basicts/runners/base_epoch_runner.py", line 694, in on_training_end
wandb: ERROR     self.load_model(ckpt_path=best_model_path, strict=True)
wandb: ERROR   File "/home/kreffert/Probabilistic_LTSF/BasicTS/basicts/runners/base_epoch_runner.py", line 728, in load_model
wandb: ERROR     self.model.load_state_dict(checkpoint_dict['model_state_dict'], strict=strict)
wandb: ERROR   File "/home/kreffert/miniconda3/envs/BasicTS/lib/python3.11/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for PatchTST:
wandb: ERROR 	Unexpected key(s) in state_dict: "model.head.prob_heads.0.head.df_layer.weight", "model.head.prob_heads.0.head.df_layer.bias", "model.head.prob_heads.1.head.df_layer.weight", "model.head.prob_heads.1.head.df_layer.bias", "model.head.prob_heads.2.head.df_layer.weight", "model.head.prob_heads.2.head.df_layer.bias", "model.head.prob_heads.3.head.df_layer.weight", "model.head.prob_heads.3.head.df_layer.bias", "model.head.prob_heads.4.head.df_layer.weight", "model.head.prob_heads.4.head.df_layer.bias", "model.head.prob_heads.5.head.df_layer.weight", "model.head.prob_heads.5.head.df_layer.bias", "model.head.prob_heads.6.head.df_layer.weight", "model.head.prob_heads.6.head.df_layer.bias". 
wandb: ERROR 	size mismatch for model.backbone.W_pos: copying a param with shape torch.Size([19, 16]) from checkpoint, the shape in current model is torch.Size([11, 128]).
wandb: ERROR 	size mismatch for model.backbone.W_P.weight: copying a param with shape torch.Size([16, 64]) from checkpoint, the shape in current model is torch.Size([128, 32]).
wandb: ERROR 	size mismatch for model.backbone.W_P.bias: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([128]).
wandb: ERROR 	size mismatch for model.backbone.encoder.layers.0.self_attn.W_Q.weight: copying a param with shape torch.Size([16, 16]) from checkpoint, the shape in current model is torch.Size([128, 128]).
wandb: ERROR 	size mismatch for model.backbone.encoder.layers.0.self_attn.W_Q.bias: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([128]).
wandb: ERROR 	size mismatch for model.backbone.encoder.layers.0.self_attn.W_K.weight: copying a param with shape torch.Size([16, 16]) from checkpoint, the shape in current model is torch.Size([128, 128]).
wandb: ERROR 	size mismatch for model.backbone.encoder.layers.0.self_attn.W_K.bias: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([128]).
wandb: ERROR 	size mismatch for model.backbone.encoder.layers.0.self_attn.W_V.weight: copying a param with shape torch.Size([16, 16]) from checkpoint, the shape in current model is torch.Size([128, 128]).
wandb: ERROR 	size mismatch for model.backbone.encoder.layers.0.self_attn.W_V.bias: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([128]).
wandb: ERROR 	size mismatch for model.backbone.encoder.layers.0.self_attn.to_out.0.weight: copying a param with shape torch.Size([16, 16]) from checkpoint, the shape in current model is torch.Size([128, 128]).
wandb: ERROR 	size mismatch for model.backbone.encoder.layers.0.self_attn.to_out.0.bias: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([128]).
wandb: ERROR 	size mismatch for model.backbone.encoder.layers.0.norm_attn.1.weight: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([128]).
wandb: ERROR 	size mismatch for model.backbone.encoder.layers.0.norm_attn.1.bias: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([128]).
wandb: ERROR 	size mismatch for model.backbone.encoder.layers.0.norm_attn.1.running_mean: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([128]).
wandb: ERROR 	size mismatch for model.backbone.encoder.layers.0.norm_attn.1.running_var: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([128]).
wandb: ERROR 	size mismatch for model.backbone.encoder.layers.0.ff.0.weight: copying a param with shape torch.Size([128, 16]) from checkpoint, the shape in current model is torch.Size([128, 128]).
wandb: ERROR 	size mismatch for model.backbone.encoder.layers.0.ff.3.weight: copying a param with shape torch.Size([16, 128]) from checkpoint, the shape in current model is torch.Size([128, 128]).
wandb: ERROR 	size mismatch for model.backbone.encoder.layers.0.ff.3.bias: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([128]).
wandb: ERROR 	size mismatch for model.backbone.encoder.layers.0.norm_ffn.1.weight: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([128]).
wandb: ERROR 	size mismatch for model.backbone.encoder.layers.0.norm_ffn.1.bias: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([128]).
wandb: ERROR 	size mismatch for model.backbone.encoder.layers.0.norm_ffn.1.running_mean: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([128]).
wandb: ERROR 	size mismatch for model.backbone.encoder.layers.0.norm_ffn.1.running_var: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([128]).
wandb: ERROR 	size mismatch for model.backbone.encoder.layers.1.self_attn.W_Q.weight: copying a param with shape torch.Size([16, 16]) from checkpoint, the shape in current model is torch.Size([128, 128]).
wandb: ERROR 	size mismatch for model.backbone.encoder.layers.1.self_attn.W_Q.bias: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([128]).
wandb: ERROR 	size mismatch for model.backbone.encoder.layers.1.self_attn.W_K.weight: copying a param with shape torch.Size([16, 16]) from checkpoint, the shape in current model is torch.Size([128, 128]).
wandb: ERROR 	size mismatch for model.backbone.encoder.layers.1.self_attn.W_K.bias: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([128]).
wandb: ERROR 	size mismatch for model.backbone.encoder.layers.1.self_attn.W_V.weight: copying a param with shape torch.Size([16, 16]) from checkpoint, the shape in current model is torch.Size([128, 128]).
wandb: ERROR 	size mismatch for model.backbone.encoder.layers.1.self_attn.W_V.bias: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([128]).
wandb: ERROR 	size mismatch for model.backbone.encoder.layers.1.self_attn.to_out.0.weight: copying a param with shape torch.Size([16, 16]) from checkpoint, the shape in current model is torch.Size([128, 128]).
wandb: ERROR 	size mismatch for model.backbone.encoder.layers.1.self_attn.to_out.0.bias: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([128]).
wandb: ERROR 	size mismatch for model.backbone.encoder.layers.1.norm_attn.1.weight: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([128]).
wandb: ERROR 	size mismatch for model.backbone.encoder.layers.1.norm_attn.1.bias: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([128]).
wandb: ERROR 	size mismatch for model.backbone.encoder.layers.1.norm_attn.1.running_mean: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([128]).
wandb: ERROR 	size mismatch for model.backbone.encoder.layers.1.norm_attn.1.running_var: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([128]).
wandb: ERROR 	size mismatch for model.backbone.encoder.layers.1.ff.0.weight: copying a param with shape torch.Size([128, 16]) from checkpoint, the shape in current model is torch.Size([128, 128]).
wandb: ERROR 	size mismatch for model.backbone.encoder.layers.1.ff.3.weight: copying a param with shape torch.Size([16, 128]) from checkpoint, the shape in current model is torch.Size([128, 128]).
wandb: ERROR 	size mismatch for model.backbone.encoder.layers.1.ff.3.bias: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([128]).
wandb: ERROR 	size mismatch for model.backbone.encoder.layers.1.norm_ffn.1.weight: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([128]).
wandb: ERROR 	size mismatch for model.backbone.encoder.layers.1.norm_ffn.1.bias: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([128]).
wandb: ERROR 	size mismatch for model.backbone.encoder.layers.1.norm_ffn.1.running_mean: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([128]).
wandb: ERROR 	size mismatch for model.backbone.encoder.layers.1.norm_ffn.1.running_var: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([128]).
wandb: ERROR 	size mismatch for model.head.prob_heads.0.head.mean_layer.weight: copying a param with shape torch.Size([96, 304]) from checkpoint, the shape in current model is torch.Size([96, 1408]).
wandb: ERROR 	size mismatch for model.head.prob_heads.0.head.std_layer.weight: copying a param with shape torch.Size([96, 304]) from checkpoint, the shape in current model is torch.Size([96, 1408]).
wandb: ERROR 	size mismatch for model.head.prob_heads.1.head.mean_layer.weight: copying a param with shape torch.Size([96, 304]) from checkpoint, the shape in current model is torch.Size([96, 1408]).
wandb: ERROR 	size mismatch for model.head.prob_heads.1.head.std_layer.weight: copying a param with shape torch.Size([96, 304]) from checkpoint, the shape in current model is torch.Size([96, 1408]).
wandb: ERROR 	size mismatch for model.head.prob_heads.2.head.mean_layer.weight: copying a param with shape torch.Size([96, 304]) from checkpoint, the shape in current model is torch.Size([96, 1408]).
wandb: ERROR 	size mismatch for model.head.prob_heads.2.head.std_layer.weight: copying a param with shape torch.Size([96, 304]) from checkpoint, the shape in current model is torch.Size([96, 1408]).
wandb: ERROR 	size mismatch for model.head.prob_heads.3.head.mean_layer.weight: copying a param with shape torch.Size([96, 304]) from checkpoint, the shape in current model is torch.Size([96, 1408]).
wandb: ERROR 	size mismatch for model.head.prob_heads.3.head.std_layer.weight: copying a param with shape torch.Size([96, 304]) from checkpoint, the shape in current model is torch.Size([96, 1408]).
wandb: ERROR 	size mismatch for model.head.prob_heads.4.head.mean_layer.weight: copying a param with shape torch.Size([96, 304]) from checkpoint, the shape in current model is torch.Size([96, 1408]).
wandb: ERROR 	size mismatch for model.head.prob_heads.4.head.std_layer.weight: copying a param with shape torch.Size([96, 304]) from checkpoint, the shape in current model is torch.Size([96, 1408]).
wandb: ERROR 	size mismatch for model.head.prob_heads.5.head.mean_layer.weight: copying a param with shape torch.Size([96, 304]) from checkpoint, the shape in current model is torch.Size([96, 1408]).
wandb: ERROR 	size mismatch for model.head.prob_heads.5.head.std_layer.weight: copying a param with shape torch.Size([96, 304]) from checkpoint, the shape in current model is torch.Size([96, 1408]).
wandb: ERROR 	size mismatch for model.head.prob_heads.6.head.mean_layer.weight: copying a param with shape torch.Size([96, 304]) from checkpoint, the shape in current model is torch.Size([96, 1408]).
wandb: ERROR 	size mismatch for model.head.prob_heads.6.head.std_layer.weight: copying a param with shape torch.Size([96, 304]) from checkpoint, the shape in current model is torch.Size([96, 1408]).
wandb: ERROR 
wandb: Agent Starting Run: frwfyiqp with config:
wandb: 	MODEL.PARAM.d_model: 8
wandb: 	MODEL.PARAM.decomposition: 0
wandb: 	MODEL.PARAM.distribution_type: student_t
wandb: 	MODEL.PARAM.dropout: 0.2553910872457879
wandb: 	MODEL.PARAM.e_layers: 5
wandb: 	MODEL.PARAM.fc_dropout: 0.39751455905336214
wandb: 	MODEL.PARAM.head_type: probabilistic
wandb: 	MODEL.PARAM.individual: 1
wandb: 	MODEL.PARAM.kernel_size: 64
wandb: 	MODEL.PARAM.n_heads: 8
wandb: 	MODEL.PARAM.patch_len: 64
wandb: 	MODEL.PARAM.stride: 16
wandb: 	MODEL.PARAM.subtract_last: 1
wandb: 	NORM_EACH_CHANNEL: True
wandb: 	NUM_EPOCHS: 100
wandb: 	OUTPUT_LEN: 96
wandb: 	RESCALE: False
wandb: 	SCALER.TYPE: MinMaxScaler
wandb: 	TRAIN.DATA.BATCH_SIZE: 64
wandb: 	TRAIN.LR_SCHEDULER.PARAM.gamma: 0.30990991840640564
wandb: 	TRAIN.LR_SCHEDULER.TYPE: MultiStepLR
wandb: 	TRAIN.OPTIM.PARAM.lr: 0.008328049699185578
wandb: 	TRAIN.OPTIM.PARAM.weight_decay: 0.000860076498994491
wandb: 	TRAIN.OPTIM.TYPE: Adam
wandb: 	TRAIN.RESUME_TRAINING: False
wandb: 	USE_WANDB: True
wandb: WARNING Ignoring project 'Prob_LTSF' when running a sweep.
wandb: WARNING Ignoring entity 'kai-reffert-university-mannheim' when running a sweep.
wandb: Tracking run with wandb version 0.19.9
wandb: Run data is saved locally in /home/kreffert/Probabilistic_LTSF/BasicTS/wandb/run-20250505_222136-frwfyiqp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run PatchTST_May_05_22_21
wandb: ‚≠êÔ∏è View project at https://wandb.ai/kai-reffert-university-mannheim/Prob_LTSF
wandb: üßπ View sweep at https://wandb.ai/kai-reffert-university-mannheim/Prob_LTSF/sweeps/fwvzje2j
wandb: üöÄ View run at https://wandb.ai/kai-reffert-university-mannheim/Prob_LTSF/runs/frwfyiqp
2025-05-05 22:21:37,585 - easytorch-sweep-agent - INFO - Starting sweep agent trial with configuration:
Update d_model to 8
Update decomposition to 0
Update distribution_type to student_t
Update dropout to 0.2553910872457879
Update e_layers to 5
Update fc_dropout to 0.39751455905336214
Update head_type to probabilistic
Update individual to 1
Update kernel_size to 64
Update n_heads to 8
Update patch_len to 64
Update stride to 16
Update subtract_last to 1
Update NORM_EACH_CHANNEL to True
Update NUM_EPOCHS to 100
Update OUTPUT_LEN to 96
Update RESCALE to False
Update TYPE to <class 'basicts.scaler.min_max_scaler.MinMaxScaler'>
Update BATCH_SIZE to 64
Update gamma to 0.30990991840640564
Update TYPE to MultiStepLR
Update lr to 0.008328049699185578
Update weight_decay to 0.000860076498994491
Update TYPE to Adam
Update RESUME_TRAINING to False
Update USE_WANDB to True
{'DESCRIPTION': 'An Example Config', 'GPU_NUM': 1, 'RUNNER': <class 'basicts.runners.runner_zoo.simple_prob_tsf_runner.SimpleProbTimeSeriesForecastingRunner'>, 'USE_WANDB': True, 'DATASET': {'NAME': 'ETTh1', 'TYPE': <class 'basicts.data.simple_tsf_dataset.TimeSeriesForecastingDataset'>, 'PARAM': {'dataset_name': 'ETTh1', 'train_val_test_ratio': [0.6, 0.2, 0.2], 'input_len': 336, 'output_len': 96}}, 'SCALER': {'TYPE': <class 'basicts.scaler.min_max_scaler.MinMaxScaler'>, 'PARAM': {'dataset_name': 'ETTh1', 'train_ratio': 0.6, 'norm_each_channel': True, 'rescale': False}}, 'MODEL': {'NAME': 'PatchTST', 'ARCH': <class 'baselines.PatchTST.arch.patchtst_arch.PatchTST'>, 'PARAM': {'enc_in': 7, 'seq_len': 336, 'pred_len': 96, 'e_layers': 5, 'n_heads': 8, 'd_model': 8, 'd_ff': 128, 'dropout': 0.2553910872457879, 'fc_dropout': 0.39751455905336214, 'head_dropout': 0.0, 'patch_len': 64, 'stride': 16, 'individual': 1, 'padding_patch': 'end', 'revin': 0, 'affine': 0, 'subtract_last': 1, 'decomposition': 0, 'kernel_size': 64, 'head_type': 'probabilistic', 'distribution_type': 'student_t', 'quantiles': []}, 'FORWARD_FEATURES': [0], 'TARGET_FEATURES': [0]}, 'METRICS': {'FUNCS': {'NLL': <function nll_loss at 0x7f0765438360>, 'CRPS': <function crps at 0x7f0766413420>}, 'TARGET': 'NLL', 'NULL_VAL': nan}, 'TRAIN': {'RESUME_TRAINING': False, 'EARLY_STOPPING_PATIENCE': 5, 'NUM_EPOCHS': 100, 'CKPT_SAVE_DIR': 'checkpoints/gaussian_PatchTST/ETTh1_100_336_96', 'LOSS': <function nll_loss at 0x7f0765438360>, 'OPTIM': {'TYPE': 'Adam', 'PARAM': {'lr': 0.008328049699185578, 'weight_decay': 0.000860076498994491}}, 'LR_SCHEDULER': {'TYPE': 'MultiStepLR', 'PARAM': {'milestones': [1, 25], 'gamma': 0.30990991840640564}}, 'CLIP_GRAD_PARAM': {'max_norm': 5.0}, 'DATA': {'BATCH_SIZE': 64, 'SHUFFLE': True}}, 'VAL': {'INTERVAL': 1, 'DATA': {'BATCH_SIZE': 64}}, 'TEST': {'INTERVAL': 1, 'DATA': {'BATCH_SIZE': 64}}, 'EVAL': {'USE_GPU': True}, 'MD5': 'b1a7fc8ebd65fd32cc59e1587d8e4831', 'NORM_EACH_CHANNEL': True, 'NUM_EPOCHS': 100, 'OUTPUT_LEN': 96, 'RESCALE': False}
2025-05-05 22:21:37,590 - easytorch-sweep-agent - INFO - Updated configuration with sweep parameters.
2025-05-05 22:21:37,590 - easytorch-launcher - INFO - Initializing runner '<class 'basicts.runners.runner_zoo.simple_prob_tsf_runner.SimpleProbTimeSeriesForecastingRunner'>'
2025-05-05 22:21:37,591 - easytorch-env - INFO - Disable TF32 mode
2025-05-05 22:21:37,591 - easytorch - INFO - Set ckpt save dir: 'checkpoints/gaussian_PatchTST/ETTh1_100_336_96/b1a7fc8ebd65fd32cc59e1587d8e4831'
2025-05-05 22:21:37,591 - easytorch - INFO - Building model.
PatchTST
2025-05-05 22:21:37,622 - easytorch-training - INFO - Initializing training.
2025-05-05 22:21:37,623 - easytorch-training - INFO - Set clip grad, param: {'max_norm': 5.0}
2025-05-05 22:21:37,623 - easytorch-training - INFO - Building training data loader.
2025-05-05 22:21:37,626 - easytorch-training - INFO - Train dataset length: 8209
2025-05-05 22:21:37,629 - easytorch-training - INFO - Set optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    decoupled_weight_decay: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.008328049699185578
    maximize: False
    weight_decay: 0.000860076498994491
)
2025-05-05 22:21:37,630 - easytorch-training - INFO - Set lr_scheduler: <torch.optim.lr_scheduler.MultiStepLR object at 0x7f074daa28d0>
2025-05-05 22:21:37,633 - easytorch-training - INFO - Initializing validation.
2025-05-05 22:21:37,633 - easytorch-training - INFO - Building val data loader.
2025-05-05 22:21:37,635 - easytorch-training - INFO - Validation dataset length: 2449
2025-05-05 22:21:37,637 - easytorch-training - INFO - Test dataset length: 2449
2025-05-05 22:21:37,638 - easytorch-training - INFO - Number of parameters: 321640
2025-05-05 22:21:37,638 - easytorch-training - INFO - Epoch 1 / 100
  0%|          | 0/129 [00:00<?, ?it/s]  1%|          | 1/129 [00:00<00:30,  4.23it/s]  2%|‚ñè         | 2/129 [00:00<00:20,  6.05it/s]  2%|‚ñè         | 3/129 [00:00<00:18,  6.81it/s]  3%|‚ñé         | 4/129 [00:00<00:16,  7.44it/s]  4%|‚ñç         | 5/129 [00:00<00:15,  7.97it/s]  5%|‚ñç         | 6/129 [00:00<00:14,  8.35it/s]  5%|‚ñå         | 7/129 [00:00<00:14,  8.55it/s]  6%|‚ñå         | 8/129 [00:01<00:13,  8.75it/s]  7%|‚ñã         | 9/129 [00:01<00:13,  8.89it/s]  8%|‚ñä         | 10/129 [00:01<00:13,  8.86it/s]  9%|‚ñä         | 11/129 [00:01<00:13,  8.90it/s]  9%|‚ñâ         | 12/129 [00:01<00:13,  8.99it/s] 10%|‚ñà         | 13/129 [00:01<00:12,  9.04it/s] 11%|‚ñà         | 14/129 [00:01<00:12,  9.09it/s] 12%|‚ñà‚ñè        | 15/129 [00:01<00:12,  9.12it/s] 12%|‚ñà‚ñè        | 16/129 [00:01<00:12,  9.17it/s] 13%|‚ñà‚ñé        | 17/129 [00:02<00:12,  9.15it/s] 14%|‚ñà‚ñç        | 18/129 [00:02<00:12,  9.11it/s] 15%|‚ñà‚ñç        | 19/129 [00:02<00:12,  9.07it/s] 16%|‚ñà‚ñå        | 20/129 [00:02<00:12,  9.01it/s] 16%|‚ñà‚ñã        | 21/129 [00:02<00:12,  8.99it/s] 17%|‚ñà‚ñã        | 22/129 [00:02<00:11,  8.96it/s] 18%|‚ñà‚ñä        | 23/129 [00:02<00:11,  8.98it/s] 19%|‚ñà‚ñä        | 24/129 [00:02<00:11,  8.99it/s] 19%|‚ñà‚ñâ        | 25/129 [00:02<00:11,  8.98it/s] 20%|‚ñà‚ñà        | 26/129 [00:03<00:11,  8.95it/s] 21%|‚ñà‚ñà        | 27/129 [00:03<00:11,  8.84it/s] 22%|‚ñà‚ñà‚ñè       | 28/129 [00:05<01:10,  1.43it/s] 22%|‚ñà‚ñà‚ñè       | 29/129 [00:05<00:52,  1.91it/s] 23%|‚ñà‚ñà‚ñé       | 30/129 [00:05<00:39,  2.50it/s] 24%|‚ñà‚ñà‚ñç       | 31/129 [00:05<00:30,  3.17it/s] 25%|‚ñà‚ñà‚ñç       | 32/129 [00:05<00:24,  3.93it/s] 26%|‚ñà‚ñà‚ñå       | 33/129 [00:05<00:20,  4.72it/s] 26%|‚ñà‚ñà‚ñã       | 34/129 [00:05<00:17,  5.51it/s] 27%|‚ñà‚ñà‚ñã       | 35/129 [00:05<00:15,  6.20it/s] 28%|‚ñà‚ñà‚ñä       | 36/129 [00:06<00:13,  6.80it/s] 29%|‚ñà‚ñà‚ñä       | 37/129 [00:06<00:12,  7.26it/s] 29%|‚ñà‚ñà‚ñâ       | 38/129 [00:06<00:11,  7.66it/s] 30%|‚ñà‚ñà‚ñà       | 39/129 [00:06<00:11,  7.95it/s] 31%|‚ñà‚ñà‚ñà       | 40/129 [00:06<00:10,  8.24it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 41/129 [00:06<00:10,  8.32it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 42/129 [00:06<00:10,  8.49it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 43/129 [00:06<00:09,  8.63it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 44/129 [00:07<00:09,  8.71it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 45/129 [00:07<00:09,  8.78it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 46/129 [00:07<00:09,  8.83it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 47/129 [00:07<00:09,  8.82it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 48/129 [00:07<00:09,  8.87it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 49/129 [00:07<00:08,  8.98it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 50/129 [00:07<00:08,  9.03it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 51/129 [00:07<00:08,  9.04it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 52/129 [00:07<00:08,  9.04it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 53/129 [00:08<00:08,  9.05it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 54/129 [00:08<00:08,  9.06it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 55/129 [00:08<00:08,  9.09it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 56/129 [00:08<00:08,  9.08it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 57/129 [00:08<00:07,  9.06it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 58/129 [00:08<00:07,  9.08it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 59/129 [00:08<00:07,  9.10it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 60/129 [00:08<00:07,  9.14it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 61/129 [00:08<00:07,  9.07it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 62/129 [00:09<00:07,  9.07it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 63/129 [00:09<00:07,  9.08it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 64/129 [00:09<00:07,  9.12it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 65/129 [00:09<00:07,  9.10it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 66/129 [00:09<00:06,  9.09it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 67/129 [00:09<00:06,  9.10it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 68/129 [00:09<00:06,  9.07it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 69/129 [00:09<00:06,  9.10it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 70/129 [00:09<00:06,  9.12it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 71/129 [00:10<00:06,  9.02it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 72/129 [00:10<00:06,  8.85it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 73/129 [00:10<00:06,  8.83it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 74/129 [00:10<00:06,  8.87it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 75/129 [00:10<00:06,  8.86it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 76/129 [00:10<00:05,  8.89it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 77/129 [00:10<00:05,  8.93it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 78/129 [00:10<00:05,  8.98it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 79/129 [00:10<00:05,  8.99it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 80/129 [00:11<00:05,  8.98it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 81/129 [00:11<00:05,  8.92it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 82/129 [00:11<00:05,  8.94it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 83/129 [00:11<00:05,  9.01it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 84/129 [00:11<00:04,  9.09it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 85/129 [00:11<00:04,  9.13it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 86/129 [00:11<00:04,  9.14it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 87/129 [00:11<00:04,  9.11it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 88/129 [00:11<00:04,  9.12it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 89/129 [00:12<00:04,  9.09it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 90/129 [00:12<00:04,  9.06it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 91/129 [00:12<00:04,  8.99it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 92/129 [00:12<00:04,  9.00it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 93/129 [00:12<00:03,  9.01it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 94/129 [00:12<00:03,  8.98it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 95/129 [00:12<00:03,  9.01it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 96/129 [00:12<00:03,  9.05it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 97/129 [00:12<00:03,  9.09it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 98/129 [00:12<00:03,  9.15it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 99/129 [00:13<00:03,  9.15it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 100/129 [00:13<00:03,  9.22it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 101/129 [00:13<00:03,  9.15it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 102/129 [00:13<00:02,  9.13it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 103/129 [00:13<00:02,  9.12it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 104/129 [00:13<00:02,  9.11it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 105/129 [00:13<00:02,  9.13it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 106/129 [00:13<00:02,  9.10it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 107/129 [00:13<00:02,  9.03it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 108/129 [00:14<00:02,  9.03it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 109/129 [00:14<00:02,  9.03it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 110/129 [00:14<00:02,  9.06it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 111/129 [00:14<00:01,  9.02it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 112/129 [00:14<00:01,  9.12it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 113/129 [00:14<00:01,  9.10it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 114/129 [00:14<00:01,  9.13it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 115/129 [00:14<00:01,  9.01it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 116/129 [00:14<00:01,  8.98it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 117/129 [00:15<00:01,  9.02it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 118/129 [00:15<00:01,  9.04it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 119/129 [00:15<00:01,  8.88it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 120/129 [00:15<00:01,  8.87it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 121/129 [00:15<00:00,  8.85it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 122/129 [00:15<00:00,  8.92it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 123/129 [00:15<00:00,  8.95it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 124/129 [00:15<00:00,  9.04it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 125/129 [00:15<00:00,  9.05it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 126/129 [00:16<00:00,  9.04it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 127/129 [00:16<00:00,  9.10it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 128/129 [00:16<00:00,  9.09it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 129/129 [00:16<00:00,  7.87it/s]
2025-05-05 22:21:54,028 - easytorch-training - INFO - Result <train>: [train/time: 16.39 (s), train/lr: 8.33e-03, train/loss: -0.4068, train/NLL: -0.4068, train/CRPS: 0.2428]
2025-05-05 22:21:54,031 - easytorch-training - INFO - Start validation.
  0%|          | 0/39 [00:00<?, ?it/s]  5%|‚ñå         | 2/39 [00:00<00:02, 14.76it/s] 10%|‚ñà         | 4/39 [00:00<00:02, 14.55it/s] 15%|‚ñà‚ñå        | 6/39 [00:00<00:02, 14.62it/s] 21%|‚ñà‚ñà        | 8/39 [00:00<00:02, 14.85it/s] 26%|‚ñà‚ñà‚ñå       | 10/39 [00:00<00:01, 15.07it/s] 31%|‚ñà‚ñà‚ñà       | 12/39 [00:00<00:01, 15.30it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 14/39 [00:00<00:01, 15.35it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 16/39 [00:01<00:01, 15.21it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 18/39 [00:01<00:01, 15.14it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 20/39 [00:01<00:01, 15.11it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 22/39 [00:01<00:01, 15.34it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 24/39 [00:01<00:00, 15.46it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 26/39 [00:01<00:00, 15.42it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 28/39 [00:01<00:00, 15.50it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 30/39 [00:01<00:00, 15.54it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 32/39 [00:02<00:00, 15.55it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 34/39 [00:02<00:00, 15.34it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 36/39 [00:02<00:00, 15.44it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 38/39 [00:02<00:00, 15.55it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 39/39 [00:02<00:00, 15.49it/s]
2025-05-05 22:21:56,552 - easytorch-training - INFO - Result <val>: [val/time: 2.52 (s), val/loss: -0.3261, val/NLL: -0.3261, val/CRPS: 0.0939]
2025-05-05 22:21:56,627 - easytorch-training - INFO - Checkpoint checkpoints/gaussian_PatchTST/ETTh1_100_336_96/b1a7fc8ebd65fd32cc59e1587d8e4831/PatchTST_best_val_NLL.pt saved
  0%|          | 0/39 [00:00<?, ?it/s] 15%|‚ñà‚ñå        | 6/39 [00:00<00:00, 51.83it/s] 31%|‚ñà‚ñà‚ñà       | 12/39 [00:00<00:00, 53.00it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 18/39 [00:00<00:00, 54.32it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 24/39 [00:00<00:00, 55.86it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 30/39 [00:00<00:00, 56.16it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 36/39 [00:00<00:00, 54.74it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 39/39 [00:00<00:00, 54.54it/s]
2025-05-05 22:21:59,037 - easytorch-training - INFO - Result <test>: [test/time: 2.41 (s), test/loss: -0.4919, test/NLL: -0.4895, test/CRPS: 0.0780]
2025-05-05 22:21:59,122 - easytorch-training - INFO - Checkpoint checkpoints/gaussian_PatchTST/ETTh1_100_336_96/b1a7fc8ebd65fd32cc59e1587d8e4831/PatchTST_001.pt saved
2025-05-05 22:21:59,124 - easytorch-training - INFO - The estimated training finish time is 2025-05-05 22:57:26
2025-05-05 22:21:59,124 - easytorch-training - INFO - Epoch 2 / 100
  0%|          | 0/129 [00:00<?, ?it/s]  1%|          | 1/129 [00:00<00:16,  7.84it/s]  2%|‚ñè         | 2/129 [00:00<00:15,  8.46it/s]  2%|‚ñè         | 3/129 [00:00<00:14,  8.67it/s]  3%|‚ñé         | 4/129 [00:00<00:14,  8.81it/s]  4%|‚ñç         | 5/129 [00:00<00:13,  8.96it/s]  5%|‚ñç         | 6/129 [00:00<00:13,  8.99it/s]  5%|‚ñå         | 7/129 [00:00<00:13,  8.95it/s]  6%|‚ñå         | 8/129 [00:00<00:13,  8.95it/s]  7%|‚ñã         | 9/129 [00:01<00:13,  8.98it/s]  8%|‚ñä         | 10/129 [00:01<00:13,  8.99it/s]  9%|‚ñä         | 11/129 [00:01<00:13,  8.95it/s]  9%|‚ñâ         | 12/129 [00:01<00:13,  9.00it/s] 10%|‚ñà         | 13/129 [00:01<00:12,  9.01it/s] 11%|‚ñà         | 14/129 [00:01<00:12,  9.02it/s] 12%|‚ñà‚ñè        | 15/129 [00:01<00:12,  9.09it/s] 12%|‚ñà‚ñè        | 16/129 [00:01<00:12,  9.07it/s] 13%|‚ñà‚ñé        | 17/129 [00:01<00:12,  9.09it/s] 14%|‚ñà‚ñç        | 18/129 [00:02<00:12,  9.14it/s] 15%|‚ñà‚ñç        | 19/129 [00:02<00:12,  9.12it/s] 16%|‚ñà‚ñå        | 20/129 [00:02<00:11,  9.12it/s] 16%|‚ñà‚ñã        | 21/129 [00:02<00:11,  9.03it/s] 17%|‚ñà‚ñã        | 22/129 [00:02<00:11,  9.06it/s] 18%|‚ñà‚ñä        | 23/129 [00:02<00:11,  9.06it/s] 19%|‚ñà‚ñä        | 24/129 [00:02<00:11,  9.00it/s] 19%|‚ñà‚ñâ        | 25/129 [00:02<00:11,  8.95it/s] 20%|‚ñà‚ñà        | 26/129 [00:02<00:11,  9.02it/s] 21%|‚ñà‚ñà        | 27/129 [00:03<00:11,  9.01it/s] 22%|‚ñà‚ñà‚ñè       | 28/129 [00:03<00:11,  9.02it/s] 22%|‚ñà‚ñà‚ñè       | 29/129 [00:03<00:11,  9.02it/s] 23%|‚ñà‚ñà‚ñé       | 30/129 [00:03<00:10,  9.11it/s] 24%|‚ñà‚ñà‚ñç       | 31/129 [00:03<00:10,  9.01it/s] 25%|‚ñà‚ñà‚ñç       | 32/129 [00:03<00:10,  9.01it/s] 26%|‚ñà‚ñà‚ñå       | 33/129 [00:03<00:10,  9.00it/s] 26%|‚ñà‚ñà‚ñã       | 34/129 [00:03<00:10,  9.04it/s] 27%|‚ñà‚ñà‚ñã       | 35/129 [00:03<00:10,  8.97it/s] 28%|‚ñà‚ñà‚ñä       | 36/129 [00:04<00:10,  8.91it/s] 29%|‚ñà‚ñà‚ñä       | 37/129 [00:04<00:10,  8.90it/s] 29%|‚ñà‚ñà‚ñâ       | 38/129 [00:04<00:10,  8.93it/s] 30%|‚ñà‚ñà‚ñà       | 39/129 [00:04<00:10,  8.96it/s] 31%|‚ñà‚ñà‚ñà       | 40/129 [00:04<00:09,  8.94it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 41/129 [00:04<00:09,  8.85it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 42/129 [00:04<00:09,  8.88it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 43/129 [00:04<00:09,  8.93it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 44/129 [00:04<00:09,  8.99it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 45/129 [00:05<00:09,  8.96it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 46/129 [00:05<00:09,  8.96it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 47/129 [00:05<00:09,  9.00it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 48/129 [00:05<00:08,  9.07it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 49/129 [00:05<00:08,  9.12it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 50/129 [00:05<00:08,  9.13it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 51/129 [00:05<00:08,  9.08it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 52/129 [00:05<00:08,  9.09it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 53/129 [00:05<00:08,  9.12it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 54/129 [00:06<00:08,  9.12it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 55/129 [00:06<00:08,  9.17it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 56/129 [00:06<00:07,  9.15it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 57/129 [00:06<00:07,  9.11it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 58/129 [00:06<00:07,  9.11it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 59/129 [00:06<00:07,  9.07it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 60/129 [00:06<00:07,  9.09it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 61/129 [00:06<00:07,  9.05it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 62/129 [00:06<00:07,  9.05it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 63/129 [00:06<00:07,  9.10it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 64/129 [00:07<00:07,  9.10it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 65/129 [00:07<00:07,  9.08it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 66/129 [00:07<00:06,  9.08it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 67/129 [00:07<00:06,  9.05it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 68/129 [00:07<00:06,  9.06it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 69/129 [00:07<00:06,  9.06it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 70/129 [00:07<00:06,  8.99it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 71/129 [00:07<00:06,  8.80it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 72/129 [00:08<00:06,  8.79it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 73/129 [00:08<00:06,  8.85it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 74/129 [00:08<00:06,  8.92it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 75/129 [00:08<00:06,  8.89it/s]wandb: WARNING Tried to log to step 129 that is less than the current step 130. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 76/129 [00:08<00:06,  8.81it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 77/129 [00:08<00:05,  8.87it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 78/129 [00:08<00:05,  8.91it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 79/129 [00:08<00:05,  8.88it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 80/129 [00:08<00:05,  8.90it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 81/129 [00:09<00:05,  8.89it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 82/129 [00:09<00:05,  8.93it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 83/129 [00:09<00:05,  8.80it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 84/129 [00:09<00:05,  8.88it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 85/129 [00:09<00:04,  8.86it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 86/129 [00:09<00:04,  8.89it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 87/129 [00:09<00:04,  8.95it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 88/129 [00:09<00:04,  8.97it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 89/129 [00:09<00:04,  8.95it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 90/129 [00:10<00:04,  8.99it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 91/129 [00:10<00:04,  8.90it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 92/129 [00:10<00:04,  8.94it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 93/129 [00:10<00:04,  8.95it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 94/129 [00:10<00:03,  9.00it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 95/129 [00:10<00:03,  9.04it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 96/129 [00:10<00:03,  9.04it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 97/129 [00:10<00:03,  9.03it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 98/129 [00:10<00:03,  9.02it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 99/129 [00:11<00:03,  9.02it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 100/129 [00:11<00:03,  8.98it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 101/129 [00:11<00:03,  8.90it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 102/129 [00:11<00:03,  8.90it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 103/129 [00:11<00:02,  8.93it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 104/129 [00:11<00:02,  8.94it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 105/129 [00:11<00:02,  8.94it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 106/129 [00:11<00:02,  8.93it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 107/129 [00:11<00:02,  8.95it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 108/129 [00:12<00:02,  8.98it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 109/129 [00:12<00:02,  8.97it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 110/129 [00:12<00:02,  8.94it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 111/129 [00:12<00:02,  8.94it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 112/129 [00:12<00:01,  8.98it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 113/129 [00:12<00:01,  8.98it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 114/129 [00:12<00:01,  8.97it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 115/129 [00:12<00:01,  8.96it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 116/129 [00:12<00:01,  8.94it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 117/129 [00:13<00:01,  8.96it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 118/129 [00:13<00:01,  8.96it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 119/129 [00:13<00:01,  8.97it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 120/129 [00:13<00:01,  8.99it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 121/129 [00:13<00:00,  8.95it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 122/129 [00:13<00:00,  8.97it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 123/129 [00:13<00:00,  9.03it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 124/129 [00:13<00:00,  9.04it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 125/129 [00:13<00:00,  9.03it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 126/129 [00:14<00:00,  9.05it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 127/129 [00:14<00:00,  8.90it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 128/129 [00:14<00:00,  8.90it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 129/129 [00:14<00:00,  9.00it/s]
2025-05-05 22:22:13,460 - easytorch-training - INFO - Result <train>: [train/time: 14.33 (s), train/lr: 2.58e-03, train/loss: -0.8383, train/NLL: -0.8383, train/CRPS: 0.1543]
2025-05-05 22:22:13,463 - easytorch-training - INFO - Start validation.
  0%|          | 0/39 [00:00<?, ?it/s]  5%|‚ñå         | 2/39 [00:00<00:02, 13.95it/s] 10%|‚ñà         | 4/39 [00:00<00:02, 14.29it/s] 15%|‚ñà‚ñå        | 6/39 [00:00<00:02, 14.43it/s] 21%|‚ñà‚ñà        | 8/39 [00:00<00:02, 14.61it/s] 26%|‚ñà‚ñà‚ñå       | 10/39 [00:00<00:01, 14.77it/s] 31%|‚ñà‚ñà‚ñà       | 12/39 [00:00<00:01, 14.96it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 14/39 [00:00<00:01, 15.06it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 16/39 [00:01<00:01, 14.88it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 18/39 [00:01<00:01, 14.98it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 20/39 [00:01<00:01, 15.07it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 22/39 [00:01<00:01, 15.22it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 24/39 [00:01<00:00, 15.31it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 26/39 [00:01<00:00, 15.36it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 28/39 [00:01<00:00, 15.43it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 30/39 [00:01<00:00, 15.44it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 32/39 [00:02<00:00, 15.53it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 34/39 [00:02<00:00, 15.44it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 36/39 [00:02<00:00, 15.59it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 38/39 [00:02<00:00, 15.78it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 39/39 [00:02<00:00, 15.41it/s]
2025-05-05 22:22:15,998 - easytorch-training - INFO - Result <val>: [val/time: 2.53 (s), val/loss: -0.6373, val/NLL: -0.6373, val/CRPS: 0.0730]
2025-05-05 22:22:16,078 - easytorch-training - INFO - Checkpoint checkpoints/gaussian_PatchTST/ETTh1_100_336_96/b1a7fc8ebd65fd32cc59e1587d8e4831/PatchTST_best_val_NLL.pt saved
  0%|          | 0/39 [00:00<?, ?it/s] 13%|‚ñà‚ñé        | 5/39 [00:00<00:00, 47.69it/s] 28%|‚ñà‚ñà‚ñä       | 11/39 [00:00<00:00, 50.45it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 17/39 [00:00<00:00, 51.20it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 23/39 [00:00<00:00, 51.39it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 29/39 [00:00<00:00, 51.32it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 35/39 [00:00<00:00, 52.21it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 39/39 [00:00<00:00, 51.71it/s]
2025-05-05 22:22:18,472 - easytorch-training - INFO - Result <test>: [test/time: 2.39 (s), test/loss: -0.8462, test/NLL: -0.8443, test/CRPS: 0.0581]
2025-05-05 22:22:18,556 - easytorch-training - INFO - Checkpoint checkpoints/gaussian_PatchTST/ETTh1_100_336_96/b1a7fc8ebd65fd32cc59e1587d8e4831/PatchTST_002.pt saved
2025-05-05 22:22:18,558 - easytorch-training - INFO - The estimated training finish time is 2025-05-05 22:55:43
2025-05-05 22:22:18,559 - easytorch-training - INFO - Epoch 3 / 100
  0%|          | 0/129 [00:00<?, ?it/s]  1%|          | 1/129 [00:00<00:16,  7.58it/s]  2%|‚ñè         | 2/129 [00:00<00:15,  8.36it/s]  2%|‚ñè         | 3/129 [00:00<00:14,  8.54it/s]  3%|‚ñé         | 4/129 [00:00<00:14,  8.80it/s]  4%|‚ñç         | 5/129 [00:00<00:13,  8.91it/s]  5%|‚ñç         | 6/129 [00:00<00:13,  8.93it/s]  5%|‚ñå         | 7/129 [00:00<00:13,  8.99it/s]  6%|‚ñå         | 8/129 [00:00<00:13,  9.07it/s]  7%|‚ñã         | 9/129 [00:01<00:13,  9.06it/s]  8%|‚ñä         | 10/129 [00:01<00:13,  9.02it/s]  9%|‚ñä         | 11/129 [00:01<00:13,  8.96it/s]  9%|‚ñâ         | 12/129 [00:01<00:13,  8.98it/s] 10%|‚ñà         | 13/129 [00:01<00:12,  9.03it/s] 11%|‚ñà         | 14/129 [00:01<00:12,  9.04it/s] 12%|‚ñà‚ñè        | 15/129 [00:01<00:12,  9.07it/s] 12%|‚ñà‚ñè        | 16/129 [00:01<00:12,  9.15it/s] 13%|‚ñà‚ñé        | 17/129 [00:01<00:12,  9.14it/s] 14%|‚ñà‚ñç        | 18/129 [00:02<00:12,  9.11it/s] 15%|‚ñà‚ñç        | 19/129 [00:02<00:12,  9.06it/s] 16%|‚ñà‚ñå        | 20/129 [00:02<00:11,  9.10it/s] 16%|‚ñà‚ñã        | 21/129 [00:02<00:11,  9.03it/s] 17%|‚ñà‚ñã        | 22/129 [00:02<00:11,  9.04it/s] 18%|‚ñà‚ñä        | 23/129 [00:02<00:11,  9.08it/s] 19%|‚ñà‚ñä        | 24/129 [00:02<00:11,  9.00it/s] 19%|‚ñà‚ñâ        | 25/129 [00:02<00:11,  9.02it/s] 20%|‚ñà‚ñà        | 26/129 [00:02<00:11,  9.04it/s] 21%|‚ñà‚ñà        | 27/129 [00:03<00:11,  9.09it/s] 22%|‚ñà‚ñà‚ñè       | 28/129 [00:03<00:11,  9.08it/s] 22%|‚ñà‚ñà‚ñè       | 29/129 [00:03<00:11,  9.06it/s] 23%|‚ñà‚ñà‚ñé       | 30/129 [00:03<00:10,  9.08it/s] 24%|‚ñà‚ñà‚ñç       | 31/129 [00:03<00:10,  9.06it/s] 25%|‚ñà‚ñà‚ñç       | 32/129 [00:03<00:10,  9.07it/s] 26%|‚ñà‚ñà‚ñå       | 33/129 [00:03<00:10,  9.01it/s] 26%|‚ñà‚ñà‚ñã       | 34/129 [00:03<00:10,  8.96it/s] 27%|‚ñà‚ñà‚ñã       | 35/129 [00:03<00:10,  8.94it/s] 28%|‚ñà‚ñà‚ñä       | 36/129 [00:04<00:10,  8.92it/s] 29%|‚ñà‚ñà‚ñä       | 37/129 [00:04<00:10,  8.94it/s] 29%|‚ñà‚ñà‚ñâ       | 38/129 [00:04<00:10,  8.97it/s] 30%|‚ñà‚ñà‚ñà       | 39/129 [00:04<00:10,  8.93it/s] 31%|‚ñà‚ñà‚ñà       | 40/129 [00:04<00:10,  8.90it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 41/129 [00:04<00:09,  8.81it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 42/129 [00:04<00:09,  8.81it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 43/129 [00:04<00:09,  8.87it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 44/129 [00:04<00:09,  8.96it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 45/129 [00:05<00:09,  9.00it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 46/129 [00:05<00:09,  8.99it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 47/129 [00:05<00:09,  9.04it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 48/129 [00:05<00:09,  8.82it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 49/129 [00:05<00:09,  8.81it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 50/129 [00:05<00:08,  8.88it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 51/129 [00:05<00:08,  8.95it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 52/129 [00:05<00:08,  9.03it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 53/129 [00:05<00:08,  8.99it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 54/129 [00:06<00:08,  9.02it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 55/129 [00:06<00:08,  9.03it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 56/129 [00:06<00:08,  9.05it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 57/129 [00:06<00:07,  9.03it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 58/129 [00:06<00:07,  9.02it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 59/129 [00:06<00:07,  9.04it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 60/129 [00:06<00:07,  9.04it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 61/129 [00:06<00:07,  9.02it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 62/129 [00:06<00:07,  9.04it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 63/129 [00:07<00:07,  9.05it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 64/129 [00:07<00:07,  9.07it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 65/129 [00:07<00:07,  9.03it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 66/129 [00:07<00:06,  9.03it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 67/129 [00:07<00:06,  9.05it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 68/129 [00:07<00:06,  9.05it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 69/129 [00:07<00:06,  9.09it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 70/129 [00:07<00:06,  9.06it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 71/129 [00:07<00:06,  8.97it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 72/129 [00:08<00:06,  8.96it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 73/129 [00:08<00:06,  8.97it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 74/129 [00:08<00:06,  8.97it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 75/129 [00:08<00:05,  9.03it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 76/129 [00:08<00:05,  9.08it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 77/129 [00:08<00:05,  9.08it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 78/129 [00:08<00:05,  9.03it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 79/129 [00:08<00:05,  9.01it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 80/129 [00:08<00:05,  9.02it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 81/129 [00:09<00:05,  8.93it/s]wandb: WARNING Tried to log to step 258 that is less than the current step 259. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 82/129 [00:09<00:05,  8.88it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 83/129 [00:09<00:05,  8.91it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 84/129 [00:09<00:05,  8.94it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 85/129 [00:09<00:04,  8.98it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 86/129 [00:09<00:04,  8.98it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 87/129 [00:09<00:04,  9.01it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 88/129 [00:09<00:04,  9.03it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 89/129 [00:09<00:04,  9.06it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 90/129 [00:10<00:04,  9.04it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 91/129 [00:10<00:04,  8.98it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 92/129 [00:10<00:04,  9.02it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 93/129 [00:10<00:03,  9.01it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 94/129 [00:10<00:03,  8.81it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 95/129 [00:10<00:03,  8.87it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 96/129 [00:10<00:03,  8.83it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 97/129 [00:10<00:03,  8.90it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 98/129 [00:10<00:03,  8.93it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 99/129 [00:11<00:03,  8.94it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 100/129 [00:11<00:03,  8.96it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 101/129 [00:11<00:03,  8.95it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 102/129 [00:11<00:03,  8.96it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 103/129 [00:11<00:02,  9.01it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 104/129 [00:11<00:02,  9.12it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 105/129 [00:11<00:02,  9.15it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 106/129 [00:11<00:02,  9.14it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 107/129 [00:11<00:02,  9.08it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 108/129 [00:12<00:02,  9.13it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 109/129 [00:12<00:02,  9.11it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 110/129 [00:12<00:02,  9.09it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 111/129 [00:12<00:02,  9.00it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 112/129 [00:12<00:01,  9.07it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 113/129 [00:12<00:01,  9.03it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 114/129 [00:12<00:01,  9.02it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 115/129 [00:12<00:01,  9.04it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 116/129 [00:12<00:01,  9.10it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 117/129 [00:13<00:01,  9.11it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 118/129 [00:13<00:01,  9.10it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 119/129 [00:13<00:01,  9.13it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 120/129 [00:13<00:00,  9.04it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 121/129 [00:13<00:00,  8.94it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 122/129 [00:13<00:00,  8.91it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 123/129 [00:13<00:00,  8.92it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 124/129 [00:13<00:00,  8.92it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 125/129 [00:13<00:00,  8.94it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 126/129 [00:14<00:00,  8.98it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 127/129 [00:14<00:00,  8.99it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 128/129 [00:14<00:00,  9.03it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 129/129 [00:14<00:00,  9.02it/s]
2025-05-05 22:22:32,868 - easytorch-training - INFO - Result <train>: [train/time: 14.31 (s), train/lr: 2.58e-03, train/loss: -0.9114, train/NLL: -0.9114, train/CRPS: 0.1252]
2025-05-05 22:22:32,872 - easytorch-training - INFO - Start validation.
  0%|          | 0/39 [00:00<?, ?it/s]  5%|‚ñå         | 2/39 [00:00<00:02, 14.55it/s] 10%|‚ñà         | 4/39 [00:00<00:02, 14.46it/s] 15%|‚ñà‚ñå        | 6/39 [00:00<00:02, 14.79it/s] 21%|‚ñà‚ñà        | 8/39 [00:00<00:02, 14.91it/s] 26%|‚ñà‚ñà‚ñå       | 10/39 [00:00<00:01, 15.12it/s] 31%|‚ñà‚ñà‚ñà       | 12/39 [00:00<00:01, 15.20it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 14/39 [00:00<00:01, 15.29it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 16/39 [00:01<00:01, 15.10it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 18/39 [00:01<00:01, 15.10it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 20/39 [00:01<00:01, 14.91it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 22/39 [00:01<00:01, 15.06it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 24/39 [00:01<00:00, 15.23it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 26/39 [00:01<00:00, 15.23it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 28/39 [00:01<00:00, 15.14it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 30/39 [00:01<00:00, 15.17it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 32/39 [00:02<00:00, 15.28it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 34/39 [00:02<00:00, 15.20it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 36/39 [00:02<00:00, 15.31it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 38/39 [00:02<00:00, 15.50it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 39/39 [00:02<00:00, 15.37it/s]
2025-05-05 22:22:35,414 - easytorch-training - INFO - Result <val>: [val/time: 2.54 (s), val/loss: -0.4930, val/NLL: -0.4930, val/CRPS: 0.0821]
  0%|          | 0/39 [00:00<?, ?it/s] 15%|‚ñà‚ñå        | 6/39 [00:00<00:00, 50.85it/s] 31%|‚ñà‚ñà‚ñà       | 12/39 [00:00<00:00, 51.68it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 18/39 [00:00<00:00, 52.13it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 24/39 [00:00<00:00, 53.01it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 30/39 [00:00<00:00, 52.94it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 36/39 [00:00<00:00, 52.59it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 39/39 [00:00<00:00, 52.69it/s]
2025-05-05 22:22:37,824 - easytorch-training - INFO - Result <test>: [test/time: 2.41 (s), test/loss: -0.7052, test/NLL: -0.7016, test/CRPS: 0.0666]
2025-05-05 22:22:37,909 - easytorch-training - INFO - Checkpoint checkpoints/gaussian_PatchTST/ETTh1_100_336_96/b1a7fc8ebd65fd32cc59e1587d8e4831/PatchTST_003.pt saved
2025-05-05 22:22:37,911 - easytorch-training - INFO - The estimated training finish time is 2025-05-05 22:55:06
2025-05-05 22:22:37,912 - easytorch-training - INFO - Epoch 4 / 100
  0%|          | 0/129 [00:00<?, ?it/s]  1%|          | 1/129 [00:00<00:16,  7.90it/s]  2%|‚ñè         | 2/129 [00:00<00:15,  8.43it/s]  2%|‚ñè         | 3/129 [00:00<00:14,  8.63it/s]  3%|‚ñé         | 4/129 [00:00<00:14,  8.81it/s]  4%|‚ñç         | 5/129 [00:00<00:13,  8.88it/s]  5%|‚ñç         | 6/129 [00:00<00:13,  8.91it/s]  5%|‚ñå         | 7/129 [00:00<00:13,  8.92it/s]  6%|‚ñå         | 8/129 [00:00<00:13,  8.96it/s]  7%|‚ñã         | 9/129 [00:01<00:13,  8.96it/s]  8%|‚ñä         | 10/129 [00:01<00:13,  8.97it/s]  9%|‚ñä         | 11/129 [00:01<00:13,  8.91it/s]  9%|‚ñâ         | 12/129 [00:01<00:13,  8.92it/s] 10%|‚ñà         | 13/129 [00:01<00:13,  8.71it/s] 11%|‚ñà         | 14/129 [00:01<00:13,  8.68it/s] 12%|‚ñà‚ñè        | 15/129 [00:01<00:12,  8.77it/s] 12%|‚ñà‚ñè        | 16/129 [00:01<00:12,  8.81it/s] 13%|‚ñà‚ñé        | 17/129 [00:01<00:12,  8.88it/s] 14%|‚ñà‚ñç        | 18/129 [00:02<00:12,  8.90it/s] 15%|‚ñà‚ñç        | 19/129 [00:02<00:12,  8.91it/s] 16%|‚ñà‚ñå        | 20/129 [00:02<00:12,  8.93it/s] 16%|‚ñà‚ñã        | 21/129 [00:02<00:12,  8.85it/s] 17%|‚ñà‚ñã        | 22/129 [00:02<00:12,  8.88it/s] 18%|‚ñà‚ñä        | 23/129 [00:02<00:11,  8.92it/s] 19%|‚ñà‚ñä        | 24/129 [00:02<00:11,  8.96it/s] 19%|‚ñà‚ñâ        | 25/129 [00:02<00:11,  8.94it/s] 20%|‚ñà‚ñà        | 26/129 [00:02<00:11,  8.94it/s] 21%|‚ñà‚ñà        | 27/129 [00:03<00:11,  8.94it/s] 22%|‚ñà‚ñà‚ñè       | 28/129 [00:03<00:11,  8.90it/s] 22%|‚ñà‚ñà‚ñè       | 29/129 [00:03<00:11,  8.91it/s] 23%|‚ñà‚ñà‚ñé       | 30/129 [00:03<00:11,  8.94it/s] 24%|‚ñà‚ñà‚ñç       | 31/129 [00:03<00:11,  8.84it/s] 25%|‚ñà‚ñà‚ñç       | 32/129 [00:03<00:10,  8.87it/s] 26%|‚ñà‚ñà‚ñå       | 33/129 [00:03<00:10,  8.87it/s] 26%|‚ñà‚ñà‚ñã       | 34/129 [00:03<00:10,  8.89it/s] 27%|‚ñà‚ñà‚ñã       | 35/129 [00:03<00:10,  8.90it/s] 28%|‚ñà‚ñà‚ñä       | 36/129 [00:04<00:10,  8.91it/s] 29%|‚ñà‚ñà‚ñä       | 37/129 [00:04<00:10,  8.63it/s] 29%|‚ñà‚ñà‚ñâ       | 38/129 [00:04<00:10,  8.70it/s] 30%|‚ñà‚ñà‚ñà       | 39/129 [00:04<00:10,  8.76it/s] 31%|‚ñà‚ñà‚ñà       | 40/129 [00:04<00:10,  8.80it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 41/129 [00:04<00:10,  8.63it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 42/129 [00:04<00:10,  8.69it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 43/129 [00:04<00:09,  8.66it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 44/129 [00:04<00:09,  8.63it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 45/129 [00:05<00:09,  8.60it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 46/129 [00:05<00:09,  8.60it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 47/129 [00:05<00:09,  8.58it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 48/129 [00:05<00:09,  8.56it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 49/129 [00:05<00:09,  8.61it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 50/129 [00:05<00:09,  8.66it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 51/129 [00:05<00:09,  8.63it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 52/129 [00:05<00:08,  8.63it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 53/129 [00:06<00:08,  8.68it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 54/129 [00:06<00:08,  8.66it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 55/129 [00:06<00:08,  8.65it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 56/129 [00:06<00:08,  8.63it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 57/129 [00:06<00:08,  8.67it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 58/129 [00:06<00:08,  8.67it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 59/129 [00:06<00:08,  8.65it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 60/129 [00:06<00:07,  8.71it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 61/129 [00:06<00:07,  8.60it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 62/129 [00:07<00:07,  8.65it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 63/129 [00:07<00:07,  8.71it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 64/129 [00:07<00:07,  8.77it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 65/129 [00:07<00:07,  8.79it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 66/129 [00:07<00:07,  8.58it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 67/129 [00:07<00:07,  8.68it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 68/129 [00:07<00:06,  8.83it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 69/129 [00:07<00:06,  8.85it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 70/129 [00:07<00:06,  8.92it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 71/129 [00:08<00:06,  8.83it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 72/129 [00:08<00:06,  8.82it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 73/129 [00:08<00:06,  8.84it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 74/129 [00:08<00:06,  8.92it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 75/129 [00:08<00:06,  8.93it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 76/129 [00:08<00:05,  8.93it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 77/129 [00:08<00:05,  8.93it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 78/129 [00:08<00:05,  8.91it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 79/129 [00:08<00:05,  8.91it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 80/129 [00:09<00:05,  8.93it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 81/129 [00:09<00:05,  8.91it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 82/129 [00:09<00:05,  8.88it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 83/129 [00:09<00:05,  8.78it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 84/129 [00:09<00:05,  8.55it/s]wandb: WARNING Tried to log to step 387 that is less than the current step 388. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 85/129 [00:09<00:05,  8.63it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 86/129 [00:09<00:04,  8.69it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 87/129 [00:09<00:04,  8.79it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 88/129 [00:10<00:04,  8.82it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 89/129 [00:10<00:04,  8.86it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 90/129 [00:10<00:04,  8.86it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 91/129 [00:10<00:04,  8.84it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 92/129 [00:10<00:04,  8.86it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 93/129 [00:10<00:04,  8.89it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 94/129 [00:10<00:03,  8.91it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 95/129 [00:10<00:03,  8.95it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 96/129 [00:10<00:03,  8.70it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 97/129 [00:11<00:03,  8.70it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 98/129 [00:11<00:03,  8.74it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 99/129 [00:11<00:03,  8.80it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 100/129 [00:11<00:03,  8.86it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 101/129 [00:11<00:03,  8.75it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 102/129 [00:11<00:03,  8.83it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 103/129 [00:11<00:02,  8.87it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 104/129 [00:11<00:02,  8.75it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 105/129 [00:11<00:02,  8.68it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 106/129 [00:12<00:02,  8.73it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 107/129 [00:12<00:02,  8.80it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 108/129 [00:12<00:02,  8.87it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 109/129 [00:12<00:02,  8.92it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 110/129 [00:12<00:02,  8.98it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 111/129 [00:12<00:02,  8.94it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 112/129 [00:12<00:01,  8.92it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 113/129 [00:12<00:01,  8.97it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 114/129 [00:12<00:01,  9.00it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 115/129 [00:13<00:01,  8.93it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 116/129 [00:13<00:01,  8.89it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 117/129 [00:13<00:01,  8.89it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 118/129 [00:13<00:01,  8.96it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 119/129 [00:13<00:01,  8.98it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 120/129 [00:13<00:00,  9.04it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 121/129 [00:13<00:00,  9.02it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 122/129 [00:13<00:00,  8.99it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 123/129 [00:13<00:00,  8.96it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 124/129 [00:14<00:00,  8.99it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 125/129 [00:14<00:00,  9.01it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 126/129 [00:14<00:00,  9.04it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 127/129 [00:14<00:00,  9.04it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 128/129 [00:14<00:00,  8.95it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 129/129 [00:14<00:00,  8.84it/s]
2025-05-05 22:22:52,504 - easytorch-training - INFO - Result <train>: [train/time: 14.59 (s), train/lr: 2.58e-03, train/loss: -0.9133, train/NLL: -0.9133, train/CRPS: 0.1137]
2025-05-05 22:22:52,508 - easytorch-training - INFO - Start validation.
  0%|          | 0/39 [00:00<?, ?it/s]  5%|‚ñå         | 2/39 [00:00<00:02, 14.36it/s] 10%|‚ñà         | 4/39 [00:00<00:02, 14.60it/s] 15%|‚ñà‚ñå        | 6/39 [00:00<00:02, 14.74it/s] 21%|‚ñà‚ñà        | 8/39 [00:00<00:02, 14.71it/s] 26%|‚ñà‚ñà‚ñå       | 10/39 [00:00<00:01, 15.03it/s] 31%|‚ñà‚ñà‚ñà       | 12/39 [00:00<00:01, 15.26it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 14/39 [00:00<00:01, 15.43it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 16/39 [00:01<00:01, 15.28it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 18/39 [00:01<00:01, 15.34it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 20/39 [00:01<00:01, 15.40it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 22/39 [00:01<00:01, 15.70it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 24/39 [00:01<00:00, 15.84it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 26/39 [00:01<00:00, 15.75it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 28/39 [00:01<00:00, 15.77it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 30/39 [00:01<00:00, 15.76it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 32/39 [00:02<00:00, 15.77it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 34/39 [00:02<00:00, 15.67it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 36/39 [00:02<00:00, 15.42it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 38/39 [00:02<00:00, 15.65it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 39/39 [00:02<00:00, 15.64it/s]
2025-05-05 22:22:55,005 - easytorch-training - INFO - Result <val>: [val/time: 2.50 (s), val/loss: -0.7094, val/NLL: -0.7094, val/CRPS: 0.0695]
2025-05-05 22:22:55,080 - easytorch-training - INFO - Checkpoint checkpoints/gaussian_PatchTST/ETTh1_100_336_96/b1a7fc8ebd65fd32cc59e1587d8e4831/PatchTST_best_val_NLL.pt saved
  0%|          | 0/39 [00:00<?, ?it/s] 13%|‚ñà‚ñé        | 5/39 [00:00<00:00, 46.27it/s] 26%|‚ñà‚ñà‚ñå       | 10/39 [00:00<00:00, 47.05it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 16/39 [00:00<00:00, 50.19it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 22/39 [00:00<00:00, 51.50it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 28/39 [00:00<00:00, 51.98it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 34/39 [00:00<00:00, 52.54it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 39/39 [00:00<00:00, 51.84it/s]
2025-05-05 22:22:57,435 - easytorch-training - INFO - Result <test>: [test/time: 2.35 (s), test/loss: -0.9519, test/NLL: -0.9513, test/CRPS: 0.0539]
2025-05-05 22:22:57,520 - easytorch-training - INFO - Checkpoint checkpoints/gaussian_PatchTST/ETTh1_100_336_96/b1a7fc8ebd65fd32cc59e1587d8e4831/PatchTST_004.pt saved
2025-05-05 22:22:57,522 - easytorch-training - INFO - The estimated training finish time is 2025-05-05 22:54:54
2025-05-05 22:22:57,523 - easytorch-training - INFO - Epoch 5 / 100
  0%|          | 0/129 [00:00<?, ?it/s]  1%|          | 1/129 [00:00<00:16,  7.75it/s]  2%|‚ñè         | 2/129 [00:00<00:15,  8.34it/s]  2%|‚ñè         | 3/129 [00:00<00:14,  8.65it/s]  3%|‚ñé         | 4/129 [00:00<00:14,  8.79it/s]  4%|‚ñç         | 5/129 [00:00<00:13,  8.87it/s]  5%|‚ñç         | 6/129 [00:00<00:13,  8.89it/s]  5%|‚ñå         | 7/129 [00:00<00:13,  8.95it/s]  6%|‚ñå         | 8/129 [00:00<00:13,  9.00it/s]  7%|‚ñã         | 9/129 [00:01<00:13,  9.04it/s]  8%|‚ñä         | 10/129 [00:01<00:13,  9.08it/s]  9%|‚ñä         | 11/129 [00:01<00:13,  8.97it/s]  9%|‚ñâ         | 12/129 [00:01<00:13,  8.92it/s] 10%|‚ñà         | 13/129 [00:01<00:12,  8.93it/s] 11%|‚ñà         | 14/129 [00:01<00:13,  8.70it/s] 12%|‚ñà‚ñè        | 15/129 [00:01<00:12,  8.78it/s] 12%|‚ñà‚ñè        | 16/129 [00:01<00:12,  8.85it/s] 13%|‚ñà‚ñé        | 17/129 [00:01<00:12,  8.83it/s] 14%|‚ñà‚ñç        | 18/129 [00:02<00:12,  8.87it/s] 15%|‚ñà‚ñç        | 19/129 [00:02<00:12,  8.89it/s] 16%|‚ñà‚ñå        | 20/129 [00:02<00:12,  8.95it/s] 16%|‚ñà‚ñã        | 21/129 [00:02<00:12,  8.92it/s] 17%|‚ñà‚ñã        | 22/129 [00:02<00:12,  8.82it/s] 18%|‚ñà‚ñä        | 23/129 [00:02<00:12,  8.78it/s] 19%|‚ñà‚ñä        | 24/129 [00:02<00:11,  8.85it/s] 19%|‚ñà‚ñâ        | 25/129 [00:02<00:11,  8.93it/s] 20%|‚ñà‚ñà        | 26/129 [00:02<00:11,  8.95it/s] 21%|‚ñà‚ñà        | 27/129 [00:03<00:11,  8.96it/s] 22%|‚ñà‚ñà‚ñè       | 28/129 [00:03<00:11,  8.98it/s] 22%|‚ñà‚ñà‚ñè       | 29/129 [00:03<00:11,  9.02it/s] 23%|‚ñà‚ñà‚ñé       | 30/129 [00:03<00:10,  9.01it/s] 24%|‚ñà‚ñà‚ñç       | 31/129 [00:03<00:10,  8.93it/s] 25%|‚ñà‚ñà‚ñç       | 32/129 [00:03<00:10,  8.88it/s] 26%|‚ñà‚ñà‚ñå       | 33/129 [00:03<00:10,  8.92it/s] 26%|‚ñà‚ñà‚ñã       | 34/129 [00:03<00:10,  8.94it/s] 27%|‚ñà‚ñà‚ñã       | 35/129 [00:03<00:10,  8.86it/s] 28%|‚ñà‚ñà‚ñä       | 36/129 [00:04<00:10,  8.87it/s] 29%|‚ñà‚ñà‚ñä       | 37/129 [00:04<00:10,  8.90it/s] 29%|‚ñà‚ñà‚ñâ       | 38/129 [00:04<00:10,  8.94it/s] 30%|‚ñà‚ñà‚ñà       | 39/129 [00:04<00:10,  8.99it/s] 31%|‚ñà‚ñà‚ñà       | 40/129 [00:04<00:09,  9.01it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 41/129 [00:04<00:09,  8.94it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 42/129 [00:04<00:09,  8.95it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 43/129 [00:04<00:09,  8.94it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 44/129 [00:04<00:09,  8.97it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 45/129 [00:05<00:09,  9.04it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 46/129 [00:05<00:09,  9.01it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 47/129 [00:05<00:09,  9.00it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 48/129 [00:05<00:08,  9.03it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 49/129 [00:05<00:08,  8.98it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 50/129 [00:05<00:08,  8.95it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 51/129 [00:05<00:08,  8.92it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 52/129 [00:05<00:08,  8.92it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 53/129 [00:05<00:08,  8.96it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 54/129 [00:06<00:08,  8.58it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 55/129 [00:06<00:08,  8.66it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 56/129 [00:06<00:08,  8.75it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 57/129 [00:06<00:08,  8.79it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 58/129 [00:06<00:08,  8.85it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 59/129 [00:06<00:07,  8.91it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 60/129 [00:06<00:07,  8.91it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 61/129 [00:06<00:07,  8.90it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 62/129 [00:06<00:07,  8.91it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 63/129 [00:07<00:07,  8.90it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 64/129 [00:07<00:07,  8.89it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 65/129 [00:07<00:07,  8.92it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 66/129 [00:07<00:07,  8.93it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 67/129 [00:07<00:06,  8.91it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 68/129 [00:07<00:06,  8.72it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 69/129 [00:07<00:06,  8.68it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 70/129 [00:07<00:06,  8.45it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 71/129 [00:08<00:06,  8.55it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 72/129 [00:08<00:06,  8.53it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 73/129 [00:08<00:06,  8.64it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 74/129 [00:08<00:06,  8.73it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 75/129 [00:08<00:06,  8.83it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 76/129 [00:08<00:05,  8.87it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 77/129 [00:08<00:05,  8.89it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 78/129 [00:08<00:05,  8.93it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 79/129 [00:08<00:05,  8.95it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 80/129 [00:09<00:05,  8.95it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 81/129 [00:09<00:05,  8.92it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 82/129 [00:09<00:05,  8.91it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 83/129 [00:09<00:05,  8.99it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 84/129 [00:09<00:05,  8.78it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 85/129 [00:09<00:04,  8.80it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 86/129 [00:09<00:04,  8.84it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 87/129 [00:09<00:04,  8.86it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 88/129 [00:09<00:04,  8.84it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 89/129 [00:10<00:04,  8.80it/s]wandb: WARNING Tried to log to step 516 that is less than the current step 517. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 90/129 [00:10<00:04,  8.73it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 91/129 [00:10<00:04,  8.71it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 92/129 [00:10<00:04,  8.73it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 93/129 [00:10<00:04,  8.68it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 94/129 [00:10<00:04,  8.73it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 95/129 [00:10<00:03,  8.75it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 96/129 [00:10<00:03,  8.82it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 97/129 [00:10<00:03,  8.90it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 98/129 [00:11<00:03,  8.92it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 99/129 [00:11<00:03,  8.94it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 100/129 [00:11<00:03,  8.90it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 101/129 [00:11<00:03,  8.85it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 102/129 [00:11<00:03,  8.87it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 103/129 [00:11<00:02,  8.86it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 104/129 [00:11<00:02,  8.86it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 105/129 [00:11<00:02,  8.91it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 106/129 [00:11<00:02,  8.87it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 107/129 [00:12<00:02,  8.85it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 108/129 [00:12<00:02,  8.85it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 109/129 [00:12<00:02,  8.90it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 110/129 [00:12<00:02,  8.94it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 111/129 [00:12<00:02,  8.88it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 112/129 [00:12<00:01,  8.94it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 113/129 [00:12<00:01,  8.81it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 114/129 [00:12<00:01,  8.75it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 115/129 [00:12<00:01,  8.78it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 116/129 [00:13<00:01,  8.79it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 117/129 [00:13<00:01,  8.82it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 118/129 [00:13<00:01,  8.87it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 119/129 [00:13<00:01,  8.87it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 120/129 [00:13<00:01,  8.82it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 121/129 [00:13<00:00,  8.72it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 122/129 [00:13<00:00,  8.70it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 123/129 [00:13<00:00,  8.70it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 124/129 [00:14<00:00,  8.73it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 125/129 [00:14<00:00,  8.80it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 126/129 [00:14<00:00,  8.72it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 127/129 [00:14<00:00,  8.73it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 128/129 [00:14<00:00,  8.72it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 129/129 [00:14<00:00,  8.87it/s]
2025-05-05 22:23:12,070 - easytorch-training - INFO - Result <train>: [train/time: 14.55 (s), train/lr: 2.58e-03, train/loss: -0.9326, train/NLL: -0.9326, train/CRPS: 0.1073]
2025-05-05 22:23:12,074 - easytorch-training - INFO - Start validation.
  0%|          | 0/39 [00:00<?, ?it/s]  5%|‚ñå         | 2/39 [00:00<00:02, 13.96it/s] 10%|‚ñà         | 4/39 [00:00<00:02, 14.20it/s] 15%|‚ñà‚ñå        | 6/39 [00:00<00:02, 14.30it/s] 21%|‚ñà‚ñà        | 8/39 [00:00<00:02, 14.42it/s] 26%|‚ñà‚ñà‚ñå       | 10/39 [00:00<00:01, 14.71it/s] 31%|‚ñà‚ñà‚ñà       | 12/39 [00:00<00:01, 14.77it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 14/39 [00:00<00:01, 14.87it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 16/39 [00:01<00:01, 14.76it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 18/39 [00:01<00:01, 14.81it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 20/39 [00:01<00:01, 14.77it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 22/39 [00:01<00:01, 14.99it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 24/39 [00:01<00:00, 15.11it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 26/39 [00:01<00:00, 15.11it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 28/39 [00:01<00:00, 15.19it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 30/39 [00:02<00:00, 15.09it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 32/39 [00:02<00:00, 15.10it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 34/39 [00:02<00:00, 15.06it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 36/39 [00:02<00:00, 15.21it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 38/39 [00:02<00:00, 15.18it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 39/39 [00:02<00:00, 15.11it/s]
2025-05-05 22:23:14,660 - easytorch-training - INFO - Result <val>: [val/time: 2.58 (s), val/loss: -0.7452, val/NLL: -0.7452, val/CRPS: 0.0677]
2025-05-05 22:23:14,740 - easytorch-training - INFO - Checkpoint checkpoints/gaussian_PatchTST/ETTh1_100_336_96/b1a7fc8ebd65fd32cc59e1587d8e4831/PatchTST_best_val_NLL.pt saved
  0%|          | 0/39 [00:00<?, ?it/s] 13%|‚ñà‚ñé        | 5/39 [00:00<00:00, 49.88it/s] 28%|‚ñà‚ñà‚ñä       | 11/39 [00:00<00:00, 51.40it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 17/39 [00:00<00:00, 51.86it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 23/39 [00:00<00:00, 52.48it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 29/39 [00:00<00:00, 52.20it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 35/39 [00:00<00:00, 51.60it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 39/39 [00:00<00:00, 52.10it/s]
2025-05-05 22:23:17,087 - easytorch-training - INFO - Result <test>: [test/time: 2.34 (s), test/loss: -0.9780, test/NLL: -0.9786, test/CRPS: 0.0521]
2025-05-05 22:23:17,173 - easytorch-training - INFO - Checkpoint checkpoints/gaussian_PatchTST/ETTh1_100_336_96/b1a7fc8ebd65fd32cc59e1587d8e4831/PatchTST_005.pt saved
2025-05-05 22:23:17,175 - easytorch-training - INFO - The estimated training finish time is 2025-05-05 22:54:48
2025-05-05 22:23:17,175 - easytorch-training - INFO - Epoch 6 / 100
  0%|          | 0/129 [00:00<?, ?it/s]  1%|          | 1/129 [00:00<00:16,  7.84it/s]  2%|‚ñè         | 2/129 [00:00<00:15,  8.42it/s]  2%|‚ñè         | 3/129 [00:00<00:14,  8.63it/s]wandb: WARNING Tried to log to step 645 that is less than the current step 646. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
  3%|‚ñé         | 4/129 [00:00<00:14,  8.65it/s]  4%|‚ñç         | 5/129 [00:00<00:14,  8.76it/s]  5%|‚ñç         | 6/129 [00:00<00:13,  8.88it/s]  5%|‚ñå         | 7/129 [00:00<00:13,  8.83it/s]  6%|‚ñå         | 8/129 [00:00<00:13,  8.84it/s]  7%|‚ñã         | 9/129 [00:01<00:13,  8.89it/s]  8%|‚ñä         | 10/129 [00:01<00:13,  8.87it/s]  9%|‚ñä         | 11/129 [00:01<00:13,  8.83it/s]  9%|‚ñâ         | 12/129 [00:01<00:13,  8.83it/s] 10%|‚ñà         | 13/129 [00:01<00:13,  8.87it/s] 11%|‚ñà         | 14/129 [00:01<00:12,  8.90it/s] 12%|‚ñà‚ñè        | 15/129 [00:01<00:12,  8.90it/s] 12%|‚ñà‚ñè        | 16/129 [00:01<00:12,  8.94it/s] 13%|‚ñà‚ñé        | 17/129 [00:01<00:12,  8.93it/s] 14%|‚ñà‚ñç        | 18/129 [00:02<00:12,  8.91it/s] 15%|‚ñà‚ñç        | 19/129 [00:02<00:12,  8.91it/s] 16%|‚ñà‚ñå        | 20/129 [00:02<00:12,  8.92it/s] 16%|‚ñà‚ñã        | 21/129 [00:02<00:12,  8.83it/s] 17%|‚ñà‚ñã        | 22/129 [00:02<00:12,  8.82it/s] 18%|‚ñà‚ñä        | 23/129 [00:02<00:11,  8.86it/s] 19%|‚ñà‚ñä        | 24/129 [00:02<00:11,  8.92it/s] 19%|‚ñà‚ñâ        | 25/129 [00:02<00:11,  8.97it/s] 20%|‚ñà‚ñà        | 26/129 [00:02<00:11,  8.97it/s] 21%|‚ñà‚ñà        | 27/129 [00:03<00:11,  8.93it/s] 22%|‚ñà‚ñà‚ñè       | 28/129 [00:03<00:11,  8.91it/s] 22%|‚ñà‚ñà‚ñè       | 29/129 [00:03<00:11,  8.92it/s] 23%|‚ñà‚ñà‚ñé       | 30/129 [00:03<00:11,  8.75it/s] 24%|‚ñà‚ñà‚ñç       | 31/129 [00:03<00:11,  8.68it/s] 25%|‚ñà‚ñà‚ñç       | 32/129 [00:03<00:11,  8.70it/s] 26%|‚ñà‚ñà‚ñå       | 33/129 [00:03<00:10,  8.77it/s] 26%|‚ñà‚ñà‚ñã       | 34/129 [00:03<00:10,  8.86it/s] 27%|‚ñà‚ñà‚ñã       | 35/129 [00:03<00:10,  8.79it/s] 28%|‚ñà‚ñà‚ñä       | 36/129 [00:04<00:10,  8.80it/s] 29%|‚ñà‚ñà‚ñä       | 37/129 [00:04<00:10,  8.85it/s] 29%|‚ñà‚ñà‚ñâ       | 38/129 [00:04<00:10,  8.87it/s] 30%|‚ñà‚ñà‚ñà       | 39/129 [00:04<00:10,  8.86it/s] 31%|‚ñà‚ñà‚ñà       | 40/129 [00:04<00:10,  8.89it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 41/129 [00:04<00:09,  8.85it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 42/129 [00:04<00:09,  8.87it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 43/129 [00:04<00:09,  8.90it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 44/129 [00:04<00:09,  8.85it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 45/129 [00:05<00:09,  8.81it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 46/129 [00:05<00:09,  8.87it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 47/129 [00:05<00:09,  8.79it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 48/129 [00:05<00:09,  8.74it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 49/129 [00:05<00:09,  8.72it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 50/129 [00:05<00:09,  8.75it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 51/129 [00:05<00:08,  8.75it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 52/129 [00:05<00:08,  8.76it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 53/129 [00:06<00:08,  8.78it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 54/129 [00:06<00:08,  8.84it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 55/129 [00:06<00:08,  8.87it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 56/129 [00:06<00:08,  8.88it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 57/129 [00:06<00:08,  8.89it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 58/129 [00:06<00:08,  8.87it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 59/129 [00:06<00:07,  8.92it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 60/129 [00:06<00:07,  8.91it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 61/129 [00:06<00:07,  8.89it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 62/129 [00:07<00:07,  8.94it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 63/129 [00:07<00:07,  8.98it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 64/129 [00:07<00:07,  8.94it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 65/129 [00:07<00:07,  8.96it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 66/129 [00:07<00:07,  8.99it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 67/129 [00:07<00:06,  9.03it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 68/129 [00:07<00:06,  9.00it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 69/129 [00:07<00:06,  8.98it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 70/129 [00:07<00:06,  8.95it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 71/129 [00:08<00:06,  8.91it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 72/129 [00:08<00:06,  8.99it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 73/129 [00:08<00:06,  8.96it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 74/129 [00:08<00:06,  8.93it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 75/129 [00:08<00:06,  8.98it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 76/129 [00:08<00:05,  8.91it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 77/129 [00:08<00:05,  8.85it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 78/129 [00:08<00:05,  8.90it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 79/129 [00:08<00:05,  8.91it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 80/129 [00:09<00:05,  8.92it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 81/129 [00:09<00:05,  8.86it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 82/129 [00:09<00:05,  8.87it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 83/129 [00:09<00:05,  8.89it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 84/129 [00:09<00:05,  8.91it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 85/129 [00:09<00:04,  8.99it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 86/129 [00:09<00:04,  8.98it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 87/129 [00:09<00:04,  8.99it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 88/129 [00:09<00:04,  8.97it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 89/129 [00:10<00:04,  8.97it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 90/129 [00:10<00:04,  9.00it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 91/129 [00:10<00:04,  8.94it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 92/129 [00:10<00:04,  8.94it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 93/129 [00:10<00:04,  8.85it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 94/129 [00:10<00:03,  8.87it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 95/129 [00:10<00:03,  8.92it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 96/129 [00:10<00:03,  8.98it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 97/129 [00:10<00:03,  8.95it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 98/129 [00:11<00:03,  8.97it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 99/129 [00:11<00:03,  8.95it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 100/129 [00:11<00:03,  9.00it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 101/129 [00:11<00:03,  8.95it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 102/129 [00:11<00:03,  8.98it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 103/129 [00:11<00:02,  8.99it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 104/129 [00:11<00:02,  9.02it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 105/129 [00:11<00:02,  8.99it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 106/129 [00:11<00:02,  8.98it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 107/129 [00:12<00:02,  8.99it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 108/129 [00:12<00:02,  9.04it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 109/129 [00:12<00:02,  9.02it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 110/129 [00:12<00:02,  9.04it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 111/129 [00:12<00:02,  8.97it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 112/129 [00:12<00:01,  8.94it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 113/129 [00:12<00:01,  8.91it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 114/129 [00:12<00:01,  8.97it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 115/129 [00:12<00:01,  8.98it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 116/129 [00:13<00:01,  8.98it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 117/129 [00:13<00:01,  8.97it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 118/129 [00:13<00:01,  8.99it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 119/129 [00:13<00:01,  8.99it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 120/129 [00:13<00:01,  8.99it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 121/129 [00:13<00:00,  8.91it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 122/129 [00:13<00:00,  8.81it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 123/129 [00:13<00:00,  8.81it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 124/129 [00:13<00:00,  8.85it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 125/129 [00:14<00:00,  8.87it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 126/129 [00:14<00:00,  8.92it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 127/129 [00:14<00:00,  8.95it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 128/129 [00:14<00:00,  8.93it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 129/129 [00:14<00:00,  8.92it/s]
2025-05-05 22:23:31,642 - easytorch-training - INFO - Result <train>: [train/time: 14.47 (s), train/lr: 2.58e-03, train/loss: -0.9619, train/NLL: -0.9619, train/CRPS: 0.0886]
2025-05-05 22:23:31,645 - easytorch-training - INFO - Start validation.
  0%|          | 0/39 [00:00<?, ?it/s]  5%|‚ñå         | 2/39 [00:00<00:02, 15.27it/s] 10%|‚ñà         | 4/39 [00:00<00:02, 15.28it/s] 15%|‚ñà‚ñå        | 6/39 [00:00<00:02, 15.12it/s] 21%|‚ñà‚ñà        | 8/39 [00:00<00:02, 14.62it/s] 26%|‚ñà‚ñà‚ñå       | 10/39 [00:00<00:01, 14.53it/s] 31%|‚ñà‚ñà‚ñà       | 12/39 [00:00<00:01, 14.69it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 14/39 [00:00<00:01, 14.89it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 16/39 [00:01<00:01, 14.84it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 18/39 [00:01<00:01, 14.96it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 20/39 [00:01<00:01, 14.95it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 22/39 [00:01<00:01, 15.24it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 24/39 [00:01<00:00, 15.36it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 26/39 [00:01<00:00, 15.40it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 28/39 [00:01<00:00, 15.33it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 30/39 [00:01<00:00, 15.31it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 32/39 [00:02<00:00, 15.35it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 34/39 [00:02<00:00, 15.36it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 36/39 [00:02<00:00, 15.51it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 38/39 [00:02<00:00, 15.63it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 39/39 [00:02<00:00, 15.40it/s]
2025-05-05 22:23:34,182 - easytorch-training - INFO - Result <val>: [val/time: 2.54 (s), val/loss: -0.6597, val/NLL: -0.6597, val/CRPS: 0.0709]
  0%|          | 0/39 [00:00<?, ?it/s] 13%|‚ñà‚ñé        | 5/39 [00:00<00:00, 49.97it/s] 28%|‚ñà‚ñà‚ñä       | 11/39 [00:00<00:00, 52.74it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 17/39 [00:00<00:00, 52.33it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 23/39 [00:00<00:00, 52.68it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 29/39 [00:00<00:00, 53.41it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 35/39 [00:00<00:00, 53.77it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 39/39 [00:00<00:00, 53.42it/s]
2025-05-05 22:23:36,583 - easytorch-training - INFO - Result <test>: [test/time: 2.40 (s), test/loss: -0.8581, test/NLL: -0.8613, test/CRPS: 0.0573]
2025-05-05 22:23:36,685 - easytorch-training - INFO - Checkpoint checkpoints/gaussian_PatchTST/ETTh1_100_336_96/b1a7fc8ebd65fd32cc59e1587d8e4831/PatchTST_006.pt saved
2025-05-05 22:23:36,688 - easytorch-training - INFO - The estimated training finish time is 2025-05-05 22:54:41
2025-05-05 22:23:36,688 - easytorch-training - INFO - Epoch 7 / 100
  0%|          | 0/129 [00:00<?, ?it/s]  1%|          | 1/129 [00:00<00:16,  7.64it/s]  2%|‚ñè         | 2/129 [00:00<00:16,  7.88it/s]  2%|‚ñè         | 3/129 [00:00<00:15,  8.12it/s]  3%|‚ñé         | 4/129 [00:00<00:15,  8.33it/s]  4%|‚ñç         | 5/129 [00:00<00:14,  8.52it/s]  5%|‚ñç         | 6/129 [00:00<00:14,  8.63it/s]  5%|‚ñå         | 7/129 [00:00<00:14,  8.65it/s]wandb: WARNING Tried to log to step 774 that is less than the current step 775. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
  6%|‚ñå         | 8/129 [00:00<00:14,  8.62it/s]  7%|‚ñã         | 9/129 [00:01<00:13,  8.66it/s]  8%|‚ñä         | 10/129 [00:01<00:13,  8.61it/s]  9%|‚ñä         | 11/129 [00:01<00:13,  8.59it/s]  9%|‚ñâ         | 12/129 [00:01<00:13,  8.62it/s] 10%|‚ñà         | 13/129 [00:01<00:13,  8.70it/s] 11%|‚ñà         | 14/129 [00:01<00:13,  8.72it/s] 12%|‚ñà‚ñè        | 15/129 [00:01<00:12,  8.82it/s] 12%|‚ñà‚ñè        | 16/129 [00:01<00:12,  8.89it/s] 13%|‚ñà‚ñé        | 17/129 [00:01<00:12,  8.86it/s] 14%|‚ñà‚ñç        | 18/129 [00:02<00:12,  8.81it/s] 15%|‚ñà‚ñç        | 19/129 [00:02<00:12,  8.80it/s] 16%|‚ñà‚ñå        | 20/129 [00:02<00:12,  8.85it/s] 16%|‚ñà‚ñã        | 21/129 [00:02<00:12,  8.84it/s] 17%|‚ñà‚ñã        | 22/129 [00:02<00:12,  8.83it/s] 18%|‚ñà‚ñä        | 23/129 [00:02<00:12,  8.76it/s] 19%|‚ñà‚ñä        | 24/129 [00:02<00:11,  8.80it/s] 19%|‚ñà‚ñâ        | 25/129 [00:02<00:11,  8.68it/s] 20%|‚ñà‚ñà        | 26/129 [00:03<00:11,  8.66it/s] 21%|‚ñà‚ñà        | 27/129 [00:03<00:11,  8.66it/s] 22%|‚ñà‚ñà‚ñè       | 28/129 [00:03<00:11,  8.72it/s] 22%|‚ñà‚ñà‚ñè       | 29/129 [00:03<00:11,  8.70it/s] 23%|‚ñà‚ñà‚ñé       | 30/129 [00:03<00:11,  8.69it/s] 24%|‚ñà‚ñà‚ñç       | 31/129 [00:03<00:11,  8.55it/s] 25%|‚ñà‚ñà‚ñç       | 32/129 [00:03<00:11,  8.54it/s] 26%|‚ñà‚ñà‚ñå       | 33/129 [00:03<00:11,  8.57it/s] 26%|‚ñà‚ñà‚ñã       | 34/129 [00:03<00:11,  8.63it/s] 27%|‚ñà‚ñà‚ñã       | 35/129 [00:04<00:10,  8.66it/s] 28%|‚ñà‚ñà‚ñä       | 36/129 [00:04<00:10,  8.76it/s] 29%|‚ñà‚ñà‚ñä       | 37/129 [00:04<00:10,  8.77it/s] 29%|‚ñà‚ñà‚ñâ       | 38/129 [00:04<00:10,  8.74it/s] 30%|‚ñà‚ñà‚ñà       | 39/129 [00:04<00:10,  8.57it/s] 31%|‚ñà‚ñà‚ñà       | 40/129 [00:04<00:10,  8.47it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 41/129 [00:04<00:10,  8.44it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 42/129 [00:04<00:10,  8.40it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 43/129 [00:04<00:10,  8.41it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 44/129 [00:05<00:10,  8.48it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 45/129 [00:05<00:09,  8.51it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 46/129 [00:05<00:09,  8.58it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 47/129 [00:05<00:09,  8.61it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 48/129 [00:05<00:09,  8.62it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 49/129 [00:05<00:09,  8.68it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 50/129 [00:05<00:09,  8.65it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 51/129 [00:05<00:09,  8.63it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 52/129 [00:06<00:08,  8.60it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 53/129 [00:06<00:08,  8.60it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 54/129 [00:06<00:08,  8.65it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 55/129 [00:06<00:08,  8.65it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 56/129 [00:06<00:08,  8.65it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 57/129 [00:06<00:08,  8.65it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 58/129 [00:06<00:08,  8.65it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 59/129 [00:06<00:08,  8.66it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 60/129 [00:06<00:07,  8.69it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 61/129 [00:07<00:07,  8.67it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 62/129 [00:07<00:07,  8.62it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 63/129 [00:07<00:07,  8.65it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 64/129 [00:07<00:07,  8.67it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 65/129 [00:07<00:07,  8.67it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 66/129 [00:07<00:07,  8.67it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 67/129 [00:07<00:07,  8.63it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 68/129 [00:07<00:07,  8.64it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 69/129 [00:07<00:06,  8.66it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 70/129 [00:08<00:06,  8.65it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 71/129 [00:08<00:06,  8.58it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 72/129 [00:08<00:06,  8.57it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 73/129 [00:08<00:06,  8.59it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 74/129 [00:08<00:06,  8.58it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 75/129 [00:08<00:06,  8.61it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 76/129 [00:08<00:06,  8.65it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 77/129 [00:08<00:06,  8.66it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 78/129 [00:09<00:05,  8.62it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 79/129 [00:09<00:05,  8.61it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 80/129 [00:09<00:05,  8.64it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 81/129 [00:09<00:05,  8.59it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 82/129 [00:09<00:05,  8.56it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 83/129 [00:09<00:05,  8.50it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 84/129 [00:09<00:05,  8.51it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 85/129 [00:09<00:05,  8.45it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 86/129 [00:09<00:05,  8.51it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 87/129 [00:10<00:04,  8.58it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 88/129 [00:10<00:04,  8.62it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 89/129 [00:10<00:04,  8.61it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 90/129 [00:10<00:04,  8.64it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 91/129 [00:10<00:04,  8.62it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 92/129 [00:10<00:04,  8.63it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 93/129 [00:10<00:04,  8.65it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 94/129 [00:10<00:04,  8.57it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 95/129 [00:11<00:03,  8.52it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 96/129 [00:11<00:03,  8.55it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 97/129 [00:11<00:03,  8.57it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 98/129 [00:11<00:03,  8.55it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 99/129 [00:11<00:03,  8.58it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 100/129 [00:11<00:03,  8.57it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 101/129 [00:11<00:03,  8.53it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 102/129 [00:11<00:03,  8.54it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 103/129 [00:11<00:03,  8.63it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 104/129 [00:12<00:02,  8.66it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 105/129 [00:12<00:02,  8.62it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 106/129 [00:12<00:02,  8.61it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 107/129 [00:12<00:02,  8.57it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 108/129 [00:12<00:02,  8.61it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 109/129 [00:12<00:02,  8.63it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 110/129 [00:12<00:02,  8.66it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 111/129 [00:12<00:02,  8.61it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 112/129 [00:13<00:01,  8.56it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 113/129 [00:13<00:01,  8.58it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 114/129 [00:13<00:01,  8.57it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 115/129 [00:13<00:01,  8.55it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 116/129 [00:13<00:01,  8.58it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 117/129 [00:13<00:01,  8.59it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 118/129 [00:13<00:01,  8.56it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 119/129 [00:13<00:01,  8.58it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 120/129 [00:13<00:01,  8.63it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 121/129 [00:14<00:00,  8.58it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 122/129 [00:14<00:00,  8.55it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 123/129 [00:14<00:00,  8.59it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 124/129 [00:14<00:00,  8.61it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 125/129 [00:14<00:00,  8.64it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 126/129 [00:14<00:00,  8.65it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 127/129 [00:14<00:00,  8.69it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 128/129 [00:14<00:00,  8.51it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 129/129 [00:14<00:00,  8.63it/s]
2025-05-05 22:23:51,634 - easytorch-training - INFO - Result <train>: [train/time: 14.94 (s), train/lr: 2.58e-03, train/loss: -0.9404, train/NLL: -0.9404, train/CRPS: 0.0912]
2025-05-05 22:23:51,636 - easytorch-training - INFO - Start validation.
  0%|          | 0/39 [00:00<?, ?it/s]  5%|‚ñå         | 2/39 [00:00<00:02, 13.86it/s] 10%|‚ñà         | 4/39 [00:00<00:02, 14.15it/s] 15%|‚ñà‚ñå        | 6/39 [00:00<00:02, 14.36it/s] 21%|‚ñà‚ñà        | 8/39 [00:00<00:02, 14.59it/s] 26%|‚ñà‚ñà‚ñå       | 10/39 [00:00<00:01, 14.81it/s] 31%|‚ñà‚ñà‚ñà       | 12/39 [00:00<00:01, 14.84it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 14/39 [00:00<00:01, 14.84it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 16/39 [00:01<00:01, 14.66it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 18/39 [00:01<00:01, 14.68it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 20/39 [00:01<00:01, 14.63it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 22/39 [00:01<00:01, 14.83it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 24/39 [00:01<00:00, 15.00it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 26/39 [00:01<00:00, 14.99it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 28/39 [00:01<00:00, 15.14it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 30/39 [00:02<00:00, 15.14it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 32/39 [00:02<00:00, 15.20it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 34/39 [00:02<00:00, 15.08it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 36/39 [00:02<00:00, 15.19it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 38/39 [00:02<00:00, 15.26it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 39/39 [00:02<00:00, 15.09it/s]
2025-05-05 22:23:54,225 - easytorch-training - INFO - Result <val>: [val/time: 2.59 (s), val/loss: -0.5482, val/NLL: -0.5482, val/CRPS: 0.0786]
  0%|          | 0/39 [00:00<?, ?it/s] 15%|‚ñà‚ñå        | 6/39 [00:00<00:00, 50.47it/s] 31%|‚ñà‚ñà‚ñà       | 12/39 [00:00<00:00, 52.47it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 18/39 [00:00<00:00, 53.09it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 24/39 [00:00<00:00, 54.84it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 30/39 [00:00<00:00, 55.06it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 36/39 [00:00<00:00, 55.18it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 39/39 [00:00<00:00, 54.55it/s]
2025-05-05 22:23:56,639 - easytorch-training - INFO - Result <test>: [test/time: 2.41 (s), test/loss: -0.7588, test/NLL: -0.7551, test/CRPS: 0.0636]
2025-05-05 22:23:56,657 - easytorch-training - ERROR - Traceback (most recent call last):
  File "/home/kreffert/Probabilistic_LTSF/BasicTS/basicts/launcher.py", line 183, in training_func
    best_metrics = runner.train(cfg=cfg)
                   ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kreffert/Probabilistic_LTSF/BasicTS/basicts/runners/base_epoch_runner.py", line 443, in train
    self.on_epoch_end(epoch)
  File "/home/kreffert/Probabilistic_LTSF/BasicTS/basicts/runners/runner_zoo/simple_prob_tsf_runner.py", line 564, in on_epoch_end
    self.save_model(epoch)
  File "/home/kreffert/miniconda3/envs/BasicTS/lib/python3.11/site-packages/easytorch/utils/dist.py", line 102, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kreffert/Probabilistic_LTSF/BasicTS/basicts/runners/base_epoch_runner.py", line 801, in save_model
    backup_last_ckpt(last_ckpt_path, epoch, self.ckpt_save_strategy)
  File "/home/kreffert/miniconda3/envs/BasicTS/lib/python3.11/site-packages/easytorch/core/checkpoint.py", line 109, in backup_last_ckpt
    os.rename(last_ckpt_path, last_ckpt_path + '.bak')
FileNotFoundError: [Errno 2] No such file or directory: 'checkpoints/gaussian_PatchTST/ETTh1_100_336_96/b1a7fc8ebd65fd32cc59e1587d8e4831/PatchTST_006.pt' -> 'checkpoints/gaussian_PatchTST/ETTh1_100_336_96/b1a7fc8ebd65fd32cc59e1587d8e4831/PatchTST_006.pt.bak'

Traceback (most recent call last):
  File "/home/kreffert/Probabilistic_LTSF/BasicTS/basicts/launcher.py", line 363, in agent_function
    return sweep_agent_function(cfg)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kreffert/Probabilistic_LTSF/BasicTS/basicts/launcher.py", line 311, in sweep_agent_function
    training_func(merged_config, wandb_run=wandb.run)
  File "/home/kreffert/Probabilistic_LTSF/BasicTS/basicts/launcher.py", line 187, in training_func
    raise e
  File "/home/kreffert/Probabilistic_LTSF/BasicTS/basicts/launcher.py", line 183, in training_func
    best_metrics = runner.train(cfg=cfg)
                   ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kreffert/Probabilistic_LTSF/BasicTS/basicts/runners/base_epoch_runner.py", line 443, in train
    self.on_epoch_end(epoch)
  File "/home/kreffert/Probabilistic_LTSF/BasicTS/basicts/runners/runner_zoo/simple_prob_tsf_runner.py", line 564, in on_epoch_end
    self.save_model(epoch)
  File "/home/kreffert/miniconda3/envs/BasicTS/lib/python3.11/site-packages/easytorch/utils/dist.py", line 102, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kreffert/Probabilistic_LTSF/BasicTS/basicts/runners/base_epoch_runner.py", line 801, in save_model
    backup_last_ckpt(last_ckpt_path, epoch, self.ckpt_save_strategy)
  File "/home/kreffert/miniconda3/envs/BasicTS/lib/python3.11/site-packages/easytorch/core/checkpoint.py", line 109, in backup_last_ckpt
    os.rename(last_ckpt_path, last_ckpt_path + '.bak')
FileNotFoundError: [Errno 2] No such file or directory: 'checkpoints/gaussian_PatchTST/ETTh1_100_336_96/b1a7fc8ebd65fd32cc59e1587d8e4831/PatchTST_006.pt' -> 'checkpoints/gaussian_PatchTST/ETTh1_100_336_96/b1a7fc8ebd65fd32cc59e1587d8e4831/PatchTST_006.pt.bak'
wandb: uploading history steps 91-91, summary, console lines 132-175
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:                    epoch ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñà
wandb: epoch_summary/train/CRPS ‚ñà‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:  epoch_summary/train/NLL ‚ñà‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb: epoch_summary/train/loss ‚ñà‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:   epoch_summary/train/lr ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: epoch_summary/train/time ‚ñà‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ
wandb:   epoch_summary/val/CRPS ‚ñà‚ñÇ‚ñÖ‚ñÅ‚ñÅ‚ñÇ‚ñÑ
wandb:    epoch_summary/val/NLL ‚ñà‚ñÉ‚ñÖ‚ñÇ‚ñÅ‚ñÇ‚ñÑ
wandb:   epoch_summary/val/loss ‚ñà‚ñÉ‚ñÖ‚ñÇ‚ñÅ‚ñÇ‚ñÑ
wandb:   epoch_summary/val/time ‚ñÉ‚ñÑ‚ñÑ‚ñÅ‚ñà‚ñÑ‚ñà
wandb:                test/CRPS ‚ñà‚ñÉ‚ñÖ‚ñÅ‚ñÅ‚ñÇ‚ñÑ
wandb:                 test/NLL ‚ñà‚ñÉ‚ñÖ‚ñÅ‚ñÅ‚ñÉ‚ñÑ
wandb:               train/CRPS ‚ñÜ‚ñà‚ñá‚ñà‚ñÑ‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                train/NLL ‚ñà‚ñÖ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:              train/epoch ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:               train/iter ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb:               train/loss ‚ñà‚ñÖ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                 val/CRPS ‚ñà‚ñÇ‚ñÖ‚ñÅ‚ñÅ‚ñÇ‚ñÑ
wandb:                  val/NLL ‚ñà‚ñÉ‚ñÖ‚ñÇ‚ñÅ‚ñÇ‚ñÑ
wandb:                 val/loss ‚ñà‚ñÉ‚ñÖ‚ñÇ‚ñÅ‚ñÇ‚ñÑ
wandb:                 val/time ‚ñÉ‚ñÑ‚ñÑ‚ñÅ‚ñà‚ñÑ‚ñà
wandb: 
wandb: Run summary:
wandb:                    epoch 7
wandb: epoch_summary/train/CRPS 0.09123
wandb:  epoch_summary/train/NLL -0.94042
wandb: epoch_summary/train/loss -0.94042
wandb:   epoch_summary/train/lr 0.00258
wandb: epoch_summary/train/time 14.94429
wandb:   epoch_summary/val/CRPS 0.07863
wandb:    epoch_summary/val/NLL -0.54821
wandb:   epoch_summary/val/loss -0.54821
wandb:   epoch_summary/val/time 2.58723
wandb:                test/CRPS 0.06358
wandb:                 test/NLL -0.75507
wandb:               train/CRPS 0.08487
wandb:                train/NLL -0.96048
wandb:              train/epoch 7
wandb:               train/iter 894
wandb:               train/loss -0.96048
wandb:                 val/CRPS 0.07863
wandb:                  val/NLL -0.54821
wandb:                 val/loss -0.54821
wandb:                 val/time 2.58723
wandb: 
wandb: üöÄ View run PatchTST_May_05_22_21 at: https://wandb.ai/kai-reffert-university-mannheim/Prob_LTSF/runs/frwfyiqp
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/kai-reffert-university-mannheim/Prob_LTSF
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250505_222136-frwfyiqp/logs
wandb: ERROR Run frwfyiqp errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/home/kreffert/miniconda3/envs/BasicTS/lib/python3.11/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/home/kreffert/Probabilistic_LTSF/BasicTS/basicts/launcher.py", line 363, in agent_function
wandb: ERROR     return sweep_agent_function(cfg)
wandb: ERROR            ^^^^^^^^^^^^^^^^^^^^^^^^^
wandb: ERROR   File "/home/kreffert/Probabilistic_LTSF/BasicTS/basicts/launcher.py", line 311, in sweep_agent_function
wandb: ERROR     training_func(merged_config, wandb_run=wandb.run)
wandb: ERROR   File "/home/kreffert/Probabilistic_LTSF/BasicTS/basicts/launcher.py", line 187, in training_func
wandb: ERROR     raise e
wandb: ERROR   File "/home/kreffert/Probabilistic_LTSF/BasicTS/basicts/launcher.py", line 183, in training_func
wandb: ERROR     best_metrics = runner.train(cfg=cfg)
wandb: ERROR                    ^^^^^^^^^^^^^^^^^^^^^
wandb: ERROR   File "/home/kreffert/Probabilistic_LTSF/BasicTS/basicts/runners/base_epoch_runner.py", line 443, in train
wandb: ERROR     self.on_epoch_end(epoch)
wandb: ERROR   File "/home/kreffert/Probabilistic_LTSF/BasicTS/basicts/runners/runner_zoo/simple_prob_tsf_runner.py", line 564, in on_epoch_end
wandb: ERROR     self.save_model(epoch)
wandb: ERROR   File "/home/kreffert/miniconda3/envs/BasicTS/lib/python3.11/site-packages/easytorch/utils/dist.py", line 102, in wrapper
wandb: ERROR     return func(*args, **kwargs)
wandb: ERROR            ^^^^^^^^^^^^^^^^^^^^^
wandb: ERROR   File "/home/kreffert/Probabilistic_LTSF/BasicTS/basicts/runners/base_epoch_runner.py", line 801, in save_model
wandb: ERROR     backup_last_ckpt(last_ckpt_path, epoch, self.ckpt_save_strategy)
wandb: ERROR   File "/home/kreffert/miniconda3/envs/BasicTS/lib/python3.11/site-packages/easytorch/core/checkpoint.py", line 109, in backup_last_ckpt
wandb: ERROR     os.rename(last_ckpt_path, last_ckpt_path + '.bak')
wandb: ERROR FileNotFoundError: [Errno 2] No such file or directory: 'checkpoints/gaussian_PatchTST/ETTh1_100_336_96/b1a7fc8ebd65fd32cc59e1587d8e4831/PatchTST_006.pt' -> 'checkpoints/gaussian_PatchTST/ETTh1_100_336_96/b1a7fc8ebd65fd32cc59e1587d8e4831/PatchTST_006.pt.bak'
wandb: ERROR 
wandb: Agent Starting Run: 3rjeowq1 with config:
wandb: 	MODEL.PARAM.d_model: 16
wandb: 	MODEL.PARAM.decomposition: 1
wandb: 	MODEL.PARAM.distribution_type: student_t
wandb: 	MODEL.PARAM.dropout: 0.2971105024279965
wandb: 	MODEL.PARAM.e_layers: 7
wandb: 	MODEL.PARAM.fc_dropout: 0.2777829941236167
wandb: 	MODEL.PARAM.head_type: probabilistic
wandb: 	MODEL.PARAM.individual: 1
wandb: 	MODEL.PARAM.kernel_size: 64
wandb: 	MODEL.PARAM.n_heads: 8
wandb: 	MODEL.PARAM.patch_len: 16
wandb: 	MODEL.PARAM.stride: 16
wandb: 	MODEL.PARAM.subtract_last: 1
wandb: 	NORM_EACH_CHANNEL: False
wandb: 	NUM_EPOCHS: 100
wandb: 	OUTPUT_LEN: 96
wandb: 	RESCALE: True
wandb: 	SCALER.TYPE: MinMaxScaler
wandb: 	TRAIN.DATA.BATCH_SIZE: 64
wandb: 	TRAIN.LR_SCHEDULER.PARAM.gamma: 0.32370399361272895
wandb: 	TRAIN.LR_SCHEDULER.TYPE: MultiStepLR
wandb: 	TRAIN.OPTIM.PARAM.lr: 0.011046992213814067
wandb: 	TRAIN.OPTIM.PARAM.weight_decay: 0.000918628862155764
wandb: 	TRAIN.OPTIM.TYPE: Adam
wandb: 	TRAIN.RESUME_TRAINING: False
wandb: 	USE_WANDB: True
wandb: WARNING Ignoring project 'Prob_LTSF' when running a sweep.
wandb: WARNING Ignoring entity 'kai-reffert-university-mannheim' when running a sweep.
wandb: Tracking run with wandb version 0.19.9
wandb: Run data is saved locally in /home/kreffert/Probabilistic_LTSF/BasicTS/wandb/run-20250505_222403-3rjeowq1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run PatchTST_May_05_22_24
wandb: ‚≠êÔ∏è View project at https://wandb.ai/kai-reffert-university-mannheim/Prob_LTSF
wandb: üßπ View sweep at https://wandb.ai/kai-reffert-university-mannheim/Prob_LTSF/sweeps/fwvzje2j
wandb: üöÄ View run at https://wandb.ai/kai-reffert-university-mannheim/Prob_LTSF/runs/3rjeowq1
2025-05-05 22:24:04,091 - easytorch-sweep-agent - INFO - Starting sweep agent trial with configuration:
Update d_model to 16
Update decomposition to 1
Update distribution_type to student_t
Update dropout to 0.2971105024279965
Update e_layers to 7
Update fc_dropout to 0.2777829941236167
Update head_type to probabilistic
Update individual to 1
Update kernel_size to 64
Update n_heads to 8
Update patch_len to 16
Update stride to 16
Update subtract_last to 1
Update NORM_EACH_CHANNEL to False
Update NUM_EPOCHS to 100
Update OUTPUT_LEN to 96
Update RESCALE to True
Update TYPE to <class 'basicts.scaler.min_max_scaler.MinMaxScaler'>
Update BATCH_SIZE to 64
Update gamma to 0.32370399361272895
Update TYPE to MultiStepLR
Update lr to 0.011046992213814067
Update weight_decay to 0.000918628862155764
Update TYPE to Adam
Update RESUME_TRAINING to False
Update USE_WANDB to True
{'DESCRIPTION': 'An Example Config', 'GPU_NUM': 1, 'RUNNER': <class 'basicts.runners.runner_zoo.simple_prob_tsf_runner.SimpleProbTimeSeriesForecastingRunner'>, 'USE_WANDB': True, 'DATASET': {'NAME': 'ETTh1', 'TYPE': <class 'basicts.data.simple_tsf_dataset.TimeSeriesForecastingDataset'>, 'PARAM': {'dataset_name': 'ETTh1', 'train_val_test_ratio': [0.6, 0.2, 0.2], 'input_len': 336, 'output_len': 96}}, 'SCALER': {'TYPE': <class 'basicts.scaler.min_max_scaler.MinMaxScaler'>, 'PARAM': {'dataset_name': 'ETTh1', 'train_ratio': 0.6, 'norm_each_channel': True, 'rescale': False}}, 'MODEL': {'NAME': 'PatchTST', 'ARCH': <class 'baselines.PatchTST.arch.patchtst_arch.PatchTST'>, 'PARAM': {'enc_in': 7, 'seq_len': 336, 'pred_len': 96, 'e_layers': 7, 'n_heads': 8, 'd_model': 16, 'd_ff': 128, 'dropout': 0.2971105024279965, 'fc_dropout': 0.2777829941236167, 'head_dropout': 0.0, 'patch_len': 16, 'stride': 16, 'individual': 1, 'padding_patch': 'end', 'revin': 0, 'affine': 0, 'subtract_last': 1, 'decomposition': 1, 'kernel_size': 64, 'head_type': 'probabilistic', 'distribution_type': 'student_t', 'quantiles': []}, 'FORWARD_FEATURES': [0], 'TARGET_FEATURES': [0]}, 'METRICS': {'FUNCS': {'NLL': <function nll_loss at 0x7f0765438360>, 'CRPS': <function crps at 0x7f0766413420>}, 'TARGET': 'NLL', 'NULL_VAL': nan}, 'TRAIN': {'RESUME_TRAINING': False, 'EARLY_STOPPING_PATIENCE': 5, 'NUM_EPOCHS': 100, 'CKPT_SAVE_DIR': 'checkpoints/gaussian_PatchTST/ETTh1_100_336_96', 'LOSS': <function nll_loss at 0x7f0765438360>, 'OPTIM': {'TYPE': 'Adam', 'PARAM': {'lr': 0.011046992213814067, 'weight_decay': 0.000918628862155764}}, 'LR_SCHEDULER': {'TYPE': 'MultiStepLR', 'PARAM': {'milestones': [1, 25], 'gamma': 0.32370399361272895}}, 'CLIP_GRAD_PARAM': {'max_norm': 5.0}, 'DATA': {'BATCH_SIZE': 64, 'SHUFFLE': True}}, 'VAL': {'INTERVAL': 1, 'DATA': {'BATCH_SIZE': 64}}, 'TEST': {'INTERVAL': 1, 'DATA': {'BATCH_SIZE': 64}}, 'EVAL': {'USE_GPU': True}, 'MD5': 'b1a7fc8ebd65fd32cc59e1587d8e4831', 'NORM_EACH_CHANNEL': False, 'NUM_EPOCHS': 100, 'OUTPUT_LEN': 96, 'RESCALE': True}
2025-05-05 22:24:04,096 - easytorch-sweep-agent - INFO - Updated configuration with sweep parameters.
2025-05-05 22:24:04,096 - easytorch-launcher - INFO - Initializing runner '<class 'basicts.runners.runner_zoo.simple_prob_tsf_runner.SimpleProbTimeSeriesForecastingRunner'>'
2025-05-05 22:24:04,097 - easytorch-env - INFO - Disable TF32 mode
2025-05-05 22:24:04,097 - easytorch - INFO - Set ckpt save dir: 'checkpoints/gaussian_PatchTST/ETTh1_100_336_96/b1a7fc8ebd65fd32cc59e1587d8e4831'
2025-05-05 22:24:04,097 - easytorch - INFO - Building model.
PatchTST
2025-05-05 22:24:04,187 - easytorch-training - INFO - Initializing training.
2025-05-05 22:24:04,188 - easytorch-training - INFO - Set clip grad, param: {'max_norm': 5.0}
2025-05-05 22:24:04,188 - easytorch-training - INFO - Building training data loader.
2025-05-05 22:24:04,192 - easytorch-training - INFO - Train dataset length: 8209
2025-05-05 22:24:04,195 - easytorch-training - INFO - Set optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    decoupled_weight_decay: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.011046992213814067
    maximize: False
    weight_decay: 0.000918628862155764
)
2025-05-05 22:24:04,196 - easytorch-training - INFO - Set lr_scheduler: <torch.optim.lr_scheduler.MultiStepLR object at 0x7f070130f090>
2025-05-05 22:24:04,201 - easytorch-training - INFO - Initializing validation.
2025-05-05 22:24:04,201 - easytorch-training - INFO - Building val data loader.
2025-05-05 22:24:04,203 - easytorch-training - INFO - Validation dataset length: 2449
2025-05-05 22:24:04,205 - easytorch-training - INFO - Test dataset length: 2449
2025-05-05 22:24:04,207 - easytorch-training - INFO - Number of parameters: 1500032
2025-05-05 22:24:04,207 - easytorch-training - INFO - Epoch 1 / 100
  0%|          | 0/129 [00:00<?, ?it/s]  0%|          | 0/129 [00:00<?, ?it/s]
2025-05-05 22:24:04,234 - easytorch-training - ERROR - Traceback (most recent call last):
  File "/home/kreffert/Probabilistic_LTSF/BasicTS/basicts/launcher.py", line 183, in training_func
    best_metrics = runner.train(cfg=cfg)
                   ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kreffert/Probabilistic_LTSF/BasicTS/basicts/runners/base_epoch_runner.py", line 433, in train
    loss = self.train_iters(epoch, iter_index, data)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kreffert/Probabilistic_LTSF/BasicTS/basicts/runners/runner_zoo/simple_prob_tsf_runner.py", line 286, in train_iters
    forward_return = self.forward(data=data, epoch=epoch, iter_num=iter_num, train=True)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kreffert/Probabilistic_LTSF/BasicTS/basicts/runners/runner_zoo/simple_prob_tsf_runner.py", line 137, in forward
    model_return = self.model(history_data=history_data, future_data=future_data_4_dec,
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kreffert/miniconda3/envs/BasicTS/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kreffert/miniconda3/envs/BasicTS/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kreffert/Probabilistic_LTSF/BasicTS/baselines/PatchTST/arch/patchtst_arch.py", line 105, in forward
    res_init, trend_init = self.decomp_module(x)
                           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kreffert/miniconda3/envs/BasicTS/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kreffert/miniconda3/envs/BasicTS/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kreffert/Probabilistic_LTSF/BasicTS/baselines/PatchTST/arch/patchtst_layers.py", line 52, in forward
    res = x - moving_mean
          ~~^~~~~~~~~~~~~
RuntimeError: The size of tensor a (336) must match the size of tensor b (335) at non-singleton dimension 1

Traceback (most recent call last):
  File "/home/kreffert/Probabilistic_LTSF/BasicTS/basicts/launcher.py", line 363, in agent_function
    return sweep_agent_function(cfg)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kreffert/Probabilistic_LTSF/BasicTS/basicts/launcher.py", line 311, in sweep_agent_function
    training_func(merged_config, wandb_run=wandb.run)
  File "/home/kreffert/Probabilistic_LTSF/BasicTS/basicts/launcher.py", line 187, in training_func
    raise e
  File "/home/kreffert/Probabilistic_LTSF/BasicTS/basicts/launcher.py", line 183, in training_func
    best_metrics = runner.train(cfg=cfg)
                   ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kreffert/Probabilistic_LTSF/BasicTS/basicts/runners/base_epoch_runner.py", line 433, in train
    loss = self.train_iters(epoch, iter_index, data)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kreffert/Probabilistic_LTSF/BasicTS/basicts/runners/runner_zoo/simple_prob_tsf_runner.py", line 286, in train_iters
    forward_return = self.forward(data=data, epoch=epoch, iter_num=iter_num, train=True)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kreffert/Probabilistic_LTSF/BasicTS/basicts/runners/runner_zoo/simple_prob_tsf_runner.py", line 137, in forward
    model_return = self.model(history_data=history_data, future_data=future_data_4_dec,
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kreffert/miniconda3/envs/BasicTS/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kreffert/miniconda3/envs/BasicTS/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kreffert/Probabilistic_LTSF/BasicTS/baselines/PatchTST/arch/patchtst_arch.py", line 105, in forward
    res_init, trend_init = self.decomp_module(x)
                           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kreffert/miniconda3/envs/BasicTS/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kreffert/miniconda3/envs/BasicTS/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kreffert/Probabilistic_LTSF/BasicTS/baselines/PatchTST/arch/patchtst_layers.py", line 52, in forward
    res = x - moving_mean
          ~~^~~~~~~~~~~~~
RuntimeError: The size of tensor a (336) must match the size of tensor b (335) at non-singleton dimension 1
wandb: uploading summary, console lines 0-131
wandb:                                                                                
wandb: üöÄ View run PatchTST_May_05_22_24 at: https://wandb.ai/kai-reffert-university-mannheim/Prob_LTSF/runs/3rjeowq1
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/kai-reffert-university-mannheim/Prob_LTSF
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250505_222403-3rjeowq1/logs
wandb: ERROR Run 3rjeowq1 errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/home/kreffert/miniconda3/envs/BasicTS/lib/python3.11/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/home/kreffert/Probabilistic_LTSF/BasicTS/basicts/launcher.py", line 363, in agent_function
wandb: ERROR     return sweep_agent_function(cfg)
wandb: ERROR            ^^^^^^^^^^^^^^^^^^^^^^^^^
wandb: ERROR   File "/home/kreffert/Probabilistic_LTSF/BasicTS/basicts/launcher.py", line 311, in sweep_agent_function
wandb: ERROR     training_func(merged_config, wandb_run=wandb.run)
wandb: ERROR   File "/home/kreffert/Probabilistic_LTSF/BasicTS/basicts/launcher.py", line 187, in training_func
wandb: ERROR     raise e
wandb: ERROR   File "/home/kreffert/Probabilistic_LTSF/BasicTS/basicts/launcher.py", line 183, in training_func
wandb: ERROR     best_metrics = runner.train(cfg=cfg)
wandb: ERROR                    ^^^^^^^^^^^^^^^^^^^^^
wandb: ERROR   File "/home/kreffert/Probabilistic_LTSF/BasicTS/basicts/runners/base_epoch_runner.py", line 433, in train
wandb: ERROR     loss = self.train_iters(epoch, iter_index, data)
wandb: ERROR            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
wandb: ERROR   File "/home/kreffert/Probabilistic_LTSF/BasicTS/basicts/runners/runner_zoo/simple_prob_tsf_runner.py", line 286, in train_iters
wandb: ERROR     forward_return = self.forward(data=data, epoch=epoch, iter_num=iter_num, train=True)
wandb: ERROR                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
wandb: ERROR   File "/home/kreffert/Probabilistic_LTSF/BasicTS/basicts/runners/runner_zoo/simple_prob_tsf_runner.py", line 137, in forward
wandb: ERROR     model_return = self.model(history_data=history_data, future_data=future_data_4_dec,
wandb: ERROR                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
wandb: ERROR   File "/home/kreffert/miniconda3/envs/BasicTS/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
wandb: ERROR     return self._call_impl(*args, **kwargs)
wandb: ERROR            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
wandb: ERROR   File "/home/kreffert/miniconda3/envs/BasicTS/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
wandb: ERROR     return forward_call(*args, **kwargs)
wandb: ERROR            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
wandb: ERROR   File "/home/kreffert/Probabilistic_LTSF/BasicTS/baselines/PatchTST/arch/patchtst_arch.py", line 105, in forward
wandb: ERROR     res_init, trend_init = self.decomp_module(x)
wandb: ERROR                            ^^^^^^^^^^^^^^^^^^^^^
wandb: ERROR   File "/home/kreffert/miniconda3/envs/BasicTS/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
wandb: ERROR     return self._call_impl(*args, **kwargs)
wandb: ERROR            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
wandb: ERROR   File "/home/kreffert/miniconda3/envs/BasicTS/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
wandb: ERROR     return forward_call(*args, **kwargs)
wandb: ERROR            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
wandb: ERROR   File "/home/kreffert/Probabilistic_LTSF/BasicTS/baselines/PatchTST/arch/patchtst_layers.py", line 52, in forward
wandb: ERROR     res = x - moving_mean
wandb: ERROR           ~~^~~~~~~~~~~~~
wandb: ERROR RuntimeError: The size of tensor a (336) must match the size of tensor b (335) at non-singleton dimension 1
wandb: ERROR 
wandb: Agent Starting Run: k1ka403r with config:
wandb: 	MODEL.PARAM.d_model: 64
wandb: 	MODEL.PARAM.decomposition: 1
wandb: 	MODEL.PARAM.distribution_type: laplace
wandb: 	MODEL.PARAM.dropout: 0.11082606525467036
wandb: 	MODEL.PARAM.e_layers: 7
wandb: 	MODEL.PARAM.fc_dropout: 0.07728530987757058
wandb: 	MODEL.PARAM.head_type: probabilistic
wandb: 	MODEL.PARAM.individual: 1
wandb: 	MODEL.PARAM.kernel_size: 32
wandb: 	MODEL.PARAM.n_heads: 4
wandb: 	MODEL.PARAM.patch_len: 4
wandb: 	MODEL.PARAM.stride: 128
wandb: 	MODEL.PARAM.subtract_last: 0
wandb: 	NORM_EACH_CHANNEL: True
wandb: 	NUM_EPOCHS: 100
wandb: 	OUTPUT_LEN: 96
wandb: 	RESCALE: False
wandb: 	SCALER.TYPE: MinMaxScaler
wandb: 	TRAIN.DATA.BATCH_SIZE: 32
wandb: 	TRAIN.LR_SCHEDULER.PARAM.gamma: 0.4385914260838612
wandb: 	TRAIN.LR_SCHEDULER.TYPE: MultiStepLR
wandb: 	TRAIN.OPTIM.PARAM.lr: 0.00782273425986829
wandb: 	TRAIN.OPTIM.PARAM.weight_decay: 0.00011771591918046793
wandb: 	TRAIN.OPTIM.TYPE: Adam
wandb: 	TRAIN.RESUME_TRAINING: False
wandb: 	USE_WANDB: True
wandb: WARNING Ignoring project 'Prob_LTSF' when running a sweep.
wandb: WARNING Ignoring entity 'kai-reffert-university-mannheim' when running a sweep.
wandb: Tracking run with wandb version 0.19.9
wandb: Run data is saved locally in /home/kreffert/Probabilistic_LTSF/BasicTS/wandb/run-20250505_222408-k1ka403r
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run PatchTST_May_05_22_24
wandb: ‚≠êÔ∏è View project at https://wandb.ai/kai-reffert-university-mannheim/Prob_LTSF
wandb: üßπ View sweep at https://wandb.ai/kai-reffert-university-mannheim/Prob_LTSF/sweeps/fwvzje2j
wandb: üöÄ View run at https://wandb.ai/kai-reffert-university-mannheim/Prob_LTSF/runs/k1ka403r
2025-05-05 22:24:09,684 - easytorch-sweep-agent - INFO - Starting sweep agent trial with configuration:
Update d_model to 64
Update decomposition to 1
Update distribution_type to laplace
Update dropout to 0.11082606525467036
Update e_layers to 7
Update fc_dropout to 0.07728530987757058
Update head_type to probabilistic
Update individual to 1
Update kernel_size to 32
Update n_heads to 4
Update patch_len to 4
Update stride to 128
Update subtract_last to 0
Update NORM_EACH_CHANNEL to True
Update NUM_EPOCHS to 100
Update OUTPUT_LEN to 96
Update RESCALE to False
Update TYPE to <class 'basicts.scaler.min_max_scaler.MinMaxScaler'>
Update BATCH_SIZE to 32
Update gamma to 0.4385914260838612
Update TYPE to MultiStepLR
Update lr to 0.00782273425986829
Update weight_decay to 0.00011771591918046793
Update TYPE to Adam
Update RESUME_TRAINING to False
Update USE_WANDB to True
{'DESCRIPTION': 'An Example Config', 'GPU_NUM': 1, 'RUNNER': <class 'basicts.runners.runner_zoo.simple_prob_tsf_runner.SimpleProbTimeSeriesForecastingRunner'>, 'USE_WANDB': True, 'DATASET': {'NAME': 'ETTh1', 'TYPE': <class 'basicts.data.simple_tsf_dataset.TimeSeriesForecastingDataset'>, 'PARAM': {'dataset_name': 'ETTh1', 'train_val_test_ratio': [0.6, 0.2, 0.2], 'input_len': 336, 'output_len': 96}}, 'SCALER': {'TYPE': <class 'basicts.scaler.min_max_scaler.MinMaxScaler'>, 'PARAM': {'dataset_name': 'ETTh1', 'train_ratio': 0.6, 'norm_each_channel': True, 'rescale': False}}, 'MODEL': {'NAME': 'PatchTST', 'ARCH': <class 'baselines.PatchTST.arch.patchtst_arch.PatchTST'>, 'PARAM': {'enc_in': 7, 'seq_len': 336, 'pred_len': 96, 'e_layers': 7, 'n_heads': 4, 'd_model': 64, 'd_ff': 128, 'dropout': 0.11082606525467036, 'fc_dropout': 0.07728530987757058, 'head_dropout': 0.0, 'patch_len': 4, 'stride': 128, 'individual': 1, 'padding_patch': 'end', 'revin': 0, 'affine': 0, 'subtract_last': 0, 'decomposition': 1, 'kernel_size': 32, 'head_type': 'probabilistic', 'distribution_type': 'laplace', 'quantiles': []}, 'FORWARD_FEATURES': [0], 'TARGET_FEATURES': [0]}, 'METRICS': {'FUNCS': {'NLL': <function nll_loss at 0x7f0765438360>, 'CRPS': <function crps at 0x7f0766413420>}, 'TARGET': 'NLL', 'NULL_VAL': nan}, 'TRAIN': {'RESUME_TRAINING': False, 'EARLY_STOPPING_PATIENCE': 5, 'NUM_EPOCHS': 100, 'CKPT_SAVE_DIR': 'checkpoints/gaussian_PatchTST/ETTh1_100_336_96', 'LOSS': <function nll_loss at 0x7f0765438360>, 'OPTIM': {'TYPE': 'Adam', 'PARAM': {'lr': 0.00782273425986829, 'weight_decay': 0.00011771591918046793}}, 'LR_SCHEDULER': {'TYPE': 'MultiStepLR', 'PARAM': {'milestones': [1, 25], 'gamma': 0.4385914260838612}}, 'CLIP_GRAD_PARAM': {'max_norm': 5.0}, 'DATA': {'BATCH_SIZE': 32, 'SHUFFLE': True}}, 'VAL': {'INTERVAL': 1, 'DATA': {'BATCH_SIZE': 64}}, 'TEST': {'INTERVAL': 1, 'DATA': {'BATCH_SIZE': 64}}, 'EVAL': {'USE_GPU': True}, 'MD5': 'b1a7fc8ebd65fd32cc59e1587d8e4831', 'NORM_EACH_CHANNEL': True, 'NUM_EPOCHS': 100, 'OUTPUT_LEN': 96, 'RESCALE': False}
2025-05-05 22:24:09,688 - easytorch-sweep-agent - INFO - Updated configuration with sweep parameters.
2025-05-05 22:24:09,689 - easytorch-launcher - INFO - Initializing runner '<class 'basicts.runners.runner_zoo.simple_prob_tsf_runner.SimpleProbTimeSeriesForecastingRunner'>'
2025-05-05 22:24:09,689 - easytorch-env - INFO - Disable TF32 mode
2025-05-05 22:24:09,690 - easytorch - INFO - Set ckpt save dir: 'checkpoints/gaussian_PatchTST/ETTh1_100_336_96/b1a7fc8ebd65fd32cc59e1587d8e4831'
2025-05-05 22:24:09,690 - easytorch - INFO - Building model.
PatchTST
2025-05-05 22:24:09,762 - easytorch-training - INFO - Initializing training.
2025-05-05 22:24:09,763 - easytorch-training - INFO - Set clip grad, param: {'max_norm': 5.0}
2025-05-05 22:24:09,763 - easytorch-training - INFO - Building training data loader.
2025-05-05 22:24:09,767 - easytorch-training - INFO - Train dataset length: 8209
2025-05-05 22:24:09,770 - easytorch-training - INFO - Set optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    decoupled_weight_decay: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.00782273425986829
    maximize: False
    weight_decay: 0.00011771591918046793
)
2025-05-05 22:24:09,771 - easytorch-training - INFO - Set lr_scheduler: <torch.optim.lr_scheduler.MultiStepLR object at 0x7f074d91e950>
2025-05-05 22:24:09,775 - easytorch-training - INFO - Initializing validation.
2025-05-05 22:24:09,775 - easytorch-training - INFO - Building val data loader.
2025-05-05 22:24:09,777 - easytorch-training - INFO - Validation dataset length: 2449
2025-05-05 22:24:09,779 - easytorch-training - INFO - Test dataset length: 2449
2025-05-05 22:24:09,781 - easytorch-training - INFO - Number of parameters: 1160576
2025-05-05 22:24:09,781 - easytorch-training - INFO - Epoch 1 / 100
  0%|          | 0/257 [00:00<?, ?it/s]  0%|          | 0/257 [00:00<?, ?it/s]
2025-05-05 22:24:09,800 - easytorch-training - ERROR - Traceback (most recent call last):
  File "/home/kreffert/Probabilistic_LTSF/BasicTS/basicts/launcher.py", line 183, in training_func
    best_metrics = runner.train(cfg=cfg)
                   ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kreffert/Probabilistic_LTSF/BasicTS/basicts/runners/base_epoch_runner.py", line 433, in train
    loss = self.train_iters(epoch, iter_index, data)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kreffert/Probabilistic_LTSF/BasicTS/basicts/runners/runner_zoo/simple_prob_tsf_runner.py", line 286, in train_iters
    forward_return = self.forward(data=data, epoch=epoch, iter_num=iter_num, train=True)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kreffert/Probabilistic_LTSF/BasicTS/basicts/runners/runner_zoo/simple_prob_tsf_runner.py", line 137, in forward
    model_return = self.model(history_data=history_data, future_data=future_data_4_dec,
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kreffert/miniconda3/envs/BasicTS/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kreffert/miniconda3/envs/BasicTS/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kreffert/Probabilistic_LTSF/BasicTS/baselines/PatchTST/arch/patchtst_arch.py", line 105, in forward
    res_init, trend_init = self.decomp_module(x)
                           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kreffert/miniconda3/envs/BasicTS/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kreffert/miniconda3/envs/BasicTS/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kreffert/Probabilistic_LTSF/BasicTS/baselines/PatchTST/arch/patchtst_layers.py", line 52, in forward
    res = x - moving_mean
          ~~^~~~~~~~~~~~~
RuntimeError: The size of tensor a (336) must match the size of tensor b (335) at non-singleton dimension 1

Traceback (most recent call last):
  File "/home/kreffert/Probabilistic_LTSF/BasicTS/basicts/launcher.py", line 363, in agent_function
    return sweep_agent_function(cfg)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kreffert/Probabilistic_LTSF/BasicTS/basicts/launcher.py", line 311, in sweep_agent_function
    training_func(merged_config, wandb_run=wandb.run)
  File "/home/kreffert/Probabilistic_LTSF/BasicTS/basicts/launcher.py", line 187, in training_func
    raise e
  File "/home/kreffert/Probabilistic_LTSF/BasicTS/basicts/launcher.py", line 183, in training_func
    best_metrics = runner.train(cfg=cfg)
                   ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kreffert/Probabilistic_LTSF/BasicTS/basicts/runners/base_epoch_runner.py", line 433, in train
    loss = self.train_iters(epoch, iter_index, data)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kreffert/Probabilistic_LTSF/BasicTS/basicts/runners/runner_zoo/simple_prob_tsf_runner.py", line 286, in train_iters
    forward_return = self.forward(data=data, epoch=epoch, iter_num=iter_num, train=True)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kreffert/Probabilistic_LTSF/BasicTS/basicts/runners/runner_zoo/simple_prob_tsf_runner.py", line 137, in forward
    model_return = self.model(history_data=history_data, future_data=future_data_4_dec,
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kreffert/miniconda3/envs/BasicTS/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kreffert/miniconda3/envs/BasicTS/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kreffert/Probabilistic_LTSF/BasicTS/baselines/PatchTST/arch/patchtst_arch.py", line 105, in forward
    res_init, trend_init = self.decomp_module(x)
                           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kreffert/miniconda3/envs/BasicTS/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kreffert/miniconda3/envs/BasicTS/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kreffert/Probabilistic_LTSF/BasicTS/baselines/PatchTST/arch/patchtst_layers.py", line 52, in forward
    res = x - moving_mean
          ~~^~~~~~~~~~~~~
RuntimeError: The size of tensor a (336) must match the size of tensor b (335) at non-singleton dimension 1
wandb:                                                                                
wandb: üöÄ View run PatchTST_May_05_22_24 at: https://wandb.ai/kai-reffert-university-mannheim/Prob_LTSF/runs/k1ka403r
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/kai-reffert-university-mannheim/Prob_LTSF
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250505_222408-k1ka403r/logs
wandb: ERROR Run k1ka403r errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/home/kreffert/miniconda3/envs/BasicTS/lib/python3.11/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/home/kreffert/Probabilistic_LTSF/BasicTS/basicts/launcher.py", line 363, in agent_function
wandb: ERROR     return sweep_agent_function(cfg)
wandb: ERROR            ^^^^^^^^^^^^^^^^^^^^^^^^^
wandb: ERROR   File "/home/kreffert/Probabilistic_LTSF/BasicTS/basicts/launcher.py", line 311, in sweep_agent_function
wandb: ERROR     training_func(merged_config, wandb_run=wandb.run)
wandb: ERROR   File "/home/kreffert/Probabilistic_LTSF/BasicTS/basicts/launcher.py", line 187, in training_func
wandb: ERROR     raise e
wandb: ERROR   File "/home/kreffert/Probabilistic_LTSF/BasicTS/basicts/launcher.py", line 183, in training_func
wandb: ERROR     best_metrics = runner.train(cfg=cfg)
wandb: ERROR                    ^^^^^^^^^^^^^^^^^^^^^
wandb: ERROR   File "/home/kreffert/Probabilistic_LTSF/BasicTS/basicts/runners/base_epoch_runner.py", line 433, in train
wandb: ERROR     loss = self.train_iters(epoch, iter_index, data)
wandb: ERROR            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
wandb: ERROR   File "/home/kreffert/Probabilistic_LTSF/BasicTS/basicts/runners/runner_zoo/simple_prob_tsf_runner.py", line 286, in train_iters
wandb: ERROR     forward_return = self.forward(data=data, epoch=epoch, iter_num=iter_num, train=True)
wandb: ERROR                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
wandb: ERROR   File "/home/kreffert/Probabilistic_LTSF/BasicTS/basicts/runners/runner_zoo/simple_prob_tsf_runner.py", line 137, in forward
wandb: ERROR     model_return = self.model(history_data=history_data, future_data=future_data_4_dec,
wandb: ERROR                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
wandb: ERROR   File "/home/kreffert/miniconda3/envs/BasicTS/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
wandb: ERROR     return self._call_impl(*args, **kwargs)
wandb: ERROR            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
wandb: ERROR   File "/home/kreffert/miniconda3/envs/BasicTS/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
wandb: ERROR     return forward_call(*args, **kwargs)
wandb: ERROR            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
wandb: ERROR   File "/home/kreffert/Probabilistic_LTSF/BasicTS/baselines/PatchTST/arch/patchtst_arch.py", line 105, in forward
wandb: ERROR     res_init, trend_init = self.decomp_module(x)
wandb: ERROR                            ^^^^^^^^^^^^^^^^^^^^^
wandb: ERROR   File "/home/kreffert/miniconda3/envs/BasicTS/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
wandb: ERROR     return self._call_impl(*args, **kwargs)
wandb: ERROR            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
wandb: ERROR   File "/home/kreffert/miniconda3/envs/BasicTS/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
wandb: ERROR     return forward_call(*args, **kwargs)
wandb: ERROR            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
wandb: ERROR   File "/home/kreffert/Probabilistic_LTSF/BasicTS/baselines/PatchTST/arch/patchtst_layers.py", line 52, in forward
wandb: ERROR     res = x - moving_mean
wandb: ERROR           ~~^~~~~~~~~~~~~
wandb: ERROR RuntimeError: The size of tensor a (336) must match the size of tensor b (335) at non-singleton dimension 1
wandb: ERROR 
wandb: Agent Starting Run: md6e7auw with config:
wandb: 	MODEL.PARAM.d_model: 8
wandb: 	MODEL.PARAM.decomposition: 1
wandb: 	MODEL.PARAM.distribution_type: student_t
wandb: 	MODEL.PARAM.dropout: 0.3391966053635608
wandb: 	MODEL.PARAM.e_layers: 7
wandb: 	MODEL.PARAM.fc_dropout: 0.1123290738231594
wandb: 	MODEL.PARAM.head_type: probabilistic
wandb: 	MODEL.PARAM.individual: 1
wandb: 	MODEL.PARAM.kernel_size: 64
wandb: 	MODEL.PARAM.n_heads: 4
wandb: 	MODEL.PARAM.patch_len: 8
wandb: 	MODEL.PARAM.stride: 16
wandb: 	MODEL.PARAM.subtract_last: 1
wandb: 	NORM_EACH_CHANNEL: True
wandb: 	NUM_EPOCHS: 100
wandb: 	OUTPUT_LEN: 96
wandb: 	RESCALE: True
wandb: 	SCALER.TYPE: MinMaxScaler
wandb: 	TRAIN.DATA.BATCH_SIZE: 128
wandb: 	TRAIN.LR_SCHEDULER.PARAM.gamma: 0.4860627145674297
wandb: 	TRAIN.LR_SCHEDULER.TYPE: MultiStepLR
wandb: 	TRAIN.OPTIM.PARAM.lr: 0.020924881100814884
wandb: 	TRAIN.OPTIM.PARAM.weight_decay: 0.00045803127828959966
wandb: 	TRAIN.OPTIM.TYPE: Adam
wandb: 	TRAIN.RESUME_TRAINING: False
wandb: 	USE_WANDB: True
wandb: WARNING Ignoring project 'Prob_LTSF' when running a sweep.
wandb: WARNING Ignoring entity 'kai-reffert-university-mannheim' when running a sweep.
wandb: Tracking run with wandb version 0.19.9
wandb: Run data is saved locally in /home/kreffert/Probabilistic_LTSF/BasicTS/wandb/run-20250505_222414-md6e7auw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run PatchTST_May_05_22_24
wandb: ‚≠êÔ∏è View project at https://wandb.ai/kai-reffert-university-mannheim/Prob_LTSF
wandb: üßπ View sweep at https://wandb.ai/kai-reffert-university-mannheim/Prob_LTSF/sweeps/fwvzje2j
wandb: üöÄ View run at https://wandb.ai/kai-reffert-university-mannheim/Prob_LTSF/runs/md6e7auw
2025-05-05 22:24:15,188 - easytorch-sweep-agent - INFO - Starting sweep agent trial with configuration:
Update d_model to 8
Update decomposition to 1
Update distribution_type to student_t
Update dropout to 0.3391966053635608
Update e_layers to 7
Update fc_dropout to 0.1123290738231594
Update head_type to probabilistic
Update individual to 1
Update kernel_size to 64
Update n_heads to 4
Update patch_len to 8
Update stride to 16
Update subtract_last to 1
Update NORM_EACH_CHANNEL to True
Update NUM_EPOCHS to 100
Update OUTPUT_LEN to 96
Update RESCALE to True
Update TYPE to <class 'basicts.scaler.min_max_scaler.MinMaxScaler'>
Update BATCH_SIZE to 128
Update gamma to 0.4860627145674297
Update TYPE to MultiStepLR
Update lr to 0.020924881100814884
Update weight_decay to 0.00045803127828959966
Update TYPE to Adam
Update RESUME_TRAINING to False
Update USE_WANDB to True
{'DESCRIPTION': 'An Example Config', 'GPU_NUM': 1, 'RUNNER': <class 'basicts.runners.runner_zoo.simple_prob_tsf_runner.SimpleProbTimeSeriesForecastingRunner'>, 'USE_WANDB': True, 'DATASET': {'NAME': 'ETTh1', 'TYPE': <class 'basicts.data.simple_tsf_dataset.TimeSeriesForecastingDataset'>, 'PARAM': {'dataset_name': 'ETTh1', 'train_val_test_ratio': [0.6, 0.2, 0.2], 'input_len': 336, 'output_len': 96}}, 'SCALER': {'TYPE': <class 'basicts.scaler.min_max_scaler.MinMaxScaler'>, 'PARAM': {'dataset_name': 'ETTh1', 'train_ratio': 0.6, 'norm_each_channel': True, 'rescale': False}}, 'MODEL': {'NAME': 'PatchTST', 'ARCH': <class 'baselines.PatchTST.arch.patchtst_arch.PatchTST'>, 'PARAM': {'enc_in': 7, 'seq_len': 336, 'pred_len': 96, 'e_layers': 7, 'n_heads': 4, 'd_model': 8, 'd_ff': 128, 'dropout': 0.3391966053635608, 'fc_dropout': 0.1123290738231594, 'head_dropout': 0.0, 'patch_len': 8, 'stride': 16, 'individual': 1, 'padding_patch': 'end', 'revin': 0, 'affine': 0, 'subtract_last': 1, 'decomposition': 1, 'kernel_size': 64, 'head_type': 'probabilistic', 'distribution_type': 'student_t', 'quantiles': []}, 'FORWARD_FEATURES': [0], 'TARGET_FEATURES': [0]}, 'METRICS': {'FUNCS': {'NLL': <function nll_loss at 0x7f0765438360>, 'CRPS': <function crps at 0x7f0766413420>}, 'TARGET': 'NLL', 'NULL_VAL': nan}, 'TRAIN': {'RESUME_TRAINING': False, 'EARLY_STOPPING_PATIENCE': 5, 'NUM_EPOCHS': 100, 'CKPT_SAVE_DIR': 'checkpoints/gaussian_PatchTST/ETTh1_100_336_96', 'LOSS': <function nll_loss at 0x7f0765438360>, 'OPTIM': {'TYPE': 'Adam', 'PARAM': {'lr': 0.020924881100814884, 'weight_decay': 0.00045803127828959966}}, 'LR_SCHEDULER': {'TYPE': 'MultiStepLR', 'PARAM': {'milestones': [1, 25], 'gamma': 0.4860627145674297}}, 'CLIP_GRAD_PARAM': {'max_norm': 5.0}, 'DATA': {'BATCH_SIZE': 128, 'SHUFFLE': True}}, 'VAL': {'INTERVAL': 1, 'DATA': {'BATCH_SIZE': 64}}, 'TEST': {'INTERVAL': 1, 'DATA': {'BATCH_SIZE': 64}}, 'EVAL': {'USE_GPU': True}, 'MD5': 'b1a7fc8ebd65fd32cc59e1587d8e4831', 'NORM_EACH_CHANNEL': True, 'NUM_EPOCHS': 100, 'OUTPUT_LEN': 96, 'RESCALE': True}
2025-05-05 22:24:15,192 - easytorch-sweep-agent - INFO - Updated configuration with sweep parameters.
2025-05-05 22:24:15,192 - easytorch-launcher - INFO - Initializing runner '<class 'basicts.runners.runner_zoo.simple_prob_tsf_runner.SimpleProbTimeSeriesForecastingRunner'>'
2025-05-05 22:24:15,193 - easytorch-env - INFO - Disable TF32 mode
2025-05-05 22:24:15,193 - easytorch - INFO - Set ckpt save dir: 'checkpoints/gaussian_PatchTST/ETTh1_100_336_96/b1a7fc8ebd65fd32cc59e1587d8e4831'
2025-05-05 22:24:15,194 - easytorch - INFO - Building model.
PatchTST
2025-05-05 22:24:15,263 - easytorch-training - INFO - Initializing training.
2025-05-05 22:24:15,264 - easytorch-training - INFO - Set clip grad, param: {'max_norm': 5.0}
2025-05-05 22:24:15,264 - easytorch-training - INFO - Building training data loader.
2025-05-05 22:24:15,268 - easytorch-training - INFO - Train dataset length: 8209
2025-05-05 22:24:15,272 - easytorch-training - INFO - Set optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    decoupled_weight_decay: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.020924881100814884
    maximize: False
    weight_decay: 0.00045803127828959966
)
2025-05-05 22:24:15,273 - easytorch-training - INFO - Set lr_scheduler: <torch.optim.lr_scheduler.MultiStepLR object at 0x7f074d66d950>
2025-05-05 22:24:15,276 - easytorch-training - INFO - Initializing validation.
2025-05-05 22:24:15,276 - easytorch-training - INFO - Building val data loader.
2025-05-05 22:24:15,278 - easytorch-training - INFO - Validation dataset length: 2449
2025-05-05 22:24:15,280 - easytorch-training - INFO - Test dataset length: 2449
2025-05-05 22:24:15,282 - easytorch-training - INFO - Number of parameters: 749216
2025-05-05 22:24:15,282 - easytorch-training - INFO - Epoch 1 / 100
  0%|          | 0/65 [00:00<?, ?it/s]  0%|          | 0/65 [00:00<?, ?it/s]
2025-05-05 22:24:15,313 - easytorch-training - ERROR - Traceback (most recent call last):
  File "/home/kreffert/Probabilistic_LTSF/BasicTS/basicts/launcher.py", line 183, in training_func
    best_metrics = runner.train(cfg=cfg)
                   ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kreffert/Probabilistic_LTSF/BasicTS/basicts/runners/base_epoch_runner.py", line 433, in train
    loss = self.train_iters(epoch, iter_index, data)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kreffert/Probabilistic_LTSF/BasicTS/basicts/runners/runner_zoo/simple_prob_tsf_runner.py", line 286, in train_iters
    forward_return = self.forward(data=data, epoch=epoch, iter_num=iter_num, train=True)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kreffert/Probabilistic_LTSF/BasicTS/basicts/runners/runner_zoo/simple_prob_tsf_runner.py", line 137, in forward
    model_return = self.model(history_data=history_data, future_data=future_data_4_dec,
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kreffert/miniconda3/envs/BasicTS/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kreffert/miniconda3/envs/BasicTS/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kreffert/Probabilistic_LTSF/BasicTS/baselines/PatchTST/arch/patchtst_arch.py", line 105, in forward
    res_init, trend_init = self.decomp_module(x)
                           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kreffert/miniconda3/envs/BasicTS/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kreffert/miniconda3/envs/BasicTS/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kreffert/Probabilistic_LTSF/BasicTS/baselines/PatchTST/arch/patchtst_layers.py", line 52, in forward
    res = x - moving_mean
          ~~^~~~~~~~~~~~~
RuntimeError: The size of tensor a (336) must match the size of tensor b (335) at non-singleton dimension 1

Traceback (most recent call last):
  File "/home/kreffert/Probabilistic_LTSF/BasicTS/basicts/launcher.py", line 363, in agent_function
    return sweep_agent_function(cfg)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kreffert/Probabilistic_LTSF/BasicTS/basicts/launcher.py", line 311, in sweep_agent_function
    training_func(merged_config, wandb_run=wandb.run)
  File "/home/kreffert/Probabilistic_LTSF/BasicTS/basicts/launcher.py", line 187, in training_func
    raise e
  File "/home/kreffert/Probabilistic_LTSF/BasicTS/basicts/launcher.py", line 183, in training_func
    best_metrics = runner.train(cfg=cfg)
                   ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kreffert/Probabilistic_LTSF/BasicTS/basicts/runners/base_epoch_runner.py", line 433, in train
    loss = self.train_iters(epoch, iter_index, data)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kreffert/Probabilistic_LTSF/BasicTS/basicts/runners/runner_zoo/simple_prob_tsf_runner.py", line 286, in train_iters
    forward_return = self.forward(data=data, epoch=epoch, iter_num=iter_num, train=True)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kreffert/Probabilistic_LTSF/BasicTS/basicts/runners/runner_zoo/simple_prob_tsf_runner.py", line 137, in forward
    model_return = self.model(history_data=history_data, future_data=future_data_4_dec,
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kreffert/miniconda3/envs/BasicTS/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kreffert/miniconda3/envs/BasicTS/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kreffert/Probabilistic_LTSF/BasicTS/baselines/PatchTST/arch/patchtst_arch.py", line 105, in forward
    res_init, trend_init = self.decomp_module(x)
                           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kreffert/miniconda3/envs/BasicTS/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kreffert/miniconda3/envs/BasicTS/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kreffert/Probabilistic_LTSF/BasicTS/baselines/PatchTST/arch/patchtst_layers.py", line 52, in forward
    res = x - moving_mean
          ~~^~~~~~~~~~~~~
RuntimeError: The size of tensor a (336) must match the size of tensor b (335) at non-singleton dimension 1
wandb: uploading summary, console lines 0-131
wandb:                                                                                
wandb: üöÄ View run PatchTST_May_05_22_24 at: https://wandb.ai/kai-reffert-university-mannheim/Prob_LTSF/runs/md6e7auw
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/kai-reffert-university-mannheim/Prob_LTSF
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250505_222414-md6e7auw/logs
wandb: ERROR Run md6e7auw errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/home/kreffert/miniconda3/envs/BasicTS/lib/python3.11/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/home/kreffert/Probabilistic_LTSF/BasicTS/basicts/launcher.py", line 363, in agent_function
wandb: ERROR     return sweep_agent_function(cfg)
wandb: ERROR            ^^^^^^^^^^^^^^^^^^^^^^^^^
wandb: ERROR   File "/home/kreffert/Probabilistic_LTSF/BasicTS/basicts/launcher.py", line 311, in sweep_agent_function
wandb: ERROR     training_func(merged_config, wandb_run=wandb.run)
wandb: ERROR   File "/home/kreffert/Probabilistic_LTSF/BasicTS/basicts/launcher.py", line 187, in training_func
wandb: ERROR     raise e
wandb: ERROR   File "/home/kreffert/Probabilistic_LTSF/BasicTS/basicts/launcher.py", line 183, in training_func
wandb: ERROR     best_metrics = runner.train(cfg=cfg)
wandb: ERROR                    ^^^^^^^^^^^^^^^^^^^^^
wandb: ERROR   File "/home/kreffert/Probabilistic_LTSF/BasicTS/basicts/runners/base_epoch_runner.py", line 433, in train
wandb: ERROR     loss = self.train_iters(epoch, iter_index, data)
wandb: ERROR            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
wandb: ERROR   File "/home/kreffert/Probabilistic_LTSF/BasicTS/basicts/runners/runner_zoo/simple_prob_tsf_runner.py", line 286, in train_iters
wandb: ERROR     forward_return = self.forward(data=data, epoch=epoch, iter_num=iter_num, train=True)
wandb: ERROR                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
wandb: ERROR   File "/home/kreffert/Probabilistic_LTSF/BasicTS/basicts/runners/runner_zoo/simple_prob_tsf_runner.py", line 137, in forward
wandb: ERROR     model_return = self.model(history_data=history_data, future_data=future_data_4_dec,
wandb: ERROR                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
wandb: ERROR   File "/home/kreffert/miniconda3/envs/BasicTS/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
wandb: ERROR     return self._call_impl(*args, **kwargs)
wandb: ERROR            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
wandb: ERROR   File "/home/kreffert/miniconda3/envs/BasicTS/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
wandb: ERROR     return forward_call(*args, **kwargs)
wandb: ERROR            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
wandb: ERROR   File "/home/kreffert/Probabilistic_LTSF/BasicTS/baselines/PatchTST/arch/patchtst_arch.py", line 105, in forward
wandb: ERROR     res_init, trend_init = self.decomp_module(x)
wandb: ERROR                            ^^^^^^^^^^^^^^^^^^^^^
wandb: ERROR   File "/home/kreffert/miniconda3/envs/BasicTS/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
wandb: ERROR     return self._call_impl(*args, **kwargs)
wandb: ERROR            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
wandb: ERROR   File "/home/kreffert/miniconda3/envs/BasicTS/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
wandb: ERROR     return forward_call(*args, **kwargs)
wandb: ERROR            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
wandb: ERROR   File "/home/kreffert/Probabilistic_LTSF/BasicTS/baselines/PatchTST/arch/patchtst_layers.py", line 52, in forward
wandb: ERROR     res = x - moving_mean
wandb: ERROR           ~~^~~~~~~~~~~~~
wandb: ERROR RuntimeError: The size of tensor a (336) must match the size of tensor b (335) at non-singleton dimension 1
wandb: ERROR 
wandb: Agent Starting Run: qi97qxg9 with config:
wandb: 	MODEL.PARAM.d_model: 32
wandb: 	MODEL.PARAM.decomposition: 1
wandb: 	MODEL.PARAM.distribution_type: student_t
wandb: 	MODEL.PARAM.dropout: 0.0943036187583432
wandb: 	MODEL.PARAM.e_layers: 3
wandb: 	MODEL.PARAM.fc_dropout: 0.15949283811930806
wandb: 	MODEL.PARAM.head_type: probabilistic
wandb: 	MODEL.PARAM.individual: 1
wandb: 	MODEL.PARAM.kernel_size: 64
wandb: 	MODEL.PARAM.n_heads: 4
wandb: 	MODEL.PARAM.patch_len: 4
wandb: 	MODEL.PARAM.stride: 32
wandb: 	MODEL.PARAM.subtract_last: 0
wandb: 	NORM_EACH_CHANNEL: True
wandb: 	NUM_EPOCHS: 100
wandb: 	OUTPUT_LEN: 96
wandb: 	RESCALE: False
wandb: 	SCALER.TYPE: MinMaxScaler
wandb: 	TRAIN.DATA.BATCH_SIZE: 64
wandb: 	TRAIN.LR_SCHEDULER.PARAM.gamma: 0.6757935611534697
wandb: 	TRAIN.LR_SCHEDULER.TYPE: MultiStepLR
wandb: 	TRAIN.OPTIM.PARAM.lr: 0.010096850572820231
wandb: 	TRAIN.OPTIM.PARAM.weight_decay: 0.00044293216483740186
wandb: 	TRAIN.OPTIM.TYPE: Adam
wandb: 	TRAIN.RESUME_TRAINING: False
wandb: 	USE_WANDB: True
wandb: WARNING Ignoring project 'Prob_LTSF' when running a sweep.
wandb: WARNING Ignoring entity 'kai-reffert-university-mannheim' when running a sweep.
wandb: Tracking run with wandb version 0.19.9
wandb: Run data is saved locally in /home/kreffert/Probabilistic_LTSF/BasicTS/wandb/run-20250505_222420-qi97qxg9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run PatchTST_May_05_22_24
wandb: ‚≠êÔ∏è View project at https://wandb.ai/kai-reffert-university-mannheim/Prob_LTSF
wandb: üßπ View sweep at https://wandb.ai/kai-reffert-university-mannheim/Prob_LTSF/sweeps/fwvzje2j
wandb: üöÄ View run at https://wandb.ai/kai-reffert-university-mannheim/Prob_LTSF/runs/qi97qxg9
2025-05-05 22:24:21,694 - easytorch-sweep-agent - INFO - Starting sweep agent trial with configuration:
Update d_model to 32
Update decomposition to 1
Update distribution_type to student_t
Update dropout to 0.0943036187583432
Update e_layers to 3
Update fc_dropout to 0.15949283811930806
Update head_type to probabilistic
Update individual to 1
Update kernel_size to 64
Update n_heads to 4
Update patch_len to 4
Update stride to 32
Update subtract_last to 0
Update NORM_EACH_CHANNEL to True
Update NUM_EPOCHS to 100
Update OUTPUT_LEN to 96
Update RESCALE to False
Update TYPE to <class 'basicts.scaler.min_max_scaler.MinMaxScaler'>
Update BATCH_SIZE to 64
Update gamma to 0.6757935611534697
Update TYPE to MultiStepLR
Update lr to 0.010096850572820231
Update weight_decay to 0.00044293216483740186
Update TYPE to Adam
Update RESUME_TRAINING to False
Update USE_WANDB to True
{'DESCRIPTION': 'An Example Config', 'GPU_NUM': 1, 'RUNNER': <class 'basicts.runners.runner_zoo.simple_prob_tsf_runner.SimpleProbTimeSeriesForecastingRunner'>, 'USE_WANDB': True, 'DATASET': {'NAME': 'ETTh1', 'TYPE': <class 'basicts.data.simple_tsf_dataset.TimeSeriesForecastingDataset'>, 'PARAM': {'dataset_name': 'ETTh1', 'train_val_test_ratio': [0.6, 0.2, 0.2], 'input_len': 336, 'output_len': 96}}, 'SCALER': {'TYPE': <class 'basicts.scaler.min_max_scaler.MinMaxScaler'>, 'PARAM': {'dataset_name': 'ETTh1', 'train_ratio': 0.6, 'norm_each_channel': True, 'rescale': False}}, 'MODEL': {'NAME': 'PatchTST', 'ARCH': <class 'baselines.PatchTST.arch.patchtst_arch.PatchTST'>, 'PARAM': {'enc_in': 7, 'seq_len': 336, 'pred_len': 96, 'e_layers': 3, 'n_heads': 4, 'd_model': 32, 'd_ff': 128, 'dropout': 0.0943036187583432, 'fc_dropout': 0.15949283811930806, 'head_dropout': 0.0, 'patch_len': 4, 'stride': 32, 'individual': 1, 'padding_patch': 'end', 'revin': 0, 'affine': 0, 'subtract_last': 0, 'decomposition': 1, 'kernel_size': 64, 'head_type': 'probabilistic', 'distribution_type': 'student_t', 'quantiles': []}, 'FORWARD_FEATURES': [0], 'TARGET_FEATURES': [0]}, 'METRICS': {'FUNCS': {'NLL': <function nll_loss at 0x7f0765438360>, 'CRPS': <function crps at 0x7f0766413420>}, 'TARGET': 'NLL', 'NULL_VAL': nan}, 'TRAIN': {'RESUME_TRAINING': False, 'EARLY_STOPPING_PATIENCE': 5, 'NUM_EPOCHS': 100, 'CKPT_SAVE_DIR': 'checkpoints/gaussian_PatchTST/ETTh1_100_336_96', 'LOSS': <function nll_loss at 0x7f0765438360>, 'OPTIM': {'TYPE': 'Adam', 'PARAM': {'lr': 0.010096850572820231, 'weight_decay': 0.00044293216483740186}}, 'LR_SCHEDULER': {'TYPE': 'MultiStepLR', 'PARAM': {'milestones': [1, 25], 'gamma': 0.6757935611534697}}, 'CLIP_GRAD_PARAM': {'max_norm': 5.0}, 'DATA': {'BATCH_SIZE': 64, 'SHUFFLE': True}}, 'VAL': {'INTERVAL': 1, 'DATA': {'BATCH_SIZE': 64}}, 'TEST': {'INTERVAL': 1, 'DATA': {'BATCH_SIZE': 64}}, 'EVAL': {'USE_GPU': True}, 'MD5': 'b1a7fc8ebd65fd32cc59e1587d8e4831', 'NORM_EACH_CHANNEL': True, 'NUM_EPOCHS': 100, 'OUTPUT_LEN': 96, 'RESCALE': False}
2025-05-05 22:24:21,700 - easytorch-sweep-agent - INFO - Updated configuration with sweep parameters.
2025-05-05 22:24:21,700 - easytorch-launcher - INFO - Initializing runner '<class 'basicts.runners.runner_zoo.simple_prob_tsf_runner.SimpleProbTimeSeriesForecastingRunner'>'
2025-05-05 22:24:21,700 - easytorch-env - INFO - Disable TF32 mode
2025-05-05 22:24:21,701 - easytorch - INFO - Set ckpt save dir: 'checkpoints/gaussian_PatchTST/ETTh1_100_336_96/b1a7fc8ebd65fd32cc59e1587d8e4831'
2025-05-05 22:24:21,701 - easytorch - INFO - Building model.
PatchTST
2025-05-05 22:24:21,773 - easytorch-training - INFO - Initializing training.
2025-05-05 22:24:21,773 - easytorch-training - INFO - Set clip grad, param: {'max_norm': 5.0}
2025-05-05 22:24:21,773 - easytorch-training - INFO - Building training data loader.
2025-05-05 22:24:21,777 - easytorch-training - INFO - Train dataset length: 8209
2025-05-05 22:24:21,780 - easytorch-training - INFO - Set optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    decoupled_weight_decay: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.010096850572820231
    maximize: False
    weight_decay: 0.00044293216483740186
)
2025-05-05 22:24:21,781 - easytorch-training - INFO - Set lr_scheduler: <torch.optim.lr_scheduler.MultiStepLR object at 0x7f074d6b1550>
2025-05-05 22:24:21,784 - easytorch-training - INFO - Initializing validation.
2025-05-05 22:24:21,785 - easytorch-training - INFO - Building val data loader.
2025-05-05 22:24:21,786 - easytorch-training - INFO - Validation dataset length: 2449
2025-05-05 22:24:21,788 - easytorch-training - INFO - Test dataset length: 2449
2025-05-05 22:24:21,789 - easytorch-training - INFO - Number of parameters: 1629632
2025-05-05 22:24:21,790 - easytorch-training - INFO - Epoch 1 / 100
  0%|          | 0/129 [00:00<?, ?it/s]  0%|          | 0/129 [00:00<?, ?it/s]
2025-05-05 22:24:21,813 - easytorch-training - ERROR - Traceback (most recent call last):
  File "/home/kreffert/Probabilistic_LTSF/BasicTS/basicts/launcher.py", line 183, in training_func
    best_metrics = runner.train(cfg=cfg)
                   ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kreffert/Probabilistic_LTSF/BasicTS/basicts/runners/base_epoch_runner.py", line 433, in train
    loss = self.train_iters(epoch, iter_index, data)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kreffert/Probabilistic_LTSF/BasicTS/basicts/runners/runner_zoo/simple_prob_tsf_runner.py", line 286, in train_iters
    forward_return = self.forward(data=data, epoch=epoch, iter_num=iter_num, train=True)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kreffert/Probabilistic_LTSF/BasicTS/basicts/runners/runner_zoo/simple_prob_tsf_runner.py", line 137, in forward
    model_return = self.model(history_data=history_data, future_data=future_data_4_dec,
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kreffert/miniconda3/envs/BasicTS/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kreffert/miniconda3/envs/BasicTS/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kreffert/Probabilistic_LTSF/BasicTS/baselines/PatchTST/arch/patchtst_arch.py", line 105, in forward
    res_init, trend_init = self.decomp_module(x)
                           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kreffert/miniconda3/envs/BasicTS/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kreffert/miniconda3/envs/BasicTS/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kreffert/Probabilistic_LTSF/BasicTS/baselines/PatchTST/arch/patchtst_layers.py", line 52, in forward
    res = x - moving_mean
          ~~^~~~~~~~~~~~~
RuntimeError: The size of tensor a (336) must match the size of tensor b (335) at non-singleton dimension 1

Traceback (most recent call last):
  File "/home/kreffert/Probabilistic_LTSF/BasicTS/basicts/launcher.py", line 363, in agent_function
    return sweep_agent_function(cfg)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kreffert/Probabilistic_LTSF/BasicTS/basicts/launcher.py", line 311, in sweep_agent_function
    training_func(merged_config, wandb_run=wandb.run)
  File "/home/kreffert/Probabilistic_LTSF/BasicTS/basicts/launcher.py", line 187, in training_func
    raise e
  File "/home/kreffert/Probabilistic_LTSF/BasicTS/basicts/launcher.py", line 183, in training_func
    best_metrics = runner.train(cfg=cfg)
                   ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kreffert/Probabilistic_LTSF/BasicTS/basicts/runners/base_epoch_runner.py", line 433, in train
    loss = self.train_iters(epoch, iter_index, data)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kreffert/Probabilistic_LTSF/BasicTS/basicts/runners/runner_zoo/simple_prob_tsf_runner.py", line 286, in train_iters
    forward_return = self.forward(data=data, epoch=epoch, iter_num=iter_num, train=True)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kreffert/Probabilistic_LTSF/BasicTS/basicts/runners/runner_zoo/simple_prob_tsf_runner.py", line 137, in forward
    model_return = self.model(history_data=history_data, future_data=future_data_4_dec,
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kreffert/miniconda3/envs/BasicTS/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kreffert/miniconda3/envs/BasicTS/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kreffert/Probabilistic_LTSF/BasicTS/baselines/PatchTST/arch/patchtst_arch.py", line 105, in forward
    res_init, trend_init = self.decomp_module(x)
                           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kreffert/miniconda3/envs/BasicTS/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kreffert/miniconda3/envs/BasicTS/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kreffert/Probabilistic_LTSF/BasicTS/baselines/PatchTST/arch/patchtst_layers.py", line 52, in forward
    res = x - moving_mean
          ~~^~~~~~~~~~~~~
RuntimeError: The size of tensor a (336) must match the size of tensor b (335) at non-singleton dimension 1
wandb: uploading summary, console lines 0-131
wandb:                                                                                
wandb: üöÄ View run PatchTST_May_05_22_24 at: https://wandb.ai/kai-reffert-university-mannheim/Prob_LTSF/runs/qi97qxg9
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/kai-reffert-university-mannheim/Prob_LTSF
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250505_222420-qi97qxg9/logs
wandb: ERROR Run qi97qxg9 errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/home/kreffert/miniconda3/envs/BasicTS/lib/python3.11/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/home/kreffert/Probabilistic_LTSF/BasicTS/basicts/launcher.py", line 363, in agent_function
wandb: ERROR     return sweep_agent_function(cfg)
wandb: ERROR            ^^^^^^^^^^^^^^^^^^^^^^^^^
wandb: ERROR   File "/home/kreffert/Probabilistic_LTSF/BasicTS/basicts/launcher.py", line 311, in sweep_agent_function
wandb: ERROR     training_func(merged_config, wandb_run=wandb.run)
wandb: ERROR   File "/home/kreffert/Probabilistic_LTSF/BasicTS/basicts/launcher.py", line 187, in training_func
wandb: ERROR     raise e
wandb: ERROR   File "/home/kreffert/Probabilistic_LTSF/BasicTS/basicts/launcher.py", line 183, in training_func
wandb: ERROR     best_metrics = runner.train(cfg=cfg)
wandb: ERROR                    ^^^^^^^^^^^^^^^^^^^^^
wandb: ERROR   File "/home/kreffert/Probabilistic_LTSF/BasicTS/basicts/runners/base_epoch_runner.py", line 433, in train
wandb: ERROR     loss = self.train_iters(epoch, iter_index, data)
wandb: ERROR            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
wandb: ERROR   File "/home/kreffert/Probabilistic_LTSF/BasicTS/basicts/runners/runner_zoo/simple_prob_tsf_runner.py", line 286, in train_iters
wandb: ERROR     forward_return = self.forward(data=data, epoch=epoch, iter_num=iter_num, train=True)
wandb: ERROR                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
wandb: ERROR   File "/home/kreffert/Probabilistic_LTSF/BasicTS/basicts/runners/runner_zoo/simple_prob_tsf_runner.py", line 137, in forward
wandb: ERROR     model_return = self.model(history_data=history_data, future_data=future_data_4_dec,
wandb: ERROR                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
wandb: ERROR   File "/home/kreffert/miniconda3/envs/BasicTS/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
wandb: ERROR     return self._call_impl(*args, **kwargs)
wandb: ERROR            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
wandb: ERROR   File "/home/kreffert/miniconda3/envs/BasicTS/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
wandb: ERROR     return forward_call(*args, **kwargs)
wandb: ERROR            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
wandb: ERROR   File "/home/kreffert/Probabilistic_LTSF/BasicTS/baselines/PatchTST/arch/patchtst_arch.py", line 105, in forward
wandb: ERROR     res_init, trend_init = self.decomp_module(x)
wandb: ERROR                            ^^^^^^^^^^^^^^^^^^^^^
wandb: ERROR   File "/home/kreffert/miniconda3/envs/BasicTS/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
wandb: ERROR     return self._call_impl(*args, **kwargs)
wandb: ERROR            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
wandb: ERROR   File "/home/kreffert/miniconda3/envs/BasicTS/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
wandb: ERROR     return forward_call(*args, **kwargs)
wandb: ERROR            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
wandb: ERROR   File "/home/kreffert/Probabilistic_LTSF/BasicTS/baselines/PatchTST/arch/patchtst_layers.py", line 52, in forward
wandb: ERROR     res = x - moving_mean
wandb: ERROR           ~~^~~~~~~~~~~~~
wandb: ERROR RuntimeError: The size of tensor a (336) must match the size of tensor b (335) at non-singleton dimension 1
wandb: ERROR 
wandb: ERROR Detected 5 failed runs in a row at start, killing sweep.
wandb: To change this value set WANDB_AGENT_MAX_INITIAL_FAILURES=val
