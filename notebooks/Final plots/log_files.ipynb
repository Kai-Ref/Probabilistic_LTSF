{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b658d465-7994-4f3e-a7b9-1f82b2fc53c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-01 10:08:57,578 - easytorch-env - INFO - Use devices 0.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "prefix = \"/home/kreffert/\"\n",
    "prefix = \"/pfs/data6/home/ma/ma_ma/ma_kreffert/\" \n",
    "os.chdir(f'{prefix}Probabilistic_LTSF/BasicTS/')\n",
    "from basicts.metrics import masked_mae, masked_mse, nll_loss, crps, Evaluator, quantile_loss, empirical_crps\n",
    "from easytorch.device import set_device_type\n",
    "from easytorch.utils import get_logger, set_visible_devices\n",
    "# set the device type (CPU, GPU, or MLU)\n",
    "device_type ='gpu'\n",
    "gpus = '0'\n",
    "set_device_type(device_type)\n",
    "set_visible_devices(gpus)\n",
    "from easydict import EasyDict\n",
    "from tqdm import tqdm\n",
    "\n",
    "# extract the paths to the configs and weights\n",
    "import yaml\n",
    "# /home/kreffert/Probabilistic_LTSF/notebooks/Final plots/weights.yaml\n",
    "with open(f'{prefix}Probabilistic_LTSF/notebooks/Final plots/weights.yaml', 'r') as file:\n",
    "    _configs = yaml.safe_load(file)\n",
    "import glob \n",
    "def reconstruct_paths(\n",
    "    simplified_dict,\n",
    "    _dataset=['ETTh1', 'ETTm1'],\n",
    "    _models=['DLinear', 'PatchTST', 'DeepAR'],\n",
    "    _dists=['q', 'iq', 'u', 'm'],\n",
    "    _seeds=[0, 1, 2, 3, 4],\n",
    "    _model_dist_map=None  # optional: {'DLinear': ['m'], 'DeepAR': ['u']}\n",
    "):\n",
    "    base_path = \"final_weights/\"\n",
    "    dist_mapping = {\"iq\": \"i_quantile\", \"u\": \"univariate\", \"m\": \"multivariate\", \"q\": \"quantile\"}\n",
    "    filtered_dict = {}\n",
    "\n",
    "    for dataset, models in simplified_dict.items():\n",
    "        if dataset not in _dataset:\n",
    "            continue\n",
    "        for model, dists in models.items():\n",
    "            if _model_dist_map:\n",
    "                if model not in _model_dist_map:\n",
    "                    continue\n",
    "            elif model not in _models:\n",
    "                continue\n",
    "\n",
    "            allowed_dists = _model_dist_map[model] if _model_dist_map else _dists\n",
    "\n",
    "            for dist, seeds in dists.items():\n",
    "                if dist not in allowed_dists:\n",
    "                    continue\n",
    "                _cfg = f\"{dataset}_prob_quantile.py\" if dist in [\"q\", \"iq\"] else f\"{dataset}_prob.py\"\n",
    "                _ckpt = \"_best_val_QL.pt\" if dist in [\"q\", \"iq\"] else \"_best_val_NLL.pt\"\n",
    "                mapped_dist = dist_mapping.get(dist, dist)\n",
    "\n",
    "                for seed, path_suffix in seeds.items():\n",
    "                    if seed not in _seeds or path_suffix is None:\n",
    "                        continue\n",
    "                    prefix = f\"{base_path}{dataset}/{model}/{mapped_dist}/{seed}/{path_suffix}\"\n",
    "                    log_pattern = os.path.join(prefix, \"training_log_*.log\")\n",
    "                    log_files = glob.glob(log_pattern)\n",
    "                    log_file = log_files[-1] if log_files else None\n",
    "                    filtered_dict.setdefault(dataset, {}).setdefault(model, {}).setdefault(dist, {})[seed] = {\n",
    "                        'cfg': f\"{prefix}/{_cfg}\",\n",
    "                        'ckpt': f\"{prefix}/{model}{_ckpt}\",\n",
    "                        'log': log_file,\n",
    "                    }\n",
    "\n",
    "    return filtered_dict\n",
    "\n",
    "\n",
    "\n",
    "_model_dist_map={'DLinear': ['m'], 'DeepAR': ['u']}\n",
    "_models = ['DeepAR'] #full_dict[dataset][model][dist][random_state]\n",
    "_dataset = ['ETTh1']\n",
    "_dists = ['u', 'm']\n",
    "_seeds = [0, 1, 2]\n",
    "_configs = reconstruct_paths(_configs, _dataset=_dataset, _models=_models, _dists=_dists, _seeds=_seeds, _model_dist_map=_model_dist_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "02b5a8aa-fca1-44cd-bcb0-bc5ddd897a05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{   'ETTh1': {   'DLinear': {   'm': {   2: {   'epoch_durations': [1085.83, 1082.46, 1081.83, 1080.72, 1077.76, 1082.34, 1082.08, 1087.5, 1082.16, 1082.08, 1082.41],\n",
      "                                                'num_epochs': 11,\n",
      "                                                'num_parameters': 188061120}}},\n",
      "                 'DeepAR': {   'u': {   0: {   'epoch_durations': [183.74, 181.54, 181.25, 181.28, 181.04, 181.13, 180.99, 180.95, 180.45, 180.79, 180.56, 181.25, 179.9, 179.4],\n",
      "                                               'num_epochs': 14,\n",
      "                                               'num_parameters': 81307},\n",
      "                                        2: {'epoch_durations': [212.25, 208.94, 208.77, 208.31, 208.74, 208.89, 208.81, 209.19, 208.55, 208.91, 209.04], 'num_epochs': 11, 'num_parameters': 81307}}}}}\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def parse_log_for_epochs(log_path):\n",
    "    epoch_pattern = re.compile(r\"Epoch (\\d+) / (\\d+)\")\n",
    "    train_time_pattern = re.compile(r\"train/time: ([\\d.]+) \\(s\\)\")\n",
    "    params_pattern = re.compile(r\"Number of parameters:\\s*(\\d+)\")\n",
    "\n",
    "    num_parameters = None\n",
    "    epochs = []\n",
    "    durations = []\n",
    "\n",
    "    with open(log_path, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    for line in lines:\n",
    "        # Extract number of parameters (only once)\n",
    "        if num_parameters is None:\n",
    "            params_match = params_pattern.search(line)\n",
    "            if params_match:\n",
    "                num_parameters = int(params_match.group(1))\n",
    "\n",
    "        epoch_match = epoch_pattern.search(line)\n",
    "        if epoch_match:\n",
    "            epoch_num = int(epoch_match.group(1))\n",
    "            epochs.append(epoch_num)\n",
    "\n",
    "        time_match = train_time_pattern.search(line)\n",
    "        if time_match:\n",
    "            durations.append(float(time_match.group(1)))\n",
    "\n",
    "    num_epochs = len(epochs)\n",
    "    return num_epochs, durations, num_parameters\n",
    "\n",
    "def extract_data(simplified_dict):\n",
    "    epoch_dict = {}\n",
    "    for dataset, models in simplified_dict.items():\n",
    "        for model, dists in models.items():\n",
    "            for dist, seeds in dists.items():\n",
    "                _cfg = f\"{dataset}_prob_quantile.py\" if dist in [\"q\", \"iq\"] else f\"{dataset}_prob.py\"\n",
    "                _ckpt = \"_best_val_QL.pt\" if dist in [\"q\", \"iq\"] else \"_best_val_NLL.pt\"\n",
    "                for seed, path_suffix in seeds.items():\n",
    "                    log_path = simplified_dict[dataset][model][dist][seed]['log']\n",
    "                    if log_path is not None:\n",
    "                        num_epochs, epoch_durations, num_parameters = parse_log_for_epochs(log_path)\n",
    "                        epoch_dict.setdefault(dataset, {}).setdefault(model, {}).setdefault(dist, {})[seed] = {\n",
    "                            'num_epochs': num_epochs,\n",
    "                            'epoch_durations': epoch_durations,\n",
    "                            'num_parameters': num_parameters\n",
    "                        }\n",
    "\n",
    "    return epoch_dict\n",
    "\n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=4, width=200)\n",
    "epoch_dict = extract_data(_configs)\n",
    "pp.pprint(epoch_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c718d90e-02a9-461f-b55a-c9c617836185",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{ 'ETTh1': { 'DLinear': { 'm': { 'avg_epoch_duration': np.float64(1082.47),\n",
      "                                 'avg_num_epochs': np.float64(11.0),\n",
      "                                 'avg_num_parameters': np.float64(188061120.0),\n",
      "                                 'std_epoch_duration': np.float64(0.0),\n",
      "                                 'std_num_epochs': np.float64(0.0),\n",
      "                                 'std_num_parameters': np.float64(0.0)}},\n",
      "             'DeepAR': { 'u': { 'avg_epoch_duration': np.float64(195.07327922077923),\n",
      "                                'avg_num_epochs': np.float64(12.5),\n",
      "                                'avg_num_parameters': np.float64(81307.0),\n",
      "                                'std_epoch_duration': np.float64(14.053993506493512),\n",
      "                                'std_num_epochs': np.float64(1.5),\n",
      "                                'std_num_parameters': np.float64(0.0)}}}}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def compute_stats_across_seeds(epoch_dict):\n",
    "    stats_dict = {}\n",
    "\n",
    "    for dataset, models in epoch_dict.items():\n",
    "        stats_dict[dataset] = {}\n",
    "        for model, dists in models.items():\n",
    "            stats_dict[dataset][model] = {}\n",
    "            for dist, seeds in dists.items():\n",
    "                num_epochs_list = []\n",
    "                avg_duration_per_seed = []\n",
    "                num_parameters_list = []\n",
    "\n",
    "                for seed, data in seeds.items():\n",
    "                    num_epochs_list.append(data['num_epochs'])\n",
    "                    # Average epoch duration within this seed\n",
    "                    avg_duration = np.mean(data['epoch_durations'])\n",
    "                    avg_duration_per_seed.append(avg_duration)\n",
    "                    num_parameters_list.append(data['num_parameters'])\n",
    "\n",
    "                avg_epochs = np.mean(num_epochs_list)\n",
    "                std_epochs = np.std(num_epochs_list)\n",
    "\n",
    "                avg_durations = np.mean(avg_duration_per_seed)\n",
    "                std_durations = np.std(avg_duration_per_seed)\n",
    "\n",
    "                avg_params = np.mean(num_parameters_list)\n",
    "                std_params = np.std(num_parameters_list)\n",
    "\n",
    "                stats_dict[dataset][model][dist] = {\n",
    "                    'avg_num_epochs': avg_epochs,\n",
    "                    'std_num_epochs': std_epochs,\n",
    "                    'avg_epoch_duration': avg_durations,\n",
    "                    'std_epoch_duration': std_durations,\n",
    "                    'avg_num_parameters': avg_params,\n",
    "                    'std_num_parameters': std_params,\n",
    "                }\n",
    "\n",
    "    return stats_dict\n",
    "\n",
    "stats = compute_stats_across_seeds(epoch_dict)\n",
    "pp.pprint(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d373c18-f1b6-4c00-925e-13386bb8a888",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (jupyter venv)",
   "language": "python",
   "name": "jupyter_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
