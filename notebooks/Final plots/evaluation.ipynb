{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df69e24e-2162-4989-9bf0-b68682d6b1a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-25 15:34:12,887 - easytorch-env - INFO - Use devices 0.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir('/home/kreffert/Probabilistic_LTSF/BasicTS/')\n",
    "from basicts.metrics import masked_mae, masked_mse, nll_loss, crps, Evaluator, quantile_loss, empirical_crps\n",
    "from easytorch.device import set_device_type\n",
    "from easytorch.utils import get_logger, set_visible_devices\n",
    "# set the device type (CPU, GPU, or MLU)\n",
    "device_type ='gpu'\n",
    "gpus = '0'\n",
    "set_device_type(device_type)\n",
    "set_visible_devices(gpus)\n",
    "from easydict import EasyDict\n",
    "from tqdm import tqdm\n",
    "\n",
    "# extract the paths to the configs and weights\n",
    "import yaml\n",
    "# /home/kreffert/Probabilistic_LTSF/notebooks/Final plots/weights.yaml\n",
    "with open('/home/kreffert/Probabilistic_LTSF/notebooks/Final plots/weights.yaml', 'r') as file:\n",
    "    _configs = yaml.safe_load(file)\n",
    "def reconstruct_paths(simplified_dict):\n",
    "    base_path = \"final_weights/\"#\"/home/kreffert/Probabilistic_LTSF/BasicTS/final_weights/\"\n",
    "    dist_mapping = {\"iq\":\"i_quantile\", \"u\": \"univariate\", \"m\":\"multivariate\", \"q\":\"quantile\"}\n",
    "    full_dict = simplified_dict.copy()\n",
    "\n",
    "    for dataset in simplified_dict.keys():\n",
    "        for model in simplified_dict[dataset].keys():\n",
    "            for dist in simplified_dict[dataset][model].keys():\n",
    "                for random_state in simplified_dict[dataset][model][dist].keys():\n",
    "                    _cfg = \"ETTh1_prob_quantile.py\" if dist in [\"q\", \"iq\"] else \"ETTh1_prob.py\"\n",
    "                    _ckpt = \"_best_val_QL.pt\" if dist in [\"q\", \"iq\"] else \"_best_val_NLL.pt\"\n",
    "                    prefix = base_path + f\"{dataset}/{model}/{dist_mapping[dist]}/{random_state}/{full_dict[dataset][model][dist][random_state]['cfg']}\"\n",
    "                    full_dict[dataset][model][dist][random_state]['cfg'] = f\"{prefix}/{_cfg}\"\n",
    "                    full_dict[dataset][model][dist][random_state]['ckpt'] = f\"{prefix}/{model}{_ckpt}\"\n",
    "    return full_dict\n",
    "_configs = reconstruct_paths(_configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50c149e3-2506-4e3c-a8a3-e99a0f44c3b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-25 15:34:12,913 - easytorch-env - INFO - Disable TF32 mode\n",
      "2025-06-25 15:34:12,916 - easytorch-env - INFO - Use deterministic algorithms.\n",
      "2025-06-25 15:34:12,916 - easytorch-env - INFO - Set cudnn deterministic.\n",
      "2025-06-25 15:34:12,917 - easytorch - INFO - Set ckpt save dir: '/home/kreffert/Probabilistic_LTSF/BasicTS/final_weights/ETTh1/DLinear/i_quantile/0/fec29c378c74498fa6c8bc49a55d802b'\n",
      "2025-06-25 15:34:12,917 - easytorch - INFO - Building model.\n",
      "2025-06-25 15:34:13,280 - easytorch - INFO - Load model from : final_weights/ETTh1/DLinear/i_quantile/0/fec29c378c74498fa6c8bc49a55d802b/DLinear_best_val_QL.pt\n",
      "2025-06-25 15:34:13,281 - easytorch - INFO - Loading Checkpoint from 'final_weights/ETTh1/DLinear/i_quantile/0/fec29c378c74498fa6c8bc49a55d802b/DLinear_best_val_QL.pt'\n",
      "2025-06-25 15:34:13,351 - easytorch-env - INFO - Disable TF32 mode\n",
      "2025-06-25 15:34:13,352 - easytorch-env - INFO - Use deterministic algorithms.\n",
      "2025-06-25 15:34:13,352 - easytorch-env - INFO - Set cudnn deterministic.\n",
      "2025-06-25 15:34:13,353 - easytorch - INFO - Set ckpt save dir: '/home/kreffert/Probabilistic_LTSF/BasicTS/final_weights/ETTh1/DLinear/i_quantile/1/628defbdfb1803a958c25f29e39544e7'\n",
      "2025-06-25 15:34:13,353 - easytorch - INFO - Building model.\n",
      "2025-06-25 15:34:13,388 - easytorch - INFO - Load model from : final_weights/ETTh1/DLinear/i_quantile/1/628defbdfb1803a958c25f29e39544e7/DLinear_best_val_QL.pt\n",
      "2025-06-25 15:34:13,389 - easytorch - INFO - Loading Checkpoint from 'final_weights/ETTh1/DLinear/i_quantile/1/628defbdfb1803a958c25f29e39544e7/DLinear_best_val_QL.pt'\n",
      "2025-06-25 15:34:13,453 - easytorch-env - INFO - Disable TF32 mode\n",
      "2025-06-25 15:34:13,454 - easytorch-env - INFO - Use deterministic algorithms.\n",
      "2025-06-25 15:34:13,454 - easytorch-env - INFO - Set cudnn deterministic.\n",
      "2025-06-25 15:34:13,454 - easytorch - INFO - Set ckpt save dir: '/home/kreffert/Probabilistic_LTSF/BasicTS/final_weights/ETTh1/DLinear/i_quantile/2/7e59031295d7db4c807d3b5f9db7bc80'\n",
      "2025-06-25 15:34:13,455 - easytorch - INFO - Building model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DLinear\n",
      "Loading model checkpoint from final_weights/ETTh1/DLinear/i_quantile/0/fec29c378c74498fa6c8bc49a55d802b/DLinear_best_val_QL.pt\n",
      "DLinear\n",
      "Loading model checkpoint from final_weights/ETTh1/DLinear/i_quantile/1/628defbdfb1803a958c25f29e39544e7/DLinear_best_val_QL.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-25 15:34:13,493 - easytorch - INFO - Load model from : final_weights/ETTh1/DLinear/i_quantile/2/7e59031295d7db4c807d3b5f9db7bc80/DLinear_best_val_QL.pt\n",
      "2025-06-25 15:34:13,494 - easytorch - INFO - Loading Checkpoint from 'final_weights/ETTh1/DLinear/i_quantile/2/7e59031295d7db4c807d3b5f9db7bc80/DLinear_best_val_QL.pt'\n",
      "2025-06-25 15:34:13,559 - easytorch-env - INFO - Disable TF32 mode\n",
      "2025-06-25 15:34:13,560 - easytorch-env - INFO - Use deterministic algorithms.\n",
      "2025-06-25 15:34:13,560 - easytorch-env - INFO - Set cudnn deterministic.\n",
      "2025-06-25 15:34:13,561 - easytorch - INFO - Set ckpt save dir: '/home/kreffert/Probabilistic_LTSF/BasicTS/final_weights/ETTh1/DLinear/i_quantile/3/8c629f97c3b989e7b22ab0f92d98b82e'\n",
      "2025-06-25 15:34:13,561 - easytorch - INFO - Building model.\n",
      "2025-06-25 15:34:13,599 - easytorch - INFO - Load model from : final_weights/ETTh1/DLinear/i_quantile/3/8c629f97c3b989e7b22ab0f92d98b82e/DLinear_best_val_QL.pt\n",
      "2025-06-25 15:34:13,600 - easytorch - INFO - Loading Checkpoint from 'final_weights/ETTh1/DLinear/i_quantile/3/8c629f97c3b989e7b22ab0f92d98b82e/DLinear_best_val_QL.pt'\n",
      "2025-06-25 15:34:13,665 - easytorch-env - INFO - Disable TF32 mode\n",
      "2025-06-25 15:34:13,666 - easytorch-env - INFO - Use deterministic algorithms.\n",
      "2025-06-25 15:34:13,666 - easytorch-env - INFO - Set cudnn deterministic.\n",
      "2025-06-25 15:34:13,666 - easytorch - INFO - Set ckpt save dir: '/home/kreffert/Probabilistic_LTSF/BasicTS/final_weights/ETTh1/DLinear/quantile/0/4ba2f4d6dfab4cb4ff2a459e0533ae43'\n",
      "2025-06-25 15:34:13,667 - easytorch - INFO - Building model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DLinear\n",
      "Loading model checkpoint from final_weights/ETTh1/DLinear/i_quantile/2/7e59031295d7db4c807d3b5f9db7bc80/DLinear_best_val_QL.pt\n",
      "DLinear\n",
      "Loading model checkpoint from final_weights/ETTh1/DLinear/i_quantile/3/8c629f97c3b989e7b22ab0f92d98b82e/DLinear_best_val_QL.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-25 15:34:13,870 - easytorch - INFO - Load model from : final_weights/ETTh1/DLinear/quantile/0/4ba2f4d6dfab4cb4ff2a459e0533ae43/DLinear_best_val_QL.pt\n",
      "2025-06-25 15:34:13,870 - easytorch - INFO - Loading Checkpoint from 'final_weights/ETTh1/DLinear/quantile/0/4ba2f4d6dfab4cb4ff2a459e0533ae43/DLinear_best_val_QL.pt'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DLinear\n",
      "Loading model checkpoint from final_weights/ETTh1/DLinear/quantile/0/4ba2f4d6dfab4cb4ff2a459e0533ae43/DLinear_best_val_QL.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-25 15:34:14,195 - easytorch-env - INFO - Disable TF32 mode\n",
      "2025-06-25 15:34:14,197 - easytorch-env - INFO - Use deterministic algorithms.\n",
      "2025-06-25 15:34:14,197 - easytorch-env - INFO - Set cudnn deterministic.\n",
      "2025-06-25 15:34:14,197 - easytorch - INFO - Set ckpt save dir: '/home/kreffert/Probabilistic_LTSF/BasicTS/final_weights/ETTh1/DLinear/quantile/1/383f9f7a076ff99a0db15308b7f4d421'\n",
      "2025-06-25 15:34:14,197 - easytorch - INFO - Building model.\n",
      "2025-06-25 15:34:14,404 - easytorch - INFO - Load model from : final_weights/ETTh1/DLinear/quantile/1/383f9f7a076ff99a0db15308b7f4d421/DLinear_best_val_QL.pt\n",
      "2025-06-25 15:34:14,405 - easytorch - INFO - Loading Checkpoint from 'final_weights/ETTh1/DLinear/quantile/1/383f9f7a076ff99a0db15308b7f4d421/DLinear_best_val_QL.pt'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DLinear\n",
      "Loading model checkpoint from final_weights/ETTh1/DLinear/quantile/1/383f9f7a076ff99a0db15308b7f4d421/DLinear_best_val_QL.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-25 15:34:14,697 - easytorch-env - INFO - Disable TF32 mode\n",
      "2025-06-25 15:34:14,698 - easytorch-env - INFO - Use deterministic algorithms.\n",
      "2025-06-25 15:34:14,698 - easytorch-env - INFO - Set cudnn deterministic.\n",
      "2025-06-25 15:34:14,699 - easytorch - INFO - Set ckpt save dir: '/home/kreffert/Probabilistic_LTSF/BasicTS/final_weights/ETTh1/DLinear/quantile/2/a7f10e8c211a68a5aeb51fbaec3c28a5'\n",
      "2025-06-25 15:34:14,699 - easytorch - INFO - Building model.\n",
      "2025-06-25 15:34:14,891 - easytorch - INFO - Load model from : final_weights/ETTh1/DLinear/quantile/2/a7f10e8c211a68a5aeb51fbaec3c28a5/DLinear_best_val_QL.pt\n",
      "2025-06-25 15:34:14,891 - easytorch - INFO - Loading Checkpoint from 'final_weights/ETTh1/DLinear/quantile/2/a7f10e8c211a68a5aeb51fbaec3c28a5/DLinear_best_val_QL.pt'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DLinear\n",
      "Loading model checkpoint from final_weights/ETTh1/DLinear/quantile/2/a7f10e8c211a68a5aeb51fbaec3c28a5/DLinear_best_val_QL.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-25 15:34:15,106 - easytorch-env - INFO - Disable TF32 mode\n",
      "2025-06-25 15:34:15,107 - easytorch-env - INFO - Use deterministic algorithms.\n",
      "2025-06-25 15:34:15,108 - easytorch-env - INFO - Set cudnn deterministic.\n",
      "2025-06-25 15:34:15,108 - easytorch - INFO - Set ckpt save dir: '/home/kreffert/Probabilistic_LTSF/BasicTS/final_weights/ETTh1/DLinear/multivariate/0/fc30f42e732d03f01b66fe4c61a9a5f2'\n",
      "2025-06-25 15:34:15,108 - easytorch - INFO - Building model.\n",
      "2025-06-25 15:34:15,885 - easytorch - INFO - Load model from : final_weights/ETTh1/DLinear/multivariate/0/fc30f42e732d03f01b66fe4c61a9a5f2/DLinear_best_val_NLL.pt\n",
      "2025-06-25 15:34:15,886 - easytorch - INFO - Loading Checkpoint from 'final_weights/ETTh1/DLinear/multivariate/0/fc30f42e732d03f01b66fe4c61a9a5f2/DLinear_best_val_NLL.pt'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DLinear\n",
      "Loading model checkpoint from final_weights/ETTh1/DLinear/multivariate/0/fc30f42e732d03f01b66fe4c61a9a5f2/DLinear_best_val_NLL.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-25 15:34:16,305 - easytorch-env - INFO - Disable TF32 mode\n",
      "2025-06-25 15:34:16,307 - easytorch-env - INFO - Use deterministic algorithms.\n",
      "2025-06-25 15:34:16,307 - easytorch-env - INFO - Set cudnn deterministic.\n",
      "2025-06-25 15:34:16,308 - easytorch - INFO - Set ckpt save dir: '/home/kreffert/Probabilistic_LTSF/BasicTS/final_weights/ETTh1/DLinear/multivariate/1/aa5d43538e1d49f3c5367e942fdf55cb'\n",
      "2025-06-25 15:34:16,308 - easytorch - INFO - Building model.\n",
      "2025-06-25 15:34:17,080 - easytorch - INFO - Load model from : final_weights/ETTh1/DLinear/multivariate/1/aa5d43538e1d49f3c5367e942fdf55cb/DLinear_best_val_NLL.pt\n",
      "2025-06-25 15:34:17,081 - easytorch - INFO - Loading Checkpoint from 'final_weights/ETTh1/DLinear/multivariate/1/aa5d43538e1d49f3c5367e942fdf55cb/DLinear_best_val_NLL.pt'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DLinear\n",
      "Loading model checkpoint from final_weights/ETTh1/DLinear/multivariate/1/aa5d43538e1d49f3c5367e942fdf55cb/DLinear_best_val_NLL.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-25 15:34:17,496 - easytorch-env - INFO - Disable TF32 mode\n",
      "2025-06-25 15:34:17,497 - easytorch-env - INFO - Use deterministic algorithms.\n",
      "2025-06-25 15:34:17,497 - easytorch-env - INFO - Set cudnn deterministic.\n",
      "2025-06-25 15:34:17,497 - easytorch - INFO - Set ckpt save dir: '/home/kreffert/Probabilistic_LTSF/BasicTS/final_weights/ETTh1/DLinear/multivariate/2/ab8ce283463444e38a4ab2c8b7fd3d83'\n",
      "2025-06-25 15:34:17,498 - easytorch - INFO - Building model.\n",
      "2025-06-25 15:34:18,275 - easytorch - INFO - Load model from : final_weights/ETTh1/DLinear/multivariate/2/ab8ce283463444e38a4ab2c8b7fd3d83/DLinear_best_val_NLL.pt\n",
      "2025-06-25 15:34:18,276 - easytorch - INFO - Loading Checkpoint from 'final_weights/ETTh1/DLinear/multivariate/2/ab8ce283463444e38a4ab2c8b7fd3d83/DLinear_best_val_NLL.pt'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DLinear\n",
      "Loading model checkpoint from final_weights/ETTh1/DLinear/multivariate/2/ab8ce283463444e38a4ab2c8b7fd3d83/DLinear_best_val_NLL.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-25 15:34:18,691 - easytorch-env - INFO - Disable TF32 mode\n",
      "2025-06-25 15:34:18,693 - easytorch-env - INFO - Use deterministic algorithms.\n",
      "2025-06-25 15:34:18,693 - easytorch-env - INFO - Set cudnn deterministic.\n",
      "2025-06-25 15:34:18,693 - easytorch - INFO - Set ckpt save dir: '/home/kreffert/Probabilistic_LTSF/BasicTS/final_weights/ETTh1/DLinear/multivariate/3/d941953ac4d381ac9deb101ed5326365'\n",
      "2025-06-25 15:34:18,694 - easytorch - INFO - Building model.\n",
      "2025-06-25 15:34:19,471 - easytorch - INFO - Load model from : final_weights/ETTh1/DLinear/multivariate/3/d941953ac4d381ac9deb101ed5326365/DLinear_best_val_NLL.pt\n",
      "2025-06-25 15:34:19,471 - easytorch - INFO - Loading Checkpoint from 'final_weights/ETTh1/DLinear/multivariate/3/d941953ac4d381ac9deb101ed5326365/DLinear_best_val_NLL.pt'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DLinear\n",
      "Loading model checkpoint from final_weights/ETTh1/DLinear/multivariate/3/d941953ac4d381ac9deb101ed5326365/DLinear_best_val_NLL.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-25 15:34:19,889 - easytorch-env - INFO - Disable TF32 mode\n",
      "2025-06-25 15:34:19,890 - easytorch-env - INFO - Use deterministic algorithms.\n",
      "2025-06-25 15:34:19,890 - easytorch-env - INFO - Set cudnn deterministic.\n",
      "2025-06-25 15:34:19,890 - easytorch - INFO - Set ckpt save dir: '/home/kreffert/Probabilistic_LTSF/BasicTS/final_weights/ETTh1/DLinear/univariate/0/22c6c387919d63a0b8c3899c830017fe'\n",
      "2025-06-25 15:34:19,891 - easytorch - INFO - Building model.\n",
      "2025-06-25 15:34:19,967 - easytorch - INFO - Load model from : final_weights/ETTh1/DLinear/univariate/0/22c6c387919d63a0b8c3899c830017fe/DLinear_best_val_NLL.pt\n",
      "2025-06-25 15:34:19,967 - easytorch - INFO - Loading Checkpoint from 'final_weights/ETTh1/DLinear/univariate/0/22c6c387919d63a0b8c3899c830017fe/DLinear_best_val_NLL.pt'\n",
      "2025-06-25 15:34:20,040 - easytorch-env - INFO - Disable TF32 mode\n",
      "2025-06-25 15:34:20,041 - easytorch-env - INFO - Use deterministic algorithms.\n",
      "2025-06-25 15:34:20,041 - easytorch-env - INFO - Set cudnn deterministic.\n",
      "2025-06-25 15:34:20,041 - easytorch - INFO - Set ckpt save dir: '/home/kreffert/Probabilistic_LTSF/BasicTS/final_weights/ETTh1/DLinear/univariate/1/f421fbe2c1f3d42f571a5c406f556fe9'\n",
      "2025-06-25 15:34:20,041 - easytorch - INFO - Building model.\n",
      "2025-06-25 15:34:20,112 - easytorch - INFO - Load model from : final_weights/ETTh1/DLinear/univariate/1/f421fbe2c1f3d42f571a5c406f556fe9/DLinear_best_val_NLL.pt\n",
      "2025-06-25 15:34:20,113 - easytorch - INFO - Loading Checkpoint from 'final_weights/ETTh1/DLinear/univariate/1/f421fbe2c1f3d42f571a5c406f556fe9/DLinear_best_val_NLL.pt'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DLinear\n",
      "Loading model checkpoint from final_weights/ETTh1/DLinear/univariate/0/22c6c387919d63a0b8c3899c830017fe/DLinear_best_val_NLL.pt\n",
      "DLinear\n",
      "Loading model checkpoint from final_weights/ETTh1/DLinear/univariate/1/f421fbe2c1f3d42f571a5c406f556fe9/DLinear_best_val_NLL.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-25 15:34:20,184 - easytorch-env - INFO - Disable TF32 mode\n",
      "2025-06-25 15:34:20,185 - easytorch-env - INFO - Use deterministic algorithms.\n",
      "2025-06-25 15:34:20,186 - easytorch-env - INFO - Set cudnn deterministic.\n",
      "2025-06-25 15:34:20,186 - easytorch - INFO - Set ckpt save dir: '/home/kreffert/Probabilistic_LTSF/BasicTS/final_weights/ETTh1/DLinear/univariate/2/def66a26229b68fb2126cf8554566a28'\n",
      "2025-06-25 15:34:20,186 - easytorch - INFO - Building model.\n",
      "2025-06-25 15:34:20,257 - easytorch - INFO - Load model from : final_weights/ETTh1/DLinear/univariate/2/def66a26229b68fb2126cf8554566a28/DLinear_best_val_NLL.pt\n",
      "2025-06-25 15:34:20,257 - easytorch - INFO - Loading Checkpoint from 'final_weights/ETTh1/DLinear/univariate/2/def66a26229b68fb2126cf8554566a28/DLinear_best_val_NLL.pt'\n",
      "2025-06-25 15:34:20,328 - easytorch-env - INFO - Disable TF32 mode\n",
      "2025-06-25 15:34:20,329 - easytorch-env - INFO - Use deterministic algorithms.\n",
      "2025-06-25 15:34:20,330 - easytorch-env - INFO - Set cudnn deterministic.\n",
      "2025-06-25 15:34:20,330 - easytorch - INFO - Set ckpt save dir: '/home/kreffert/Probabilistic_LTSF/BasicTS/final_weights/ETTh1/DLinear/univariate/3/ba8ca6485a10429b9607d1de240a9ef3'\n",
      "2025-06-25 15:34:20,330 - easytorch - INFO - Building model.\n",
      "2025-06-25 15:34:20,401 - easytorch - INFO - Load model from : final_weights/ETTh1/DLinear/univariate/3/ba8ca6485a10429b9607d1de240a9ef3/DLinear_best_val_NLL.pt\n",
      "2025-06-25 15:34:20,402 - easytorch - INFO - Loading Checkpoint from 'final_weights/ETTh1/DLinear/univariate/3/ba8ca6485a10429b9607d1de240a9ef3/DLinear_best_val_NLL.pt'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DLinear\n",
      "Loading model checkpoint from final_weights/ETTh1/DLinear/univariate/2/def66a26229b68fb2126cf8554566a28/DLinear_best_val_NLL.pt\n",
      "DLinear\n",
      "Loading model checkpoint from final_weights/ETTh1/DLinear/univariate/3/ba8ca6485a10429b9607d1de240a9ef3/DLinear_best_val_NLL.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-25 15:34:20,488 - easytorch-env - INFO - Disable TF32 mode\n",
      "2025-06-25 15:34:20,489 - easytorch-env - INFO - Use deterministic algorithms.\n",
      "2025-06-25 15:34:20,489 - easytorch-env - INFO - Set cudnn deterministic.\n",
      "2025-06-25 15:34:20,489 - easytorch - INFO - Set ckpt save dir: '/home/kreffert/Probabilistic_LTSF/BasicTS/final_weights/DeepAR/i_quantile/0/43dbede9727b8ef4497560ede2c37f67'\n",
      "2025-06-25 15:34:20,490 - easytorch - INFO - Building model.\n",
      "2025-06-25 15:34:20,507 - easytorch - INFO - Load model from : final_weights/ETTh1/DeepAR/i_quantile/0/43dbede9727b8ef4497560ede2c37f67/DeepAR_best_val_QL.pt\n",
      "2025-06-25 15:34:20,507 - easytorch - INFO - Loading Checkpoint from 'final_weights/ETTh1/DeepAR/i_quantile/0/43dbede9727b8ef4497560ede2c37f67/DeepAR_best_val_QL.pt'\n",
      "2025-06-25 15:34:20,542 - easytorch-env - INFO - Disable TF32 mode\n",
      "2025-06-25 15:34:20,543 - easytorch-env - INFO - Use deterministic algorithms.\n",
      "2025-06-25 15:34:20,543 - easytorch-env - INFO - Set cudnn deterministic.\n",
      "2025-06-25 15:34:20,544 - easytorch - INFO - Set ckpt save dir: '/home/kreffert/Probabilistic_LTSF/BasicTS/final_weights/DeepAR/i_quantile/1/9e89f68060978f59d3019ca8d8dd7b66'\n",
      "2025-06-25 15:34:20,544 - easytorch - INFO - Building model.\n",
      "2025-06-25 15:34:20,550 - easytorch - INFO - Load model from : final_weights/ETTh1/DeepAR/i_quantile/1/9e89f68060978f59d3019ca8d8dd7b66/DeepAR_best_val_QL.pt\n",
      "2025-06-25 15:34:20,550 - easytorch - INFO - Loading Checkpoint from 'final_weights/ETTh1/DeepAR/i_quantile/1/9e89f68060978f59d3019ca8d8dd7b66/DeepAR_best_val_QL.pt'\n",
      "2025-06-25 15:34:20,581 - easytorch-env - INFO - Disable TF32 mode\n",
      "2025-06-25 15:34:20,582 - easytorch-env - INFO - Use deterministic algorithms.\n",
      "2025-06-25 15:34:20,583 - easytorch-env - INFO - Set cudnn deterministic.\n",
      "2025-06-25 15:34:20,583 - easytorch - INFO - Set ckpt save dir: '/home/kreffert/Probabilistic_LTSF/BasicTS/final_weights/ETTh1/DeepAR/i_quantile/3/1eb3f4e4d74a8b8a15bc2c9c62996a4c'\n",
      "2025-06-25 15:34:20,583 - easytorch - INFO - Building model.\n",
      "2025-06-25 15:34:20,589 - easytorch - INFO - Load model from : final_weights/ETTh1/DeepAR/i_quantile/3/1eb3f4e4d74a8b8a15bc2c9c62996a4c/DeepAR_best_val_QL.pt\n",
      "2025-06-25 15:34:20,589 - easytorch - INFO - Loading Checkpoint from 'final_weights/ETTh1/DeepAR/i_quantile/3/1eb3f4e4d74a8b8a15bc2c9c62996a4c/DeepAR_best_val_QL.pt'\n",
      "2025-06-25 15:34:20,612 - easytorch-env - INFO - Disable TF32 mode\n",
      "2025-06-25 15:34:20,612 - easytorch-env - INFO - Use deterministic algorithms.\n",
      "2025-06-25 15:34:20,613 - easytorch-env - INFO - Set cudnn deterministic.\n",
      "2025-06-25 15:34:20,613 - easytorch - INFO - Set ckpt save dir: '/home/kreffert/Probabilistic_LTSF/BasicTS/final_weights/DeepAR/quantile/0/6d95e6dc9ddb61bf198592c2998a9f2a'\n",
      "2025-06-25 15:34:20,613 - easytorch - INFO - Building model.\n",
      "2025-06-25 15:34:20,626 - easytorch - INFO - Load model from : final_weights/ETTh1/DeepAR/quantile/0/d1d21565d8c0ed4dca6f9f391735e4f7/DeepAR_best_val_QL.pt\n",
      "2025-06-25 15:34:20,626 - easytorch - INFO - Loading Checkpoint from 'final_weights/ETTh1/DeepAR/quantile/0/d1d21565d8c0ed4dca6f9f391735e4f7/DeepAR_best_val_QL.pt'\n",
      "2025-06-25 15:34:20,664 - easytorch-env - INFO - Disable TF32 mode\n",
      "2025-06-25 15:34:20,665 - easytorch-env - INFO - Use deterministic algorithms.\n",
      "2025-06-25 15:34:20,665 - easytorch-env - INFO - Set cudnn deterministic.\n",
      "2025-06-25 15:34:20,666 - easytorch - INFO - Set ckpt save dir: '/home/kreffert/Probabilistic_LTSF/BasicTS/final_weights/ETTh1/DeepAR/quantile/1/bc40ec9edcf8b1bcd8f0a3725175b84f'\n",
      "2025-06-25 15:34:20,666 - easytorch - INFO - Building model.\n",
      "2025-06-25 15:34:20,673 - easytorch - INFO - Load model from : final_weights/ETTh1/DeepAR/quantile/1/bc40ec9edcf8b1bcd8f0a3725175b84f/DeepAR_best_val_QL.pt\n",
      "2025-06-25 15:34:20,674 - easytorch - INFO - Loading Checkpoint from 'final_weights/ETTh1/DeepAR/quantile/1/bc40ec9edcf8b1bcd8f0a3725175b84f/DeepAR_best_val_QL.pt'\n",
      "2025-06-25 15:34:20,704 - easytorch-env - INFO - Disable TF32 mode\n",
      "2025-06-25 15:34:20,705 - easytorch-env - INFO - Use deterministic algorithms.\n",
      "2025-06-25 15:34:20,705 - easytorch-env - INFO - Set cudnn deterministic.\n",
      "2025-06-25 15:34:20,705 - easytorch - INFO - Set ckpt save dir: '/home/kreffert/Probabilistic_LTSF/BasicTS/final_weights/ETTh1/DeepAR/quantile/2/2ad27c696897fc216064f719a8bea178'\n",
      "2025-06-25 15:34:20,705 - easytorch - INFO - Building model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DeepAR\n",
      "Loading model checkpoint from final_weights/ETTh1/DeepAR/i_quantile/0/43dbede9727b8ef4497560ede2c37f67/DeepAR_best_val_QL.pt\n",
      "DeepAR\n",
      "Loading model checkpoint from final_weights/ETTh1/DeepAR/i_quantile/1/9e89f68060978f59d3019ca8d8dd7b66/DeepAR_best_val_QL.pt\n",
      "DeepAR\n",
      "Loading model checkpoint from final_weights/ETTh1/DeepAR/i_quantile/3/1eb3f4e4d74a8b8a15bc2c9c62996a4c/DeepAR_best_val_QL.pt\n",
      "DeepAR\n",
      "Loading model checkpoint from final_weights/ETTh1/DeepAR/quantile/0/d1d21565d8c0ed4dca6f9f391735e4f7/DeepAR_best_val_QL.pt\n",
      "DeepAR\n",
      "Loading model checkpoint from final_weights/ETTh1/DeepAR/quantile/1/bc40ec9edcf8b1bcd8f0a3725175b84f/DeepAR_best_val_QL.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-25 15:34:20,713 - easytorch - INFO - Load model from : final_weights/ETTh1/DeepAR/quantile/2/2ad27c696897fc216064f719a8bea178/DeepAR_best_val_QL.pt\n",
      "2025-06-25 15:34:20,713 - easytorch - INFO - Loading Checkpoint from 'final_weights/ETTh1/DeepAR/quantile/2/2ad27c696897fc216064f719a8bea178/DeepAR_best_val_QL.pt'\n",
      "2025-06-25 15:34:20,737 - easytorch-env - INFO - Disable TF32 mode\n",
      "2025-06-25 15:34:20,738 - easytorch-env - INFO - Use deterministic algorithms.\n",
      "2025-06-25 15:34:20,738 - easytorch-env - INFO - Set cudnn deterministic.\n",
      "2025-06-25 15:34:20,738 - easytorch - INFO - Set ckpt save dir: '/home/kreffert/Probabilistic_LTSF/BasicTS/final_weights/DeepAR/univariate/0/f7d0a9c9a4f592c7d2597ea802b6e624'\n",
      "2025-06-25 15:34:20,739 - easytorch - INFO - Building model.\n",
      "2025-06-25 15:34:20,744 - easytorch - INFO - Load model from : final_weights/ETTh1/DeepAR/univariate/0/f7d0a9c9a4f592c7d2597ea802b6e624/DeepAR_best_val_NLL.pt\n",
      "2025-06-25 15:34:20,744 - easytorch - INFO - Loading Checkpoint from 'final_weights/ETTh1/DeepAR/univariate/0/f7d0a9c9a4f592c7d2597ea802b6e624/DeepAR_best_val_NLL.pt'\n",
      "2025-06-25 15:34:20,772 - easytorch-env - INFO - Disable TF32 mode\n",
      "2025-06-25 15:34:20,773 - easytorch-env - INFO - Use deterministic algorithms.\n",
      "2025-06-25 15:34:20,773 - easytorch-env - INFO - Set cudnn deterministic.\n",
      "2025-06-25 15:34:20,773 - easytorch - INFO - Set ckpt save dir: '/home/kreffert/Probabilistic_LTSF/BasicTS/final_weights/DeepAR/univariate/2/7b44d8385fad4872031c2a5b06b144c0'\n",
      "2025-06-25 15:34:20,773 - easytorch - INFO - Building model.\n",
      "2025-06-25 15:34:20,778 - easytorch - INFO - Load model from : final_weights/ETTh1/DeepAR/univariate/2/7b44d8385fad4872031c2a5b06b144c0/DeepAR_best_val_NLL.pt\n",
      "2025-06-25 15:34:20,779 - easytorch - INFO - Loading Checkpoint from 'final_weights/ETTh1/DeepAR/univariate/2/7b44d8385fad4872031c2a5b06b144c0/DeepAR_best_val_NLL.pt'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DeepAR\n",
      "Loading model checkpoint from final_weights/ETTh1/DeepAR/quantile/2/2ad27c696897fc216064f719a8bea178/DeepAR_best_val_QL.pt\n",
      "DeepAR\n",
      "Loading model checkpoint from final_weights/ETTh1/DeepAR/univariate/0/f7d0a9c9a4f592c7d2597ea802b6e624/DeepAR_best_val_NLL.pt\n",
      "DeepAR\n",
      "Loading model checkpoint from final_weights/ETTh1/DeepAR/univariate/2/7b44d8385fad4872031c2a5b06b144c0/DeepAR_best_val_NLL.pt\n"
     ]
    }
   ],
   "source": [
    "def load_cfg(cfg, random_state=None):\n",
    "    from easytorch.config import init_cfg\n",
    "    # cfg path which start with dot will crash the easytorch, just remove dot\n",
    "    while isinstance(cfg, str) and cfg.startswith(('./','.\\\\')):\n",
    "        cfg = cfg[2:]\n",
    "    # while ckpt_path.startswith(('./','.\\\\')):\n",
    "    #     ckpt_path = ckpt_path[2:]\n",
    "    \n",
    "    # initialize the configuration\n",
    "    cfg = init_cfg(cfg, save=False)\n",
    "    return cfg\n",
    "\n",
    "def load_runner(configs, datasets=None, models=None):\n",
    "    for dataset in configs.keys():\n",
    "        for model in configs[dataset].keys():\n",
    "            for dist in configs[dataset][model].keys():\n",
    "                for random_state in configs[dataset][model][dist].keys():\n",
    "                    configs[dataset][model][dist][random_state]['cfg'] = load_cfg(configs[dataset][model][dist][random_state]['cfg'])\n",
    "                    cfg = configs[dataset][model][dist][random_state]['cfg']\n",
    "                    ckpt = configs[dataset][model][dist][random_state]['ckpt']\n",
    "                    strict=True\n",
    "                    runner = cfg['RUNNER'](cfg)\n",
    "                    # setup the graph if needed\n",
    "                    if runner.need_setup_graph:\n",
    "                        runner.setup_graph(cfg=cfg, train=False)\n",
    "                        \n",
    "                    print(f'Loading model checkpoint from {ckpt}')\n",
    "                    runner.load_model(ckpt_path=ckpt, strict=strict)\n",
    "                    \n",
    "                    # runner.test_pipeline(cfg=cfg, save_metrics=False, save_results=False)\n",
    "                    configs[dataset][model][dist][random_state]['runner'] = runner\n",
    "    return configs\n",
    "\n",
    "_configs = load_runner(_configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "82c7f1fc-3a76-4d42-a046-0b58eb30f91b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-25 15:35:02,599 - easytorch - INFO - Test dataset length: 2065\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 33/33 [00:01<00:00, 25.04it/s]\n",
      "2025-06-25 15:35:03,920 - easytorch - INFO - Test dataset length: 2065\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 33/33 [00:01<00:00, 25.19it/s]\n",
      "2025-06-25 15:35:05,233 - easytorch - INFO - Test dataset length: 2065\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 33/33 [00:01<00:00, 25.21it/s]\n",
      "2025-06-25 15:35:06,546 - easytorch - INFO - Test dataset length: 2065\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 33/33 [00:01<00:00, 25.35it/s]\n",
      "2025-06-25 15:35:07,850 - easytorch - INFO - Test dataset length: 2065\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 33/33 [00:00<00:00, 64.93it/s]\n",
      "2025-06-25 15:35:08,361 - easytorch - INFO - Test dataset length: 2065\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 33/33 [00:00<00:00, 64.14it/s]\n",
      "2025-06-25 15:35:08,879 - easytorch - INFO - Test dataset length: 2065\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 33/33 [00:00<00:00, 64.84it/s]\n",
      "2025-06-25 15:35:09,391 - easytorch - INFO - Test dataset length: 2065\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 33/33 [00:00<00:00, 57.75it/s]\n",
      "2025-06-25 15:35:09,966 - easytorch - INFO - Test dataset length: 2065\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 33/33 [00:00<00:00, 53.49it/s]\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 14.04 GiB. GPU 0 has a total capacity of 47.41 GiB of which 11.72 GiB is free. Including non-PyTorch memory, this process has 35.68 GiB memory in use. Of the allocated memory 34.81 GiB is allocated by PyTorch, and 553.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOutOfMemoryError\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 36\u001b[39m\n\u001b[32m     33\u001b[39m                     configs[dataset][model][dist][random_state][\u001b[33m'\u001b[39m\u001b[33mreturns_all\u001b[39m\u001b[33m'\u001b[39m] = returns_all\n\u001b[32m     34\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m configs\n\u001b[32m---> \u001b[39m\u001b[32m36\u001b[39m _configs = \u001b[43mget_predictions\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_configs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/BasicTS/lib/python3.11/site-packages/torch/utils/_contextlib.py:116\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    113\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    114\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    115\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 28\u001b[39m, in \u001b[36mget_predictions\u001b[39m\u001b[34m(configs)\u001b[39m\n\u001b[32m     25\u001b[39m     target.append(forward_return[\u001b[33m'\u001b[39m\u001b[33mtarget\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m     26\u001b[39m     inputs.append(forward_return[\u001b[33m'\u001b[39m\u001b[33minputs\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m prediction = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     29\u001b[39m target = torch.cat(target, dim=\u001b[32m0\u001b[39m)\n\u001b[32m     30\u001b[39m inputs = torch.cat(inputs, dim=\u001b[32m0\u001b[39m)\n",
      "\u001b[31mOutOfMemoryError\u001b[39m: CUDA out of memory. Tried to allocate 14.04 GiB. GPU 0 has a total capacity of 47.41 GiB of which 11.72 GiB is free. Including non-PyTorch memory, this process has 35.68 GiB memory in use. Of the allocated memory 34.81 GiB is allocated by PyTorch, and 553.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "@torch.no_grad()\n",
    "def get_predictions(configs):\n",
    "    for dataset in configs.keys():\n",
    "        for model in configs[dataset].keys():\n",
    "            for dist in configs[dataset][model].keys():\n",
    "                for random_state in configs[dataset][model][dist].keys():\n",
    "                    runner = configs[dataset][model][dist][random_state]['runner']\n",
    "                    cfg = configs[dataset][model][dist][random_state]['cfg']\n",
    "                    # init test\n",
    "                    runner.test_interval = cfg['TEST'].get('INTERVAL', 1)\n",
    "                    runner.test_data_loader = runner.build_test_data_loader(cfg)\n",
    "                \n",
    "                    runner.model.eval()\n",
    "                    prediction, target, inputs = [], [], []\n",
    "                \n",
    "                    for data in tqdm(runner.test_data_loader):\n",
    "                        # if model DeepAR -> forward with postprocessing of quantile and 100 sample trajectories!\n",
    "                        \n",
    "                        forward_return = runner.forward(data, epoch=None, iter_num=None, train=False)\n",
    "                        if not runner.if_evaluate_on_gpu:\n",
    "                            forward_return['prediction'] = forward_return['prediction'].detach().cpu()\n",
    "                            forward_return['target'] = forward_return['target'].detach().cpu()\n",
    "                            forward_return['inputs'] = forward_return['inputs'].detach().cpu()\n",
    "                \n",
    "                        prediction.append(forward_return['prediction'])\n",
    "                        target.append(forward_return['target'])\n",
    "                        inputs.append(forward_return['inputs'])\n",
    "                \n",
    "                    prediction = torch.cat(prediction, dim=0)\n",
    "                    target = torch.cat(target, dim=0)\n",
    "                    inputs = torch.cat(inputs, dim=0)\n",
    "                \n",
    "                    returns_all = {'prediction': prediction, 'target': target, 'inputs': inputs}\n",
    "                    configs[dataset][model][dist][random_state]['returns_all'] = returns_all\n",
    "    return configs\n",
    "\n",
    "_configs = get_predictions(_configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892e5d76-dd7c-41e5-beb1-79f117e04dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. load the model and set the device\n",
    "_configs = {'ETTh1_PTST_u': {'cfg':'final_weights/PatchTST/univariate/ETTh1_prob.py',\n",
    "                           'ckpt': 'final_weights/PatchTST/univariate/ETTh1_100_96_720/a8de06edad7530010e0b704422b431a2/PatchTST_best_val_NLL.pt'\n",
    "                          },\n",
    "           # 'ETTh1_PTST_q': {'cfg': 'final_weights/PatchTST/quantile/ETTh1_prob.py',\n",
    "           #                  'ckpt': 'final_weights/PatchTST/quantile/ETTh1_100_96_720/a2a39ac1680165e5ffbda2c7bbda5add/PatchTST_best_val_QL.pt'\n",
    "           #                 }\n",
    "          }\n",
    "\n",
    "random_states = range(5)\n",
    "\n",
    "configs = {rs:_configs for rs in random_states}\n",
    "\n",
    "configs = load_runner(configs, random_states=random_states)\n",
    "configs = get_predictions(configs)\n",
    "# metrics_results = self.compute_evaluation_metrics(returns_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad2779b-e0b2-42e1-b694-91ae0decfeb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "def vs_ensemble_torch(obs, fct, p=1.0):\n",
    "    \"\"\"\n",
    "    Compute Variogram Score using PyTorch on GPU.\n",
    "    obs: shape (..., D)\n",
    "    fct: shape (..., M, D)\n",
    "    \"\"\"\n",
    "    M = fct.shape[-2]\n",
    "\n",
    "    # Compute ensemble variogram component\n",
    "    fct_diff = fct.unsqueeze(-2) - fct.unsqueeze(-1)  # (B, M, D, D)\n",
    "    # print(fct_diff.shape)\n",
    "    vfct = (fct_diff.abs() ** p).sum(dim=-3) / M  # (B, D, D)\n",
    "    # print(vfct.shape)\n",
    "    # Compute observed variogram component\n",
    "    obs_diff = obs.unsqueeze(-2) - obs.unsqueeze(-1)  # (B, D, D)\n",
    "    vobs = (obs_diff.abs() ** p)  # (B, D, D)\n",
    "    # print(vobs.shape)\n",
    "    # print(vfct.shape)\n",
    "    vs = ((vfct - vobs) ** 2).sum(dim=(-2, -1))  # (B,)\n",
    "    return vs\n",
    "\n",
    "def es_ensemble_torch(obs: torch.Tensor, fct: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Compute the energy score using PyTorch.\n",
    "    \n",
    "    Parameters:\n",
    "    - obs: Tensor of shape (B, D)\n",
    "    - fct: Tensor of shape (B, M, D)\n",
    "\n",
    "    Returns:\n",
    "    - Tensor of shape (B,) with energy scores\n",
    "    \"\"\"\n",
    "    M = fct.shape[-2]\n",
    "\n",
    "    # E_1: mean norm between forecast samples and the observation\n",
    "    err_norm = torch.norm(fct - obs.unsqueeze(-2), dim=-1)  # (B, M)\n",
    "    E_1 = err_norm.sum(dim=-1) / M  # (B,)\n",
    "\n",
    "    # E_2: mean pairwise distance between forecast samples\n",
    "    spread = fct.unsqueeze(-3) - fct.unsqueeze(-2)  # (B, M, M, D)\n",
    "    spread_norm = torch.norm(spread, dim=-1)  # (B, M, M)\n",
    "    E_2 = spread_norm.sum(dim=(-2, -1)) / (M**2) # (B,)\n",
    "\n",
    "    return E_1 - 0.5 * E_2  # (B,)\n",
    "\n",
    "def sample(runner, returns_all, random_state=None):\n",
    "    from prob.prob_head import ProbabilisticHead # load that class for sampling\n",
    "    head = ProbabilisticHead(1, 1, runner.distribution_type, prob_args=runner.prob_args)\n",
    "    samples = []\n",
    "    batch_size = 64\n",
    "    num_batches = int(returns_all['prediction'].shape[0]/batch_size)+1\n",
    "    for b in range(num_batches):\n",
    "        start, end = b*batch_size, min((b+1)*batch_size, returns_all['prediction'].shape[0])\n",
    "        pred = returns_all['prediction'][start:end, :, :, :]\n",
    "        sample = head.sample(pred, num_samples=100, random_state=random_state) # [samples x bs x seq_len x nvars]\n",
    "        sample = sample.permute(1, 0, 2, 3)       # [bs x samples x seq_len x nvars]\n",
    "        samples.append(sample)\n",
    "    samples = torch.cat(samples, dim=0)\n",
    "    return samples\n",
    "\n",
    "def evaluate(predictions, returns_all, batch_size=4):\n",
    "    import scoringrules as sr\n",
    "    import numpy as np\n",
    "    device = returns_all['target'].device\n",
    "    targets = returns_all['target'].squeeze(-1)#.detach().cpu()\n",
    "    sampless = predictions.permute(0, 2, 3, 1)#.detach().cpu() \n",
    "    num_batches = int(returns_all['prediction'].shape[0]/batch_size)+1\n",
    "    # Lists to accumulate metric values\n",
    "    crps_list = []\n",
    "    crps_sum_list = []\n",
    "    vs_05_list = []\n",
    "    vs_1_list = []\n",
    "    vs_2_list = []\n",
    "    es_list = []\n",
    "    # Loop through batches\n",
    "    pbar = tqdm(range(num_batches))\n",
    "    for b in pbar:\n",
    "        start, end = b * batch_size, min((b + 1) * batch_size, returns_all['prediction'].shape[0])\n",
    "        if start == end:\n",
    "            print(\"SKipping\")\n",
    "            continue  # Skip empty batch\n",
    "    \n",
    "        samples = sampless[start:end, :, :, :]\n",
    "        target = targets[start:end, :, :]\n",
    "    \n",
    "        crps = np.mean(sr.crps_ensemble(target.detach().cpu(), samples.detach().cpu(), estimator='pwm'))\n",
    "        crps_sum = np.mean(sr.crps_ensemble(target.detach().cpu().sum(axis=-1), samples.detach().cpu().sum(axis=-2), estimator='pwm'))\n",
    "        # vs_05 = np.mean(sr.variogram_score(target.permute(0, 2, 1), samples.permute(0, 2, 3, 1), p=0.5, backend='numba'))\n",
    "        vs_05 = torch.mean(vs_ensemble_torch(target.permute(0, 2, 1).to(device), samples.permute(0, 2, 3, 1).to(device), p=0.5))\n",
    "        # vs_1 = np.mean(sr.variogram_score(target.permute(0, 2, 1), samples.permute(0, 2, 3, 1), p=1.0, backend='numba'))\n",
    "        vs_1 = torch.mean(vs_ensemble_torch(target.permute(0, 2, 1).to(device), samples.permute(0, 2, 3, 1).to(device), p=1))\n",
    "        # vs_2 = np.mean(sr.variogram_score(target.permute(0, 2, 1), samples.permute(0, 2, 3, 1), p=2.0, backend='numba'))\n",
    "        vs_2 = torch.mean(vs_ensemble_torch(target.permute(0, 2, 1).to(device), samples.permute(0, 2, 3, 1).to(device), p=2))\n",
    "        \n",
    "        # es = np.mean(sr.energy_score(target.permute(0, 2, 1), samples.permute(0, 2, 3, 1), backend='numba'))\n",
    "        es = torch.mean(es_ensemble_torch(target.permute(0, 2, 1).to(device), samples.permute(0, 2, 3, 1).to(device)))\n",
    "        \n",
    "        # Append to lists\n",
    "        crps_list.append(crps)\n",
    "        crps_sum_list.append(crps_sum)\n",
    "        vs_05_list.append(vs_05.detach().cpu())\n",
    "        vs_1_list.append(vs_1.detach().cpu())\n",
    "        vs_2_list.append(vs_2.detach().cpu())\n",
    "        es_list.append(es.detach().cpu())\n",
    "    \n",
    "    # Final averages\n",
    "    final_scores = {\n",
    "        \"CRPS\": np.mean(crps_list),\n",
    "        \"CRPS_Sum\": np.mean(crps_sum_list),\n",
    "        \"VS_0.5\": np.mean(vs_05_list),\n",
    "        \"VS_1.0\": np.mean(vs_1_list),\n",
    "        \"VS_2.0\": np.mean(vs_2_list),\n",
    "        \"ES\": np.mean(es_list),\n",
    "    }\n",
    "    return final_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce4aeff-3861-45cf-9eca-543aa5f87a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_all(configs):\n",
    "    eval_dict = {rs:{} for rs in configs.keys()}\n",
    "    for rs in configs.keys():\n",
    "        for key in configs[rs].keys():\n",
    "            samples = sample(configs[rs][key]['runner'], configs[rs][key]['returns_all'], random_state=rs)\n",
    "            eval_dict[rs][key] = evaluate(samples, configs[rs][key]['returns_all'], batch_size=4)\n",
    "    print(eval_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1882b782-9ae0-49ac-8cab-28bc47f3470f",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_all(configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b86c945b-bced-4cf3-bd9e-115651f3ae4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {0: {'ETTh1_PTST_u': {'CRPS': np.float64(2.4197740580153275), 'CRPS_Sum': np.float64(8.704141144967366), 'VS_0.5': np.float32(572256.2), 'VS_1.0': np.float32(14644100.0), 'VS_2.0': np.float32(1985060100000.0), 'ES': np.float32(83.836754)}}, \n",
    "           1: {'ETTh1_PTST_u': {'CRPS': np.float64(2.4191808755737285), 'CRPS_Sum': np.float64(8.702462262138733), 'VS_0.5': np.float32(572201.0), 'VS_1.0': np.float32(14609265.0), 'VS_2.0': np.float32(28738159000.0), 'ES': np.float32(83.84088)}}, \n",
    "           2: {'ETTh1_PTST_u': {'CRPS': np.float64(2.4195399059040246), 'CRPS_Sum': np.float64(8.704312420450742), 'VS_0.5': np.float32(572196.56), 'VS_1.0': np.float32(14605370.0), 'VS_2.0': np.float32(48451195000.0), 'ES': np.float32(83.866234)}}, \n",
    "           3: {'ETTh1_PTST_u': {'CRPS': np.float64(2.41907135491505), 'CRPS_Sum': np.float64(8.702063031509304), 'VS_0.5': np.float32(572468.4), 'VS_1.0': np.float32(14621595.0), 'VS_2.0': np.float32(48899846000.0), 'ES': np.float32(83.85971)}}, \n",
    "           4: {'ETTh1_PTST_u': {'CRPS': np.float64(2.4195961071133296), 'CRPS_Sum': np.float64(8.704253091582524), 'VS_0.5': np.float32(572262.1), 'VS_1.0': np.float32(14613185.0), 'VS_2.0': np.float32(138508400000.0), 'ES': np.float32(83.84413)}}}\n",
    "# Extract metrics\n",
    "metrics = list(next(iter(results.values()))['ETTh1_PTST_u'].keys())\n",
    "agg = {metric: [] for metric in metrics}\n",
    "\n",
    "# rescaling = {\n",
    "#     \"VS_0.5\": 1e-4,\n",
    "#     \"VS_1.0\": 1e-6,\n",
    "#     \"VS_2.0\": 1e-10,\n",
    "# }\n",
    "rescaling = {}\n",
    "for run in results.values():\n",
    "    for metric in metrics:\n",
    "        if metric in rescaling.keys():\n",
    "            agg[metric].append(run['ETTh1_PTST_u'][metric]*rescaling[metric])\n",
    "        else:\n",
    "            agg[metric].append(run['ETTh1_PTST_u'][metric])\n",
    "\n",
    "# Compute stats\n",
    "summary = {}\n",
    "for metric in metrics:\n",
    "    values = np.array(agg[metric], dtype=np.float64)\n",
    "    summary[metric] = {\n",
    "        \"mean\": np.mean(values),\n",
    "        \"std\": np.std(values)\n",
    "    }\n",
    "\n",
    "# Display results\n",
    "for metric, stats in summary.items():\n",
    "    print(f\"{metric}: {stats['mean']:.4f} ± {stats['std']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b91e8461-cfc7-45b7-b948-13ae5ba31129",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scoringrules as sr\n",
    "import numpy as np\n",
    "device = returns_all['target'].device\n",
    "targets = returns_all['target'].squeeze(-1)#.detach().cpu()\n",
    "sampless = prediction.permute(0, 2, 3, 1)#.detach().cpu() \n",
    "print(sampless.shape)\n",
    "print(targets.shape)\n",
    " # 3. Compute approximate metrics\n",
    "batch_size = 4\n",
    "num_batches = int(returns_all['prediction'].shape[0]/batch_size)+1\n",
    "# Lists to accumulate metric values\n",
    "crps_list = []\n",
    "crps_sum_list = []\n",
    "vs_05_list = []\n",
    "vs_1_list = []\n",
    "vs_2_list = []\n",
    "es_list = []\n",
    "\n",
    "import torch\n",
    "\n",
    "def vs_ensemble_torch(obs, fct, p=1.0):\n",
    "    \"\"\"\n",
    "    Compute Variogram Score using PyTorch on GPU.\n",
    "    obs: shape (..., D)\n",
    "    fct: shape (..., M, D)\n",
    "    \"\"\"\n",
    "    M = fct.shape[-2]\n",
    "\n",
    "    # Compute ensemble variogram component\n",
    "    fct_diff = fct.unsqueeze(-2) - fct.unsqueeze(-1)  # (B, M, D, D)\n",
    "    # print(fct_diff.shape)\n",
    "    vfct = (fct_diff.abs() ** p).sum(dim=-3) / M  # (B, D, D)\n",
    "    # print(vfct.shape)\n",
    "    # Compute observed variogram component\n",
    "    obs_diff = obs.unsqueeze(-2) - obs.unsqueeze(-1)  # (B, D, D)\n",
    "    vobs = (obs_diff.abs() ** p)  # (B, D, D)\n",
    "    # print(vobs.shape)\n",
    "    # print(vfct.shape)\n",
    "    vs = ((vfct - vobs) ** 2).sum(dim=(-2, -1))  # (B,)\n",
    "    return vs\n",
    "\n",
    "def es_ensemble_torch(obs: torch.Tensor, fct: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Compute the energy score using PyTorch.\n",
    "    \n",
    "    Parameters:\n",
    "    - obs: Tensor of shape (B, D)\n",
    "    - fct: Tensor of shape (B, M, D)\n",
    "\n",
    "    Returns:\n",
    "    - Tensor of shape (B,) with energy scores\n",
    "    \"\"\"\n",
    "    M = fct.shape[-2]\n",
    "\n",
    "    # E_1: mean norm between forecast samples and the observation\n",
    "    err_norm = torch.norm(fct - obs.unsqueeze(-2), dim=-1)  # (B, M)\n",
    "    E_1 = err_norm.sum(dim=-1) / M  # (B,)\n",
    "\n",
    "    # E_2: mean pairwise distance between forecast samples\n",
    "    spread = fct.unsqueeze(-3) - fct.unsqueeze(-2)  # (B, M, M, D)\n",
    "    spread_norm = torch.norm(spread, dim=-1)  # (B, M, M)\n",
    "    E_2 = spread_norm.sum(dim=(-2, -1)) / (M**2) # (B,)\n",
    "\n",
    "    return E_1 - 0.5 * E_2  # (B,)\n",
    "\n",
    "# Loop through batches\n",
    "pbar = tqdm(range(num_batches))\n",
    "for b in pbar:\n",
    "    start, end = b * batch_size, min((b + 1) * batch_size, returns_all['prediction'].shape[0])\n",
    "    if start == end:\n",
    "        print(\"SKipping\")\n",
    "        continue  # Skip empty batch\n",
    "\n",
    "    samples = sampless[start:end, :, :, :]\n",
    "    target = targets[start:end, :, :]\n",
    "\n",
    "    crps = np.mean(sr.crps_ensemble(target.detach().cpu(), samples.detach().cpu(), estimator='pwm'))\n",
    "    crps_sum = np.mean(sr.crps_ensemble(target.detach().cpu().sum(axis=-1), samples.detach().cpu().sum(axis=-2), estimator='pwm'))\n",
    "    # vs_05 = np.mean(sr.variogram_score(target.permute(0, 2, 1), samples.permute(0, 2, 3, 1), p=0.5, backend='numba'))\n",
    "    vs_05 = torch.mean(vs_ensemble_torch(target.permute(0, 2, 1).to(device), samples.permute(0, 2, 3, 1).to(device), p=0.5))\n",
    "    # vs_1 = np.mean(sr.variogram_score(target.permute(0, 2, 1), samples.permute(0, 2, 3, 1), p=1.0, backend='numba'))\n",
    "    vs_1 = torch.mean(vs_ensemble_torch(target.permute(0, 2, 1).to(device), samples.permute(0, 2, 3, 1).to(device), p=1))\n",
    "    # vs_2 = np.mean(sr.variogram_score(target.permute(0, 2, 1), samples.permute(0, 2, 3, 1), p=2.0, backend='numba'))\n",
    "    vs_2 = torch.mean(vs_ensemble_torch(target.permute(0, 2, 1).to(device), samples.permute(0, 2, 3, 1).to(device), p=2))\n",
    "    \n",
    "    # es = np.mean(sr.energy_score(target.permute(0, 2, 1), samples.permute(0, 2, 3, 1), backend='numba'))\n",
    "    es = torch.mean(es_ensemble_torch(target.permute(0, 2, 1).to(device), samples.permute(0, 2, 3, 1).to(device)))\n",
    "    \n",
    "    # Append to lists\n",
    "    crps_list.append(crps)\n",
    "    crps_sum_list.append(crps_sum)\n",
    "    vs_05_list.append(vs_05.detach().cpu())\n",
    "    vs_1_list.append(vs_1.detach().cpu())\n",
    "    vs_2_list.append(vs_2.detach().cpu())\n",
    "    es_list.append(es.detach().cpu())\n",
    "\n",
    "    # # Update tqdm with running averages\n",
    "    # # pbar.set_description(f\"CRPS: {np.mean(crps_list):.4f}, VS1: {np.mean(vs_1_list):.4f}, ES: {np.mean(es_list):.4f}\")\n",
    "    \n",
    "    # pbar.set_description(f\"VS: {vs_05:.4f}, VS_T: {vs_05_torch:.4f},\")\n",
    "\n",
    "# Final averages\n",
    "final_scores = {\n",
    "    \"CRPS\": np.mean(crps_list),\n",
    "    \"CRPS_Sum\": np.mean(crps_sum_list),\n",
    "    \"VS_0.5\": np.mean(vs_05_list),\n",
    "    \"VS_1.0\": np.mean(vs_1_list),\n",
    "    \"VS_2.0\": np.mean(vs_2_list),\n",
    "    \"ES\": np.mean(es_list),\n",
    "}\n",
    "\n",
    "print(\"\\nFinal Scores:\")\n",
    "for k, v in final_scores.items():\n",
    "    print(f\"{k}: {v:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155d902f-88b6-4a96-b72a-c1fa01a87992",
   "metadata": {},
   "outputs": [],
   "source": [
    "Final Scores:\n",
    "CRPS: 2.4193\n",
    "CRPS_Sum: 8.7032\n",
    "VS_0.5: 572217.8750\n",
    "VS_1.0: 14610408.0000\n",
    "VS_2.0: 345045532672.0000\n",
    "ES: 83.8458\n",
    "\n",
    "\n",
    "Final Scores:\n",
    "CRPS: 2.4194\n",
    "CRPS_Sum: 8.7040\n",
    "VS_0.5: 572181.3125\n",
    "VS_1.0: 14610432.0000\n",
    "VS_2.0: 168409481216.0000\n",
    "ES: 83.8460"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BasicTS",
   "language": "python",
   "name": "basicts"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
