{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df69e24e-2162-4989-9bf0-b68682d6b1a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-08 13:08:17,233 - easytorch-env - INFO - Use devices 0.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir('/home/kreffert/Probabilistic_LTSF/BasicTS/')\n",
    "from basicts.metrics import masked_mae, masked_mse, nll_loss, crps, Evaluator, quantile_loss, empirical_crps\n",
    "from easytorch.device import set_device_type\n",
    "from easytorch.utils import get_logger, set_visible_devices\n",
    "# set the device type (CPU, GPU, or MLU)\n",
    "device_type ='gpu'\n",
    "gpus = '0'\n",
    "set_device_type(device_type)\n",
    "set_visible_devices(gpus)\n",
    "from easydict import EasyDict\n",
    "from tqdm import tqdm\n",
    "\n",
    "def load_cfg(cfg, random_state=None):\n",
    "    from easytorch.config import init_cfg\n",
    "    # cfg path which start with dot will crash the easytorch, just remove dot\n",
    "    while isinstance(cfg, str) and cfg.startswith(('./','.\\\\')):\n",
    "        cfg = cfg[2:]\n",
    "    # while ckpt_path.startswith(('./','.\\\\')):\n",
    "    #     ckpt_path = ckpt_path[2:]\n",
    "    \n",
    "    # initialize the configuration\n",
    "    cfg = init_cfg(cfg, save=False)\n",
    "    # cfg['METRICS'] = EasyDict()\n",
    "    # all_metrics = [#\"MSE\", \"abs_error\", \"abs_target_sum\", \"abs_target_mean\",\n",
    "    #                 # \"MAPE\", \"sMAPE\", \"MASE\", \"RMSE\", \"NRMSE\", \"ND\", \"weighted_ND\",\n",
    "    #                 \"mean_absolute_QuantileLoss\", \"CRPS\", \"MAE_Coverage\", \"NLL\", \n",
    "    #                 #\"VS\", \"ES\"\n",
    "    #                 ]\n",
    "    # cfg['METRICS']['FUNCS'] = EasyDict({\n",
    "    #     'NLL': nll_loss,\n",
    "    #     'CRPS': crps,\n",
    "    #     # 'Evaluator': Evaluator(distribution_type=MODEL_PARAM['distribution_type'], \n",
    "    #     #                        quantiles=MODEL_PARAM['quantiles']),\n",
    "    #     'Val_Evaluator': Evaluator(distribution_type=cfg['MODEL']['PARAM']['distribution_type'], metrics = all_metrics,\n",
    "    #                             quantiles=cfg['MODEL']['PARAM']['prob_args']['quantiles']),  # only use the evaluator during validation/testing iters\n",
    "    # })\n",
    "\n",
    "    \n",
    "    if random_state is not None:\n",
    "        print(f'Using random state {random_state}')\n",
    "        # import os\n",
    "        # os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\"\n",
    "        cfg['ENV'] = EasyDict() # Environment settings. Default: None\n",
    "        # GPU and random seed settings\n",
    "        cfg['ENV']['TF32'] = True # Whether to use TensorFloat-32 in GPU. Default: False. See https://pytorch.org/docs/stable/notes/cuda.html#tf32-on-ampere.\n",
    "        cfg['ENV']['SEED'] = random_state # Random seed. Default: None\n",
    "        cfg['ENV']['DETERMINISTIC'] = True # Whether to set the random seed to get deterministic results. Default: False\n",
    "        cfg['ENV']['CUDNN'] = EasyDict()\n",
    "        cfg['ENV']['CUDNN']['ENABLED'] = True # Whether to enable cuDNN. Default: True\n",
    "        cfg['ENV']['CUDNN']['BENCHMARK'] = True# Whether to enable cuDNN benchmark. Default: True\n",
    "        cfg['ENV']['CUDNN']['DETERMINISTIC'] = True # Whether to set cuDNN to deterministic mode. Default: False\n",
    "    return cfg\n",
    "\n",
    "def load_runner(configs, random_states=[]):\n",
    "    for rs in random_states:\n",
    "        for key in configs[rs].keys():\n",
    "            configs[rs][key]['cfg'] = load_cfg(configs[rs][key]['cfg'], random_state=rs)\n",
    "            cfg = configs[rs][key]['cfg']\n",
    "            ckpt_path = '/home/kreffert/Probabilistic_LTSF/BasicTS/' + configs[rs][key]['ckpt']\n",
    "            strict = True\n",
    "            runner = cfg['RUNNER'](cfg)\n",
    "            # setup the graph if needed\n",
    "            if runner.need_setup_graph:\n",
    "                runner.setup_graph(cfg=cfg, train=False)\n",
    "                \n",
    "            print(f'Loading model checkpoint from {ckpt_path}')\n",
    "            runner.load_model(ckpt_path=ckpt_path, strict=strict)\n",
    "            \n",
    "            # runner.test_pipeline(cfg=cfg, save_metrics=False, save_results=False)\n",
    "            configs[rs][key]['runner'] = runner\n",
    "    return configs\n",
    "\n",
    "import torch\n",
    "\n",
    "@torch.no_grad()\n",
    "def get_predictions(configs):\n",
    "    for rs in configs.keys():\n",
    "        for key in configs[rs].keys():\n",
    "            runner = configs[rs][key]['runner']\n",
    "            cfg = configs[rs][key]['cfg']\n",
    "            # init test\n",
    "            runner.test_interval = cfg['TEST'].get('INTERVAL', 1)\n",
    "            runner.test_data_loader = runner.build_test_data_loader(cfg)\n",
    "        \n",
    "            runner.model.eval()\n",
    "            prediction, target, inputs = [], [], []\n",
    "        \n",
    "            for data in tqdm(runner.test_data_loader):\n",
    "                forward_return = runner.forward(data, epoch=None, iter_num=None, train=False)\n",
    "                if not runner.if_evaluate_on_gpu:\n",
    "                    forward_return['prediction'] = forward_return['prediction'].detach().cpu()\n",
    "                    forward_return['target'] = forward_return['target'].detach().cpu()\n",
    "                    forward_return['inputs'] = forward_return['inputs'].detach().cpu()\n",
    "        \n",
    "                prediction.append(forward_return['prediction'])\n",
    "                target.append(forward_return['target'])\n",
    "                inputs.append(forward_return['inputs'])\n",
    "        \n",
    "            prediction = torch.cat(prediction, dim=0)\n",
    "            target = torch.cat(target, dim=0)\n",
    "            inputs = torch.cat(inputs, dim=0)\n",
    "        \n",
    "            returns_all = {'prediction': prediction, 'target': target, 'inputs': inputs}\n",
    "            configs[rs][key]['returns_all'] = returns_all\n",
    "    return configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "892e5d76-dd7c-41e5-beb1-79f117e04dc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-08 13:08:17,276 - easytorch-env - INFO - Enable TF32 mode\n",
      "2025-06-08 13:08:17,284 - easytorch-env - INFO - Use deterministic algorithms.\n",
      "2025-06-08 13:08:17,284 - easytorch-env - INFO - Set cudnn deterministic.\n",
      "2025-06-08 13:08:17,285 - easytorch - INFO - Set ckpt save dir: '/home/kreffert/Probabilistic_LTSF/BasicTS/final_weights/PatchTST/univariate/ETTh1_100_96_720/590c87b95ca683a9092af664b104c9bd'\n",
      "2025-06-08 13:08:17,286 - easytorch - INFO - Building model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using random state 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-08 13:08:19,032 - easytorch - INFO - Load model from : /home/kreffert/Probabilistic_LTSF/BasicTS/final_weights/PatchTST/univariate/ETTh1_100_96_720/a8de06edad7530010e0b704422b431a2/PatchTST_best_val_NLL.pt\n",
      "2025-06-08 13:08:19,036 - easytorch - INFO - Loading Checkpoint from '/home/kreffert/Probabilistic_LTSF/BasicTS/final_weights/PatchTST/univariate/ETTh1_100_96_720/a8de06edad7530010e0b704422b431a2/PatchTST_best_val_NLL.pt'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PatchTST\n",
      "Loading model checkpoint from /home/kreffert/Probabilistic_LTSF/BasicTS/final_weights/PatchTST/univariate/ETTh1_100_96_720/a8de06edad7530010e0b704422b431a2/PatchTST_best_val_NLL.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-08 13:08:19,485 - easytorch-env - INFO - Enable TF32 mode\n",
      "2025-06-08 13:08:19,494 - easytorch-env - INFO - Use deterministic algorithms.\n",
      "2025-06-08 13:08:19,495 - easytorch-env - INFO - Set cudnn deterministic.\n",
      "2025-06-08 13:08:19,496 - easytorch - INFO - Set ckpt save dir: '/home/kreffert/Probabilistic_LTSF/BasicTS/final_weights/PatchTST/univariate/ETTh1_100_96_720/590c87b95ca683a9092af664b104c9bd'\n",
      "2025-06-08 13:08:19,497 - easytorch - INFO - Building model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using random state 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-08 13:08:20,641 - easytorch - INFO - Load model from : /home/kreffert/Probabilistic_LTSF/BasicTS/final_weights/PatchTST/univariate/ETTh1_100_96_720/a8de06edad7530010e0b704422b431a2/PatchTST_best_val_NLL.pt\n",
      "2025-06-08 13:08:20,644 - easytorch - INFO - Loading Checkpoint from '/home/kreffert/Probabilistic_LTSF/BasicTS/final_weights/PatchTST/univariate/ETTh1_100_96_720/a8de06edad7530010e0b704422b431a2/PatchTST_best_val_NLL.pt'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PatchTST\n",
      "Loading model checkpoint from /home/kreffert/Probabilistic_LTSF/BasicTS/final_weights/PatchTST/univariate/ETTh1_100_96_720/a8de06edad7530010e0b704422b431a2/PatchTST_best_val_NLL.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-08 13:08:21,203 - easytorch-env - INFO - Enable TF32 mode\n",
      "2025-06-08 13:08:21,210 - easytorch-env - INFO - Use deterministic algorithms.\n",
      "2025-06-08 13:08:21,211 - easytorch-env - INFO - Set cudnn deterministic.\n",
      "2025-06-08 13:08:21,211 - easytorch - INFO - Set ckpt save dir: '/home/kreffert/Probabilistic_LTSF/BasicTS/final_weights/PatchTST/univariate/ETTh1_100_96_720/590c87b95ca683a9092af664b104c9bd'\n",
      "2025-06-08 13:08:21,212 - easytorch - INFO - Building model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using random state 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-08 13:08:22,371 - easytorch - INFO - Load model from : /home/kreffert/Probabilistic_LTSF/BasicTS/final_weights/PatchTST/univariate/ETTh1_100_96_720/a8de06edad7530010e0b704422b431a2/PatchTST_best_val_NLL.pt\n",
      "2025-06-08 13:08:22,374 - easytorch - INFO - Loading Checkpoint from '/home/kreffert/Probabilistic_LTSF/BasicTS/final_weights/PatchTST/univariate/ETTh1_100_96_720/a8de06edad7530010e0b704422b431a2/PatchTST_best_val_NLL.pt'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PatchTST\n",
      "Loading model checkpoint from /home/kreffert/Probabilistic_LTSF/BasicTS/final_weights/PatchTST/univariate/ETTh1_100_96_720/a8de06edad7530010e0b704422b431a2/PatchTST_best_val_NLL.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-08 13:08:26,167 - easytorch-env - INFO - Enable TF32 mode\n",
      "2025-06-08 13:08:26,174 - easytorch-env - INFO - Use deterministic algorithms.\n",
      "2025-06-08 13:08:26,175 - easytorch-env - INFO - Set cudnn deterministic.\n",
      "2025-06-08 13:08:26,176 - easytorch - INFO - Set ckpt save dir: '/home/kreffert/Probabilistic_LTSF/BasicTS/final_weights/PatchTST/univariate/ETTh1_100_96_720/590c87b95ca683a9092af664b104c9bd'\n",
      "2025-06-08 13:08:26,176 - easytorch - INFO - Building model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using random state 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-08 13:08:27,316 - easytorch - INFO - Load model from : /home/kreffert/Probabilistic_LTSF/BasicTS/final_weights/PatchTST/univariate/ETTh1_100_96_720/a8de06edad7530010e0b704422b431a2/PatchTST_best_val_NLL.pt\n",
      "2025-06-08 13:08:27,319 - easytorch - INFO - Loading Checkpoint from '/home/kreffert/Probabilistic_LTSF/BasicTS/final_weights/PatchTST/univariate/ETTh1_100_96_720/a8de06edad7530010e0b704422b431a2/PatchTST_best_val_NLL.pt'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PatchTST\n",
      "Loading model checkpoint from /home/kreffert/Probabilistic_LTSF/BasicTS/final_weights/PatchTST/univariate/ETTh1_100_96_720/a8de06edad7530010e0b704422b431a2/PatchTST_best_val_NLL.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-08 13:08:27,838 - easytorch-env - INFO - Enable TF32 mode\n",
      "2025-06-08 13:08:27,845 - easytorch-env - INFO - Use deterministic algorithms.\n",
      "2025-06-08 13:08:27,847 - easytorch-env - INFO - Set cudnn deterministic.\n",
      "2025-06-08 13:08:27,847 - easytorch - INFO - Set ckpt save dir: '/home/kreffert/Probabilistic_LTSF/BasicTS/final_weights/PatchTST/univariate/ETTh1_100_96_720/590c87b95ca683a9092af664b104c9bd'\n",
      "2025-06-08 13:08:27,848 - easytorch - INFO - Building model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using random state 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-08 13:08:28,976 - easytorch - INFO - Load model from : /home/kreffert/Probabilistic_LTSF/BasicTS/final_weights/PatchTST/univariate/ETTh1_100_96_720/a8de06edad7530010e0b704422b431a2/PatchTST_best_val_NLL.pt\n",
      "2025-06-08 13:08:28,979 - easytorch - INFO - Loading Checkpoint from '/home/kreffert/Probabilistic_LTSF/BasicTS/final_weights/PatchTST/univariate/ETTh1_100_96_720/a8de06edad7530010e0b704422b431a2/PatchTST_best_val_NLL.pt'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PatchTST\n",
      "Loading model checkpoint from /home/kreffert/Probabilistic_LTSF/BasicTS/final_weights/PatchTST/univariate/ETTh1_100_96_720/a8de06edad7530010e0b704422b431a2/PatchTST_best_val_NLL.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-08 13:08:29,542 - easytorch - INFO - Test dataset length: 2065\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 33/33 [00:08<00:00,  3.83it/s]\n",
      "2025-06-08 13:08:38,176 - easytorch - INFO - Test dataset length: 2065\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 33/33 [00:07<00:00,  4.50it/s]\n",
      "2025-06-08 13:08:45,540 - easytorch - INFO - Test dataset length: 2065\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 33/33 [00:07<00:00,  4.51it/s]\n",
      "2025-06-08 13:08:52,863 - easytorch - INFO - Test dataset length: 2065\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 33/33 [00:07<00:00,  4.49it/s]\n",
      "2025-06-08 13:09:00,244 - easytorch - INFO - Test dataset length: 2065\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 33/33 [00:07<00:00,  4.44it/s]\n"
     ]
    }
   ],
   "source": [
    "# 1. load the model and set the device\n",
    "_configs = {'ETTh1_PTST_u': {'cfg':'final_weights/PatchTST/univariate/ETTh1_prob.py',\n",
    "                           'ckpt': 'final_weights/PatchTST/univariate/ETTh1_100_96_720/a8de06edad7530010e0b704422b431a2/PatchTST_best_val_NLL.pt'\n",
    "                          },\n",
    "           # 'ETTh1_PTST_q': {'cfg': 'final_weights/PatchTST/quantile/ETTh1_prob.py',\n",
    "           #                  'ckpt': 'final_weights/PatchTST/quantile/ETTh1_100_96_720/a2a39ac1680165e5ffbda2c7bbda5add/PatchTST_best_val_QL.pt'\n",
    "           #                 }\n",
    "          }\n",
    "\n",
    "random_states = range(5)\n",
    "\n",
    "configs = {rs:_configs for rs in random_states}\n",
    "\n",
    "configs = load_runner(configs, random_states=random_states)\n",
    "configs = get_predictions(configs)\n",
    "# metrics_results = self.compute_evaluation_metrics(returns_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ad2779b-e0b2-42e1-b694-91ae0decfeb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "def vs_ensemble_torch(obs, fct, p=1.0):\n",
    "    \"\"\"\n",
    "    Compute Variogram Score using PyTorch on GPU.\n",
    "    obs: shape (..., D)\n",
    "    fct: shape (..., M, D)\n",
    "    \"\"\"\n",
    "    M = fct.shape[-2]\n",
    "\n",
    "    # Compute ensemble variogram component\n",
    "    fct_diff = fct.unsqueeze(-2) - fct.unsqueeze(-1)  # (B, M, D, D)\n",
    "    # print(fct_diff.shape)\n",
    "    vfct = (fct_diff.abs() ** p).sum(dim=-3) / M  # (B, D, D)\n",
    "    # print(vfct.shape)\n",
    "    # Compute observed variogram component\n",
    "    obs_diff = obs.unsqueeze(-2) - obs.unsqueeze(-1)  # (B, D, D)\n",
    "    vobs = (obs_diff.abs() ** p)  # (B, D, D)\n",
    "    # print(vobs.shape)\n",
    "    # print(vfct.shape)\n",
    "    vs = ((vfct - vobs) ** 2).sum(dim=(-2, -1))  # (B,)\n",
    "    return vs\n",
    "\n",
    "def es_ensemble_torch(obs: torch.Tensor, fct: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Compute the energy score using PyTorch.\n",
    "    \n",
    "    Parameters:\n",
    "    - obs: Tensor of shape (B, D)\n",
    "    - fct: Tensor of shape (B, M, D)\n",
    "\n",
    "    Returns:\n",
    "    - Tensor of shape (B,) with energy scores\n",
    "    \"\"\"\n",
    "    M = fct.shape[-2]\n",
    "\n",
    "    # E_1: mean norm between forecast samples and the observation\n",
    "    err_norm = torch.norm(fct - obs.unsqueeze(-2), dim=-1)  # (B, M)\n",
    "    E_1 = err_norm.sum(dim=-1) / M  # (B,)\n",
    "\n",
    "    # E_2: mean pairwise distance between forecast samples\n",
    "    spread = fct.unsqueeze(-3) - fct.unsqueeze(-2)  # (B, M, M, D)\n",
    "    spread_norm = torch.norm(spread, dim=-1)  # (B, M, M)\n",
    "    E_2 = spread_norm.sum(dim=(-2, -1)) / (M**2) # (B,)\n",
    "\n",
    "    return E_1 - 0.5 * E_2  # (B,)\n",
    "\n",
    "def sample(runner, returns_all, random_state=None):\n",
    "    from prob.prob_head import ProbabilisticHead # load that class for sampling\n",
    "    head = ProbabilisticHead(1, 1, runner.distribution_type, prob_args=runner.prob_args)\n",
    "    samples = []\n",
    "    batch_size = 64\n",
    "    num_batches = int(returns_all['prediction'].shape[0]/batch_size)+1\n",
    "    for b in range(num_batches):\n",
    "        start, end = b*batch_size, min((b+1)*batch_size, returns_all['prediction'].shape[0])\n",
    "        pred = returns_all['prediction'][start:end, :, :, :]\n",
    "        sample = head.sample(pred, num_samples=100, random_state=random_state) # [samples x bs x seq_len x nvars]\n",
    "        sample = sample.permute(1, 0, 2, 3)       # [bs x samples x seq_len x nvars]\n",
    "        samples.append(sample)\n",
    "    samples = torch.cat(samples, dim=0)\n",
    "    return samples\n",
    "\n",
    "def evaluate(predictions, returns_all, batch_size=4):\n",
    "    import scoringrules as sr\n",
    "    import numpy as np\n",
    "    device = returns_all['target'].device\n",
    "    targets = returns_all['target'].squeeze(-1)#.detach().cpu()\n",
    "    sampless = predictions.permute(0, 2, 3, 1)#.detach().cpu() \n",
    "    num_batches = int(returns_all['prediction'].shape[0]/batch_size)+1\n",
    "    # Lists to accumulate metric values\n",
    "    crps_list = []\n",
    "    crps_sum_list = []\n",
    "    vs_05_list = []\n",
    "    vs_1_list = []\n",
    "    vs_2_list = []\n",
    "    es_list = []\n",
    "    # Loop through batches\n",
    "    pbar = tqdm(range(num_batches))\n",
    "    for b in pbar:\n",
    "        start, end = b * batch_size, min((b + 1) * batch_size, returns_all['prediction'].shape[0])\n",
    "        if start == end:\n",
    "            print(\"SKipping\")\n",
    "            continue  # Skip empty batch\n",
    "    \n",
    "        samples = sampless[start:end, :, :, :]\n",
    "        target = targets[start:end, :, :]\n",
    "    \n",
    "        crps = np.mean(sr.crps_ensemble(target.detach().cpu(), samples.detach().cpu(), estimator='pwm'))\n",
    "        crps_sum = np.mean(sr.crps_ensemble(target.detach().cpu().sum(axis=-1), samples.detach().cpu().sum(axis=-2), estimator='pwm'))\n",
    "        # vs_05 = np.mean(sr.variogram_score(target.permute(0, 2, 1), samples.permute(0, 2, 3, 1), p=0.5, backend='numba'))\n",
    "        vs_05 = torch.mean(vs_ensemble_torch(target.permute(0, 2, 1).to(device), samples.permute(0, 2, 3, 1).to(device), p=0.5))\n",
    "        # vs_1 = np.mean(sr.variogram_score(target.permute(0, 2, 1), samples.permute(0, 2, 3, 1), p=1.0, backend='numba'))\n",
    "        vs_1 = torch.mean(vs_ensemble_torch(target.permute(0, 2, 1).to(device), samples.permute(0, 2, 3, 1).to(device), p=1))\n",
    "        # vs_2 = np.mean(sr.variogram_score(target.permute(0, 2, 1), samples.permute(0, 2, 3, 1), p=2.0, backend='numba'))\n",
    "        vs_2 = torch.mean(vs_ensemble_torch(target.permute(0, 2, 1).to(device), samples.permute(0, 2, 3, 1).to(device), p=2))\n",
    "        \n",
    "        # es = np.mean(sr.energy_score(target.permute(0, 2, 1), samples.permute(0, 2, 3, 1), backend='numba'))\n",
    "        es = torch.mean(es_ensemble_torch(target.permute(0, 2, 1).to(device), samples.permute(0, 2, 3, 1).to(device)))\n",
    "        \n",
    "        # Append to lists\n",
    "        crps_list.append(crps)\n",
    "        crps_sum_list.append(crps_sum)\n",
    "        vs_05_list.append(vs_05.detach().cpu())\n",
    "        vs_1_list.append(vs_1.detach().cpu())\n",
    "        vs_2_list.append(vs_2.detach().cpu())\n",
    "        es_list.append(es.detach().cpu())\n",
    "    \n",
    "    # Final averages\n",
    "    final_scores = {\n",
    "        \"CRPS\": np.mean(crps_list),\n",
    "        \"CRPS_Sum\": np.mean(crps_sum_list),\n",
    "        \"VS_0.5\": np.mean(vs_05_list),\n",
    "        \"VS_1.0\": np.mean(vs_1_list),\n",
    "        \"VS_2.0\": np.mean(vs_2_list),\n",
    "        \"ES\": np.mean(es_list),\n",
    "    }\n",
    "    return final_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ce4aeff-3861-45cf-9eca-543aa5f87a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_all(configs):\n",
    "    eval_dict = {rs:{} for rs in configs.keys()}\n",
    "    for rs in configs.keys():\n",
    "        for key in configs[rs].keys():\n",
    "            samples = sample(configs[rs][key]['runner'], configs[rs][key]['returns_all'], random_state=rs)\n",
    "            eval_dict[rs][key] = evaluate(samples, configs[rs][key]['returns_all'], batch_size=4)\n",
    "    print(eval_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1882b782-9ae0-49ac-8cab-28bc47f3470f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 517/517 [04:07<00:00,  2.09it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 517/517 [04:13<00:00,  2.04it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 517/517 [04:06<00:00,  2.09it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 517/517 [04:06<00:00,  2.10it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 517/517 [04:06<00:00,  2.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: {'ETTh1_PTST_u': {'CRPS': np.float64(2.4197740580153275), 'CRPS_Sum': np.float64(8.704141144967366), 'VS_0.5': np.float32(572256.2), 'VS_1.0': np.float32(14644100.0), 'VS_2.0': np.float32(1985060100000.0), 'ES': np.float32(83.836754)}}, 1: {'ETTh1_PTST_u': {'CRPS': np.float64(2.4191808755737285), 'CRPS_Sum': np.float64(8.702462262138733), 'VS_0.5': np.float32(572201.0), 'VS_1.0': np.float32(14609265.0), 'VS_2.0': np.float32(28738159000.0), 'ES': np.float32(83.84088)}}, 2: {'ETTh1_PTST_u': {'CRPS': np.float64(2.4195399059040246), 'CRPS_Sum': np.float64(8.704312420450742), 'VS_0.5': np.float32(572196.56), 'VS_1.0': np.float32(14605370.0), 'VS_2.0': np.float32(48451195000.0), 'ES': np.float32(83.866234)}}, 3: {'ETTh1_PTST_u': {'CRPS': np.float64(2.41907135491505), 'CRPS_Sum': np.float64(8.702063031509304), 'VS_0.5': np.float32(572468.4), 'VS_1.0': np.float32(14621595.0), 'VS_2.0': np.float32(48899846000.0), 'ES': np.float32(83.85971)}}, 4: {'ETTh1_PTST_u': {'CRPS': np.float64(2.4195961071133296), 'CRPS_Sum': np.float64(8.704253091582524), 'VS_0.5': np.float32(572262.1), 'VS_1.0': np.float32(14613185.0), 'VS_2.0': np.float32(138508400000.0), 'ES': np.float32(83.84413)}}}\n"
     ]
    }
   ],
   "source": [
    "evaluate_all(configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b86c945b-bced-4cf3-bd9e-115651f3ae4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CRPS: 2.4194 ± 0.0003\n",
      "CRPS_Sum: 8.7034 ± 0.0010\n",
      "VS_0.5: 572276.8500 ± 99.5238\n",
      "VS_1.0: 14618703.0000 ± 13788.8675\n",
      "VS_2.0: 449931549081.6000 ± 768507768348.2292\n",
      "ES: 83.8495 ± 0.0114\n"
     ]
    }
   ],
   "source": [
    "results = {0: {'ETTh1_PTST_u': {'CRPS': np.float64(2.4197740580153275), 'CRPS_Sum': np.float64(8.704141144967366), 'VS_0.5': np.float32(572256.2), 'VS_1.0': np.float32(14644100.0), 'VS_2.0': np.float32(1985060100000.0), 'ES': np.float32(83.836754)}}, \n",
    "           1: {'ETTh1_PTST_u': {'CRPS': np.float64(2.4191808755737285), 'CRPS_Sum': np.float64(8.702462262138733), 'VS_0.5': np.float32(572201.0), 'VS_1.0': np.float32(14609265.0), 'VS_2.0': np.float32(28738159000.0), 'ES': np.float32(83.84088)}}, \n",
    "           2: {'ETTh1_PTST_u': {'CRPS': np.float64(2.4195399059040246), 'CRPS_Sum': np.float64(8.704312420450742), 'VS_0.5': np.float32(572196.56), 'VS_1.0': np.float32(14605370.0), 'VS_2.0': np.float32(48451195000.0), 'ES': np.float32(83.866234)}}, \n",
    "           3: {'ETTh1_PTST_u': {'CRPS': np.float64(2.41907135491505), 'CRPS_Sum': np.float64(8.702063031509304), 'VS_0.5': np.float32(572468.4), 'VS_1.0': np.float32(14621595.0), 'VS_2.0': np.float32(48899846000.0), 'ES': np.float32(83.85971)}}, \n",
    "           4: {'ETTh1_PTST_u': {'CRPS': np.float64(2.4195961071133296), 'CRPS_Sum': np.float64(8.704253091582524), 'VS_0.5': np.float32(572262.1), 'VS_1.0': np.float32(14613185.0), 'VS_2.0': np.float32(138508400000.0), 'ES': np.float32(83.84413)}}}\n",
    "# Extract metrics\n",
    "metrics = list(next(iter(results.values()))['ETTh1_PTST_u'].keys())\n",
    "agg = {metric: [] for metric in metrics}\n",
    "\n",
    "# rescaling = {\n",
    "#     \"VS_0.5\": 1e-4,\n",
    "#     \"VS_1.0\": 1e-6,\n",
    "#     \"VS_2.0\": 1e-10,\n",
    "# }\n",
    "rescaling = {}\n",
    "for run in results.values():\n",
    "    for metric in metrics:\n",
    "        if metric in rescaling.keys():\n",
    "            agg[metric].append(run['ETTh1_PTST_u'][metric]*rescaling[metric])\n",
    "        else:\n",
    "            agg[metric].append(run['ETTh1_PTST_u'][metric])\n",
    "\n",
    "# Compute stats\n",
    "summary = {}\n",
    "for metric in metrics:\n",
    "    values = np.array(agg[metric], dtype=np.float64)\n",
    "    summary[metric] = {\n",
    "        \"mean\": np.mean(values),\n",
    "        \"std\": np.std(values)\n",
    "    }\n",
    "\n",
    "# Display results\n",
    "for metric, stats in summary.items():\n",
    "    print(f\"{metric}: {stats['mean']:.4f} ± {stats['std']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b91e8461-cfc7-45b7-b948-13ae5ba31129",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'returns_all' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mscoringrules\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msr\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m device = \u001b[43mreturns_all\u001b[49m[\u001b[33m'\u001b[39m\u001b[33mtarget\u001b[39m\u001b[33m'\u001b[39m].device\n\u001b[32m      4\u001b[39m targets = returns_all[\u001b[33m'\u001b[39m\u001b[33mtarget\u001b[39m\u001b[33m'\u001b[39m].squeeze(-\u001b[32m1\u001b[39m)\u001b[38;5;66;03m#.detach().cpu()\u001b[39;00m\n\u001b[32m      5\u001b[39m sampless = prediction.permute(\u001b[32m0\u001b[39m, \u001b[32m2\u001b[39m, \u001b[32m3\u001b[39m, \u001b[32m1\u001b[39m)\u001b[38;5;66;03m#.detach().cpu() \u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'returns_all' is not defined"
     ]
    }
   ],
   "source": [
    "import scoringrules as sr\n",
    "import numpy as np\n",
    "device = returns_all['target'].device\n",
    "targets = returns_all['target'].squeeze(-1)#.detach().cpu()\n",
    "sampless = prediction.permute(0, 2, 3, 1)#.detach().cpu() \n",
    "print(sampless.shape)\n",
    "print(targets.shape)\n",
    " # 3. Compute approximate metrics\n",
    "batch_size = 4\n",
    "num_batches = int(returns_all['prediction'].shape[0]/batch_size)+1\n",
    "# Lists to accumulate metric values\n",
    "crps_list = []\n",
    "crps_sum_list = []\n",
    "vs_05_list = []\n",
    "vs_1_list = []\n",
    "vs_2_list = []\n",
    "es_list = []\n",
    "\n",
    "import torch\n",
    "\n",
    "def vs_ensemble_torch(obs, fct, p=1.0):\n",
    "    \"\"\"\n",
    "    Compute Variogram Score using PyTorch on GPU.\n",
    "    obs: shape (..., D)\n",
    "    fct: shape (..., M, D)\n",
    "    \"\"\"\n",
    "    M = fct.shape[-2]\n",
    "\n",
    "    # Compute ensemble variogram component\n",
    "    fct_diff = fct.unsqueeze(-2) - fct.unsqueeze(-1)  # (B, M, D, D)\n",
    "    # print(fct_diff.shape)\n",
    "    vfct = (fct_diff.abs() ** p).sum(dim=-3) / M  # (B, D, D)\n",
    "    # print(vfct.shape)\n",
    "    # Compute observed variogram component\n",
    "    obs_diff = obs.unsqueeze(-2) - obs.unsqueeze(-1)  # (B, D, D)\n",
    "    vobs = (obs_diff.abs() ** p)  # (B, D, D)\n",
    "    # print(vobs.shape)\n",
    "    # print(vfct.shape)\n",
    "    vs = ((vfct - vobs) ** 2).sum(dim=(-2, -1))  # (B,)\n",
    "    return vs\n",
    "\n",
    "def es_ensemble_torch(obs: torch.Tensor, fct: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Compute the energy score using PyTorch.\n",
    "    \n",
    "    Parameters:\n",
    "    - obs: Tensor of shape (B, D)\n",
    "    - fct: Tensor of shape (B, M, D)\n",
    "\n",
    "    Returns:\n",
    "    - Tensor of shape (B,) with energy scores\n",
    "    \"\"\"\n",
    "    M = fct.shape[-2]\n",
    "\n",
    "    # E_1: mean norm between forecast samples and the observation\n",
    "    err_norm = torch.norm(fct - obs.unsqueeze(-2), dim=-1)  # (B, M)\n",
    "    E_1 = err_norm.sum(dim=-1) / M  # (B,)\n",
    "\n",
    "    # E_2: mean pairwise distance between forecast samples\n",
    "    spread = fct.unsqueeze(-3) - fct.unsqueeze(-2)  # (B, M, M, D)\n",
    "    spread_norm = torch.norm(spread, dim=-1)  # (B, M, M)\n",
    "    E_2 = spread_norm.sum(dim=(-2, -1)) / (M**2) # (B,)\n",
    "\n",
    "    return E_1 - 0.5 * E_2  # (B,)\n",
    "\n",
    "# Loop through batches\n",
    "pbar = tqdm(range(num_batches))\n",
    "for b in pbar:\n",
    "    start, end = b * batch_size, min((b + 1) * batch_size, returns_all['prediction'].shape[0])\n",
    "    if start == end:\n",
    "        print(\"SKipping\")\n",
    "        continue  # Skip empty batch\n",
    "\n",
    "    samples = sampless[start:end, :, :, :]\n",
    "    target = targets[start:end, :, :]\n",
    "\n",
    "    crps = np.mean(sr.crps_ensemble(target.detach().cpu(), samples.detach().cpu(), estimator='pwm'))\n",
    "    crps_sum = np.mean(sr.crps_ensemble(target.detach().cpu().sum(axis=-1), samples.detach().cpu().sum(axis=-2), estimator='pwm'))\n",
    "    # vs_05 = np.mean(sr.variogram_score(target.permute(0, 2, 1), samples.permute(0, 2, 3, 1), p=0.5, backend='numba'))\n",
    "    vs_05 = torch.mean(vs_ensemble_torch(target.permute(0, 2, 1).to(device), samples.permute(0, 2, 3, 1).to(device), p=0.5))\n",
    "    # vs_1 = np.mean(sr.variogram_score(target.permute(0, 2, 1), samples.permute(0, 2, 3, 1), p=1.0, backend='numba'))\n",
    "    vs_1 = torch.mean(vs_ensemble_torch(target.permute(0, 2, 1).to(device), samples.permute(0, 2, 3, 1).to(device), p=1))\n",
    "    # vs_2 = np.mean(sr.variogram_score(target.permute(0, 2, 1), samples.permute(0, 2, 3, 1), p=2.0, backend='numba'))\n",
    "    vs_2 = torch.mean(vs_ensemble_torch(target.permute(0, 2, 1).to(device), samples.permute(0, 2, 3, 1).to(device), p=2))\n",
    "    \n",
    "    # es = np.mean(sr.energy_score(target.permute(0, 2, 1), samples.permute(0, 2, 3, 1), backend='numba'))\n",
    "    es = torch.mean(es_ensemble_torch(target.permute(0, 2, 1).to(device), samples.permute(0, 2, 3, 1).to(device)))\n",
    "    \n",
    "    # Append to lists\n",
    "    crps_list.append(crps)\n",
    "    crps_sum_list.append(crps_sum)\n",
    "    vs_05_list.append(vs_05.detach().cpu())\n",
    "    vs_1_list.append(vs_1.detach().cpu())\n",
    "    vs_2_list.append(vs_2.detach().cpu())\n",
    "    es_list.append(es.detach().cpu())\n",
    "\n",
    "    # # Update tqdm with running averages\n",
    "    # # pbar.set_description(f\"CRPS: {np.mean(crps_list):.4f}, VS1: {np.mean(vs_1_list):.4f}, ES: {np.mean(es_list):.4f}\")\n",
    "    \n",
    "    # pbar.set_description(f\"VS: {vs_05:.4f}, VS_T: {vs_05_torch:.4f},\")\n",
    "\n",
    "# Final averages\n",
    "final_scores = {\n",
    "    \"CRPS\": np.mean(crps_list),\n",
    "    \"CRPS_Sum\": np.mean(crps_sum_list),\n",
    "    \"VS_0.5\": np.mean(vs_05_list),\n",
    "    \"VS_1.0\": np.mean(vs_1_list),\n",
    "    \"VS_2.0\": np.mean(vs_2_list),\n",
    "    \"ES\": np.mean(es_list),\n",
    "}\n",
    "\n",
    "print(\"\\nFinal Scores:\")\n",
    "for k, v in final_scores.items():\n",
    "    print(f\"{k}: {v:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155d902f-88b6-4a96-b72a-c1fa01a87992",
   "metadata": {},
   "outputs": [],
   "source": [
    "Final Scores:\n",
    "CRPS: 2.4193\n",
    "CRPS_Sum: 8.7032\n",
    "VS_0.5: 572217.8750\n",
    "VS_1.0: 14610408.0000\n",
    "VS_2.0: 345045532672.0000\n",
    "ES: 83.8458\n",
    "\n",
    "\n",
    "Final Scores:\n",
    "CRPS: 2.4194\n",
    "CRPS_Sum: 8.7040\n",
    "VS_0.5: 572181.3125\n",
    "VS_1.0: 14610432.0000\n",
    "VS_2.0: 168409481216.0000\n",
    "ES: 83.8460"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BasicTS",
   "language": "python",
   "name": "basicts"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
